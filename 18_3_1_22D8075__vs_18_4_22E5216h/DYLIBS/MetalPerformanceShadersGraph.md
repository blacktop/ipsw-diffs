## MetalPerformanceShadersGraph

> `/System/Library/Frameworks/MetalPerformanceShadersGraph.framework/MetalPerformanceShadersGraph`

```diff

-5.2.3.0.0
-  __TEXT.__text: 0xec7700
-  __TEXT.__auth_stubs: 0x2720
+5.4.7.0.0
+  __TEXT.__text: 0xf67ba0
+  __TEXT.__auth_stubs: 0x29c0
   __TEXT.__mpsgraph_init_: 0xc
-  __TEXT.__objc_methlist: 0x5ffc
-  __TEXT.__gcc_except_tab: 0x57730
-  __TEXT.__cstring: 0x7b71c
-  __TEXT.__const: 0x37b48
+  __TEXT.__objc_methlist: 0x68bc
+  __TEXT.__const: 0x3d2d8
+  __TEXT.__cstring: 0x88562
+  __TEXT.__gcc_except_tab: 0x58e80
   __TEXT.__oslogstring: 0x32
-  __TEXT.__unwind_info: 0x24870
-  __TEXT.__eh_frame: 0x2410
-  __TEXT.__objc_classname: 0x1b07
-  __TEXT.__objc_methname: 0x127a7
-  __TEXT.__objc_methtype: 0x3795
-  __TEXT.__objc_stubs: 0x8e00
-  __DATA_CONST.__got: 0x728
-  __DATA_CONST.__const: 0x32c8
-  __DATA_CONST.__objc_classlist: 0x6f0
+  __TEXT.__unwind_info: 0x275e0
+  __TEXT.__eh_frame: 0x24d4
+  __TEXT.__objc_classname: 0x1c21
+  __TEXT.__objc_methname: 0x136eb
+  __TEXT.__objc_methtype: 0x51a9
+  __TEXT.__objc_stubs: 0x9580
+  __DATA_CONST.__got: 0x7a8
+  __DATA_CONST.__const: 0x3378
+  __DATA_CONST.__objc_classlist: 0x738
   __DATA_CONST.__objc_protolist: 0x38
   __DATA_CONST.__objc_imageinfo: 0x8
-  __DATA_CONST.__objc_selrefs: 0x30c0
-  __DATA_CONST.__objc_superrefs: 0x1a8
-  __DATA_CONST.__objc_arraydata: 0xf18
-  __AUTH_CONST.__auth_got: 0x13a0
-  __AUTH_CONST.__auth_ptr: 0x58
-  __AUTH_CONST.__const: 0x57dd0
-  __AUTH_CONST.__cfstring: 0xeb00
-  __AUTH_CONST.__objc_const: 0xeef0
+  __DATA_CONST.__objc_selrefs: 0x3448
+  __DATA_CONST.__objc_superrefs: 0x1e0
+  __DATA_CONST.__objc_arraydata: 0x1078
+  __AUTH_CONST.__auth_got: 0x14f0
+  __AUTH_CONST.__auth_ptr: 0x60
+  __AUTH_CONST.__const: 0x630c0
+  __AUTH_CONST.__cfstring: 0xf960
+  __AUTH_CONST.__objc_const: 0xf388
   __AUTH_CONST.__objc_intobj: 0x4f8
-  __AUTH_CONST.__objc_arrayobj: 0x1ea8
-  __AUTH_CONST.__objc_dictobj: 0x140
-  __AUTH.__objc_data: 0x4510
-  __AUTH.__data: 0x36d0
-  __AUTH.__thread_vars: 0xf0
-  __AUTH.__thread_bss: 0x16c
-  __DATA.__objc_ivar: 0x188
-  __DATA.__data: 0x5390
-  __DATA.__common: 0x1580
-  __DATA.__bss: 0x2d8
-  __DATA_DIRTY.__objc_ivar: 0x810
+  __AUTH_CONST.__objc_arrayobj: 0x1ff8
+  __AUTH_CONST.__objc_dictobj: 0x208
+  __AUTH.__objc_data: 0x47e0
+  __AUTH.__data: 0x4110
+  __AUTH.__thread_vars: 0x120
+  __AUTH.__thread_bss: 0x238
+  __DATA.__objc_ivar: 0x1b4
+  __DATA.__data: 0x5cc0
+  __DATA.__bss: 0x390
+  __DATA.__common: 0x1967
+  __DATA_DIRTY.__objc_ivar: 0x898
   __DATA_DIRTY.__objc_data: 0x50
   __DATA_DIRTY.__data: 0xa8
-  __DATA_DIRTY.__bss: 0x1400
-  __DATA_DIRTY.__common: 0x30
+  __DATA_DIRTY.__bss: 0x1590
   - /System/Library/Frameworks/Accelerate.framework/Accelerate
   - /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation
   - /System/Library/Frameworks/Foundation.framework/Foundation

   - /usr/lib/libc++.1.dylib
   - /usr/lib/libncurses.5.4.dylib
   - /usr/lib/libobjc.A.dylib
-  Functions: 52429
-  Symbols:   58190
-  CStrings:  12566
+  Functions: 59446
+  Symbols:   76868
+  CStrings:  13796
 
Symbols:
+ _ANECLayerNormLayerDescInitialize
+ _ANECValidateLayerNormLayer
+ _MPSGetDataTypeName
+ _OBJC_CLASS_$_MPSGraphCoreMLCompilerDelegate
+ _OBJC_CLASS_$_MPSGraphExecutableEntryPoint
+ _OBJC_CLASS_$_MPSGraphExecutableEntryPointToSymbolAndFileNameMap
+ _OBJC_CLASS_$_MPSNDArrayQuantizedConvolution
+ _OBJC_CLASS_$_NSMapTable
+ _OBJC_CLASS_$_NSUUID
+ _OBJC_CLASS_$__ANEModelInstanceParameters
+ _OBJC_CLASS_$__ANEProcedureData
+ _OBJC_CLASS_$__ANEWeight
+ _OBJC_METACLASS_$_MPSGraphCoreMLCompilerDelegate
+ _OBJC_METACLASS_$_MPSGraphExecutableEntryPoint
+ _OBJC_METACLASS_$_MPSGraphExecutableEntryPointToSymbolAndFileNameMap
+ __ZNK3MIL13IRTensorValue11GetDataViewINS_5UInt3EEENS_4Util4SpanIKT_Lm18446744073709551615EEEv
+ __ZNK3MIL13IRTensorValue11GetDataViewINS_5UInt6EEENS_4Util4SpanIKT_Lm18446744073709551615EEEv
+ __ZNK3MIL18IRConstantProperty20GetUInt64ScalarValueEv
+ __ZNK3MIL23IRTensorBufferValueType25TryGetRowAlignmentInBytesEv
+ __ZNK3MIL8IRObject13GetAttributesEv
+ __ZNKSt3__123__match_any_but_newlineIcE6__execERNS_7__stateIcEE
+ __ZNKSt3__14__fs10filesystem4path10__filenameEv
+ __ZNKSt3__14__fs10filesystem4path13__parent_pathEv
+ __ZNKSt3__14__fs10filesystem4path18lexically_relativeERKS2_
+ __ZNKSt3__16locale4nameEv
+ __ZNSt13exception_ptrD1Ev
+ __ZNSt3__111regex_errorC1ENS_15regex_constants10error_typeE
+ __ZNSt3__111regex_errorD1Ev
+ __ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE
+ __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEaSEc
+ __ZNSt3__113random_deviceC1ERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE
+ __ZNSt3__113random_deviceD1Ev
+ __ZNSt3__113random_deviceclEv
+ __ZNSt3__114__shared_countD2Ev
+ __ZNSt3__115__get_classnameEPKcb
+ __ZNSt3__115__thread_structC1Ev
+ __ZNSt3__115__thread_structD1Ev
+ __ZNSt3__117__assoc_sub_state16__on_zero_sharedEv
+ __ZNSt3__117__assoc_sub_state9set_valueEv
+ __ZNSt3__117bad_function_callD1Ev
+ __ZNSt3__119__thread_local_dataEv
+ __ZNSt3__120__get_collation_nameEPKc
+ __ZNSt3__120__throw_system_errorEiPKc
+ __ZNSt3__14__fs10filesystem11__copy_fileERKNS1_4pathES4_NS1_12copy_optionsEPNS_10error_codeE
+ __ZNSt3__14__fs10filesystem18__weakly_canonicalERKNS1_4pathEPNS_10error_codeE
+ __ZNSt3__14__fs10filesystem8__removeERKNS1_4pathEPNS_10error_codeE
+ __ZNSt3__14__fs10filesystem8__statusERKNS1_4pathEPNS_10error_codeE
+ __ZNSt3__16futureIvEC1EPNS_17__assoc_sub_stateE
+ __ZNSt3__16localeC1ERKS0_
+ __ZNSt3__16localeC1Ev
+ __ZNSt3__16thread6detachEv
+ __ZNSt3__16threadD1Ev
+ __ZNSt3__17collateIcE2idE
+ __ZTINSt3__111regex_errorE
+ __ZTINSt3__117__assoc_sub_stateE
+ __ZTINSt3__117bad_function_callE
+ __ZTVNSt3__117__assoc_sub_stateE
+ __ZTVNSt3__117bad_function_callE
+ ___mulsc3
+ __availability_version_check
+ _fread
+ _fseek
+ _ftell
+ _gethostname
+ _getsid
+ _kANEFBaseModelIdentifierKey
+ _kANEFModelPreCompiledValue
+ _pthread_setspecific
+ _rewind
+ _setsid
+ _sscanf
+ _symlink
- __ZNKSt9exception4whatEv
- __ZNSt9exceptionD2Ev
- _del_curterm
- _logb
- _scalbn
- _set_curterm
- _setupterm
- _tigetnum
CStrings:
+ "\x03#"
+ "\x05D\x12"
+ " '"
+ " (the type of the reduction inputs)"
+ " <= "
+ " > input rank "
+ " > output rank "
+ " Shrink dims = "
+ " already exists"
+ " and result rank "
+ " and the stored callee type: "
+ " as "
+ " as it is a directory"
+ " axes."
+ " but got "
+ " but start/end/strides are provided with "
+ " bytes in the blob, found "
+ " cannot be lowered as Flatten on ANE"
+ " cannot be lowered as Unflatten on ANE"
+ " dimensions instead."
+ " dynamic dims while output_shape has "
+ " elements"
+ " expect it to be "
+ " expect result rank to be "
+ " expected output shape mismatch: "
+ " expected rank is "
+ " externalize"
+ " from "
+ " given shape is "
+ " has non-unit dimension length "
+ " in input tensor."
+ " in the "
+ " inputs instead"
+ " is a tensor or a memref"
+ " is already registered."
+ " is larger than input rank "
+ " is not equivalent to the canonical transposed input type "
+ " is not registered"
+ " must be 0D tensor of 16-bit float or 32-bit float or 32/64-bit signed integer values, but got "
+ " must be 0D tensor of 16-bit float or 32-bit float values, but got "
+ " must be 0D tensor of 32-bit signed integer values or 1D tensor of 32-bit signed integer values, but got "
+ " must be 0D tensor of 32-bit signed integer values, but got "
+ " must be 0D tensor of Boolean type. or 16-bit float or 32-bit float or 8/32/64-bit signed integer values, but got "
+ " must be 0D tensor of Boolean type. values, but got "
+ " must be 1D tensor of 16-bit float or 32-bit float or 32/64-bit signed integer values, but got "
+ " must be 1D tensor of 16-bit float or 32-bit float values, but got "
+ " must be 1D tensor of 32-bit signed integer values, but got "
+ " must be 4D tensor of 16-bit float or 32-bit float or 32-bit signed integer values, but got "
+ " must be 4D/5D memref of 16-bit float or 16-bit unsigned integer or 16-bit signed integer or 8-bit unsigned integer or 8-bit signed integer or 4-bit signed integer values, but got "
+ " must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer or 4-bit signed integer values, but got "
+ " must be 4D/5D memref of 16-bit float or 8-bit unsigned integer or 8-bit signed integer values, but got "
+ " must be 4D/5D memref of 32-bit float or 16-bit float or 8-bit signed integer or 8-bit unsigned integer or 2/4/8-bit unsigned integer values, but got "
+ " must be 5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer or 4-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or 16/32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or 32-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or 32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or 8/32-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or 8/32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or Boolean type. or 32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or Boolean type. or 8/16/32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or Boolean type. or 8/32-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or Boolean type. or 8/32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float values, but got "
+ " must be CoreML Tensor of 16/32-bit signed integer values, but got "
+ " must be CoreML Tensor of 32-bit signed integer values, but got "
+ " must be CoreML Tensor of Boolean type. or 16-bit float or 32-bit float or 32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of Boolean type. or 16-bit float or 32-bit float or 8/16/32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of Boolean type. or 16-bit float or 32-bit float or 8/32/64-bit signed integer values, but got "
+ " must be CoreML Tensor of Boolean type. values, but got "
+ " must be CoreML Tensor of complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be complex-type, but got "
+ " must be tensor of mps native type or complex or quantized or palette LUT index values or memref of mps native type or complex or quantized or palette LUT index values, but got "
+ " must be variadic of , but got "
+ " must be variadic of 4D/5D memref of 16-bit float or 16-bit unsigned integer or 16-bit signed integer or 8-bit unsigned integer or 8-bit signed integer or 4-bit signed integer values, but got "
+ " must be variadic of 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer or 4-bit signed integer values, but got "
+ " must be variadic of 4D/5D memref of 32-bit signed integer or 64-bit signed integer values, but got "
+ " must be variadic of CoreML Tensor of 16-bit float or 32-bit float or 32/64-bit signed integer values, but got "
+ " must be variadic of strided memref of any type values, but got "
+ " must be variadic of tensor of 16-bit float or 32-bit float or 32/64-bit signed integer values, but got "
+ " must be variadic of tensor of any type values or 1-bit signless integer, but got "
+ " noinline"
+ " number of axes to shrink "
+ " private"
+ " results, got "
+ " shrink axes contains "
+ " shrink dimension "
+ " static sizes"
+ " stride elements for output "
+ " to ANE"
+ " to be the same as the "
+ " to be valid and contiguous."
+ " to have a higher (or same) rank "
+ " to have size equal to the expanded rank ("
+ " to match"
+ " which is higher than input rank "
+ "!_currentEntryInfo->tiAndFoldHelper->hasType(value) && \"static type already defined\""
+ "!aneInfo->aneRegionCallOpHandler"
+ "!runtime"
+ "\"\x11R"
+ "%@ not included in the provided perEntryPointToSymbolAndFileNameMap with following items:\n%@"
+ "%@%@%@"
+ "%@:%@"
+ "%d.%d.%d"
+ "&other != this"
+ "' failed to satisfy constraint: "
+ "' failed to satisfy constraint: 64-bit signed integer attribute"
+ "' failed to satisfy constraint: Array of `param.decl`"
+ "' failed to satisfy constraint: CoordinateMode elements attribute of shape {2}"
+ "' failed to satisfy constraint: CoordinateType elements attribute of shape {2}"
+ "' failed to satisfy constraint: Floating point rounding mode"
+ "' failed to satisfy constraint: Integer overflow arith flags"
+ "' failed to satisfy constraint: NormalizedCoordinateRange elements attribute of shape {2}"
+ "' failed to satisfy constraint: PaddingMode elements attribute of shape {2}"
+ "' failed to satisfy constraint: PoisonAttrInterface instance"
+ "' failed to satisfy constraint: WarpCoordinateMode elements attribute of shape {1}"
+ "' failed to satisfy constraint: dense elements attribute for palettized LUT of rank 0/1/2/3/4/5"
+ "' failed to satisfy constraint: dictionary of named attribute values"
+ "' failed to satisfy constraint: i8 dense array attribute"
+ "' failed to satisfy constraint: ui64 elements attribute of rank 0/1"
+ "' failed to satisfy constraint: ui8 elements attribute of rank 0/1"
+ "' to represent state for '"
+ "' value invalid for ulong argument!"
+ "', found that it represents '"
+ "'aggregate' must be ranked tensor of any type values, but got "
+ "'anec.convolution' op attribute 'kernel_palettized_LUT' failed to satisfy constraint: dense elements attribute for palettized LUT of rank 0/1/2/3/4/5"
+ "'anec.deconvolution' op attribute 'kernel_palettized_LUT' failed to satisfy constraint: dense elements attribute for palettized LUT of rank 0/1/2/3/4/5"
+ "'anec.input_view' op attribute 'step' failed to satisfy constraint: 64-bit signed integer attribute"
+ "'anec.input_view' with negative stride must have size {0} that equals the size of tensor {1} at dimension {2}"
+ "'anec.resample' op attribute 'background_value' failed to satisfy constraint: 16-bit float attribute"
+ "'anec.resample' op attribute 'coordinate_mode' failed to satisfy constraint: CoordinateMode elements attribute of shape {2}"
+ "'anec.resample' op attribute 'coordinate_type' failed to satisfy constraint: CoordinateType elements attribute of shape {2}"
+ "'anec.resample' op attribute 'normalized_range' failed to satisfy constraint: NormalizedCoordinateRange elements attribute of shape {2}"
+ "'anec.resample' op attribute 'padding_modes' failed to satisfy constraint: PaddingMode elements attribute of shape {2}"
+ "'anec.resample' op attribute 'sampling_method' failed to satisfy constraint: SamplingGridMethod elements attribute of shape {2}"
+ "'anec.resample' op attribute 'warp_coordinate_mode' failed to satisfy constraint: WarpCoordinateMode elements attribute of shape {1}"
+ "'anec.resample' op requires attribute 'background_value'"
+ "'anec.resample' op requires attribute 'coordinate_mode'"
+ "'anec.resample' op requires attribute 'coordinate_type'"
+ "'anec.resample' op requires attribute 'normalized_range'"
+ "'anec.resample' op requires attribute 'padding_modes'"
+ "'anec.resample' op requires attribute 'sampling_method'"
+ "'anec.resample' op requires attribute 'warp_coordinate_mode'"
+ "'mpsx.buffer_to_tensor' op attribute 'interleave' failed to satisfy constraint: ui64 elements attribute of rank 1"
+ "'mpsx.buffer_to_tensor' op attribute 'isChannelAndInterleaveSame' failed to satisfy constraint: bool attribute"
+ "'mpsx.buffer_to_tensor' op attribute 'isTensorBufferOp' failed to satisfy constraint: bool attribute"
+ "'mpsx.buffer_to_tensor' op attribute 'resultElementType' failed to satisfy constraint: any type attribute"
+ "'mpsx.buffer_to_tensor' op attribute 'shape' failed to satisfy constraint: ui64 elements attribute of rank 1"
+ "'mpsx.quantized_conv2d' op 'operandSegmentSizes' attribute for specifying operand segments must have 11 elements, but got "
+ "'mpsx.quantized_conv2d' op attribute 'data_layout' failed to satisfy constraint: valid TensorDataLayout"
+ "'mpsx.quantized_conv2d' op attribute 'dilation_rates' failed to satisfy constraint: ui64 elements attribute of shape {4}"
+ "'mpsx.quantized_conv2d' op attribute 'explicit_padding' failed to satisfy constraint: ui64 elements attribute of shape {4, 2}"
+ "'mpsx.quantized_conv2d' op attribute 'groups' failed to satisfy constraint: 64-bit unsigned integer attribute"
+ "'mpsx.quantized_conv2d' op attribute 'input_quant_params_axis' failed to satisfy constraint: 32-bit signed integer attribute"
+ "'mpsx.quantized_conv2d' op attribute 'output_type' failed to satisfy constraint: any type attribute"
+ "'mpsx.quantized_conv2d' op attribute 'padding_style' failed to satisfy constraint: valid padding_style"
+ "'mpsx.quantized_conv2d' op attribute 'strides' failed to satisfy constraint: ui64 elements attribute of shape {4}"
+ "'mpsx.quantized_conv2d' op attribute 'weights_layout' failed to satisfy constraint: valid TensorDataLayout"
+ "'mpsx.quantized_conv2d' op attribute 'weights_quant_params_axis' failed to satisfy constraint: 32-bit signed integer attribute"
+ "'mpsx.quantized_conv2d' op requires attribute 'data_layout'"
+ "'mpsx.quantized_conv2d' op requires attribute 'dilation_rates'"
+ "'mpsx.quantized_conv2d' op requires attribute 'explicit_padding'"
+ "'mpsx.quantized_conv2d' op requires attribute 'groups'"
+ "'mpsx.quantized_conv2d' op requires attribute 'operandSegmentSizes'"
+ "'mpsx.quantized_conv2d' op requires attribute 'output_type'"
+ "'mpsx.quantized_conv2d' op requires attribute 'padding_style'"
+ "'mpsx.quantized_conv2d' op requires attribute 'strides'"
+ "'mpsx.quantized_conv2d' op requires attribute 'weights_layout'"
+ "'mpsx.tensor_to_buffer' op attribute 'interleave' failed to satisfy constraint: ui64 elements attribute of rank 1"
+ "'mpsx.tensor_to_buffer' op attribute 'isChannelAndInterleaveSame' failed to satisfy constraint: bool attribute"
+ "'mpsx.tensor_to_buffer' op attribute 'isTensorBufferOp' failed to satisfy constraint: bool attribute"
+ "'mpsx.tensor_to_buffer' op attribute 'resultElementType' failed to satisfy constraint: any type attribute"
+ "'mpsx.tensor_to_buffer' op attribute 'shape' failed to satisfy constraint: ui64 elements attribute of rank 1"
+ "(Optional) If set, all the relative paths will use this as the base path."
+ "(dims: %@ type: %@)"
+ "(getNumBuckets() & (getNumBuckets() - 1)) == 0 && \"# initial buckets must be a power of two!\""
+ ") along the split axis"
+ ") but found "
+ ") does not match the input dimension size ("
+ ") to "
+ ") to equal the number of reassociation maps ("
+ "), "
+ "), but it is  "
+ ")."
+ "* %@ => %@"
+ "+Inf"
+ ", ["
+ ", cannot handle interleave in this case. Aborting."
+ ", type was "
+ "-%%%%%%%%"
+ "-[MPSGraphBufferToTensorOp makeMLIROpWithBuilder:symbolTable:inputValues:opInitialization:name:]"
+ "-[MPSGraphExecutable applyEntryPointToSymbolAndFileNameMap:device:compilationDescriptor:]"
+ "-[MPSGraphExecutable applyOptimizationPassesWithDevice:module:compilationID:compilationDescriptor:]"
+ "-[MPSGraphExecutable emitViewerSPIWithDevice:inputShapes:compilationDescriptor:]"
+ "-[MPSGraphExecutable getOutputTypesWithDevice:shapedEntryPoint:compilationDescriptor:]"
+ "-[MPSGraphExecutable runInternalWithDevice:commandBuffer:feeds:results:executableExecutionDescriptor:mpsGraphOwnedCommandBuffer:]"
+ "-[MPSGraphExecutable specializedModuleWithDevice:shapedEntryPoints:compilationDescriptor:fallingBack:fallbackRuntimeKey:]"
+ "-[MPSGraphExecutable unloadEntryPointToSymbolAndFileNameMap:device:compilationDescriptor:]"
+ "-[MPSGraphPackage initWithPackageURL:temporaryPackageURL:append:]"
+ "-[MPSGraphTensorToBufferOp makeMLIROpWithBuilder:symbolTable:inputValues:opInitialization:name:]"
+ "-[MetalPackage initWithPackageURL:temporaryPackageURL:]"
+ "-[RuntimeSpecializationsCache getOrCreateSpecializationForMap:perEntryFuncOpSymbolMap:]"
+ "-th reduction has an empty body"
+ "-th reduction operand: "
+ "-th reduction region"
+ "-th result type: "
+ ". This is not a collapse ("
+ ". This is not an expansion ("
+ ".arg"
+ ".lock"
+ ".output"
+ "/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphCoreMLCompilerDelegate.mm"
+ "/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/Operations/MPSGraphTensorBufferOpsPrivate.mm"
+ "/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Headers/Project/MPSGraphANEUtils.h"
+ "/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Runtimes/MPSRuntime/Headers/MemrefBufferization.h"
+ "/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Runtimes/MPSRuntime/Headers/Operations/GPUConvolutionOps.h"
+ "/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Runtimes/MPSRuntime/Headers/Operations/GPUFusionOps.h"
+ "/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Runtimes/MPSRuntime/Operations/GPUFusionOps.mm"
+ "/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Runtimes/MPSRuntime/Operations/GPUMemrefOps.mm"
+ "/System/Library/CoreServices/SystemVersion.plist"
+ "/dev/urandom"
+ "0123456789ABCDEF"
+ "1.3.1"
+ "1.3.2"
+ "1.3.3"
+ "180400"
+ "20.0.0git"
+ "5.4.0"
+ "5.4.1"
+ "5.4.4"
+ "5.4.5"
+ "5.4.6"
+ "5.4.7"
+ "8 % bitWidth == 0"
+ ": Unknown "
+ ": constant attribute 0"
+ "::mlir::arith::IntegerOverflowFlags"
+ "={"
+ "@\"MPSGraphExecutableEntryPointToSymbolAndFileNameMap\""
+ "@\"NSJSONSerialization\""
+ "@\"NSMapTable\""
+ "@24@0:8^v16"
+ "@24@0:8{FuncOp=^{Operation}}16"
+ "@32@0:8@16r^v24"
+ "@40@0:8r^v16r^v24^v32"
+ "@60@0:8@16@24I32@36B44B48@52"
+ "@76@0:8@16@24@32@40I48@52B60B64@68"
+ "A18"
+ "A18 family"
+ "A18_region"
+ "ANE Concat supports only supports const positive axis"
+ "ANE Output should have more than 1 dimension"
+ "ANE adapted model load failure: %s"
+ "ANE-incompatible type: input type has to be fp32/fp16/ui8/i8/u16/i16"
+ "ANE-incompatible type: input type of indices for palettized conv has to be ui2/ui4/ui8"
+ "ANE-incompatible type: output type has to be fp32/fp16/ui8/i8/u16/i16"
+ "ANECRingBufferReader"
+ "ANECRingBufferWriter"
+ "ANECTensorBuffer"
+ "ANEF returned cacheURLIdentifier as nil for base model"
+ "Absolute"
+ "Adapting ANE model."
+ "Add an init op for delegate with payload to the existing module"
+ "AddInitOpForDelegate"
+ "All files will be copied to this path and will be referred to relatievly to this path."
+ "Assigns to which memref a tensor should be written."
+ "Attribute 'constant_values' do not represent a 16-bit integer or floating-point attribute"
+ "Attribute 'constant_values' do not represent a single-element integer or floating-point attribute"
+ "Axis value is incorrect for Op "
+ "BatchToSpace batch_axis operand must be constant"
+ "BatchToSpace batch_axis operand must match with ANEC batch axis"
+ "BatchToSpace block_dimensions operand must be constant"
+ "BatchToSpace spatial_axes operand must match with ANEC spatial axes"
+ "BatchToSpace spatial_axis operand must be constant"
+ "BiasAdd invalid channel or not a constant bias"
+ "BiasType"
+ "BuiltinAttributes.h.inc"
+ "CFDataCreateWithBytesNoCopy"
+ "CFDictionaryGetValue"
+ "CFGetTypeID"
+ "CFPropertyListCreateFromXMLData"
+ "CFPropertyListCreateWithData"
+ "CFRelease"
+ "CFStringCreateWithCStringNoCopy"
+ "CFStringGetCString"
+ "CFStringGetTypeID"
+ "CWConv3DOp must have 4D inputs"
+ "Cannot create a valid GOC"
+ "Cannot find corresponding index from weight file path: "
+ "Cannot get channel index"
+ "Cannot get the filter definition op"
+ "Canonicalization failed for ANE region "
+ "Canonicalization of convolution ops failed for ANE region "
+ "Channel <-> Space supports only 1 axis"
+ "Circular"
+ "Collapsing dimension for Op "
+ "Comma seperated list of entry functions"
+ "Concat supports only 1 axis"
+ "Conv dilation must be 1 for batch / channel axis"
+ "Conv stride must be 1 for batch / channel axis"
+ "Conv stride must be 1 for batch axis"
+ "Convert conv / pooling ops to either channels-first layout (for example NCHW or NCDHW) or channels-last layout (for example NHWC or NDHWC)."
+ "Convert operations from f32 to f16."
+ "Convert to a channels-first layout."
+ "Convert to a channels-last layout."
+ "Converts a buffer to a tensor for MIL tensor buffer ops."
+ "Converts a tensor to a buffer for MIL tensor buffer ops."
+ "Coordinate tensor must be rank 4."
+ "CoordinateType"
+ "CoordinateTypeInfo"
+ "Copies the data files to the base path provided and updates the paths in mps.read_data_from_file to be relative to that path."
+ "CoreMLToMPS"
+ "Could not copy data files"
+ "Could not create a lock for %@ at %@ with error: %s"
+ "Could not detach process, ::setsid failed"
+ "Could not find function %@ in the module"
+ "Could not find operand in memref map."
+ "Could not locate function named "
+ "Could not specialize the module for multiple entry points"
+ "Counters and values:\n"
+ "Create memref regions."
+ "Data File Names"
+ "Delegate id to identify caller delegate."
+ "Dialect Attribute with name "
+ "Dialect Type with name "
+ "Dim op is not defined by a reshape op."
+ "Don't run any control-flow simplification."
+ "Duplicate entry for value in _bufferForValue map."
+ "Empty"
+ "Entry function %@ not found"
+ "Entry function %@ not set in the provided perEntryPointToSymbolAndFileNameMap"
+ "Entry point for function %@ with input types: %@"
+ "Entry points are not unique"
+ "Error: CoreML -> MPS lowering failed"
+ "Error: Each entry point needs to set the entry function name"
+ "Error: Failed to remove unreachable functions"
+ "Error: No ANEC region was generated from the MPS host function."
+ "Error: The device needs to be set when using multiple entry points."
+ "Error: The executable has multiple entry points however the entry function has not been specified. Please provide it when creating a new MPSGraphExecutable"
+ "Error: The executable is being compiled for multiple entry points, however entry function has been set via the MPSGraphCompilationDescriptor. Set one or the other."
+ "Error: can not find ANEC region"
+ "Error: creating .metalpackage directory failed"
+ "Error: delegate op placement failed"
+ "Error: do not support tensor buffer op with rank <= 3"
+ "Error: failed to extract the stride and interleave info"
+ "Error: invalid tensor buffer pattern"
+ "Error: the ANEC region has more than one caller"
+ "Error: unknown fused op type"
+ "Expected "
+ "Expected Chunks to be in increasing order "
+ "Expected data tensor to have 5 dimensions after padding, but got "
+ "Expected index tensor to have 5 dimensions after padding, but got "
+ "Expected one block in region for MemrefBackedOp."
+ "Expected one region for MemrefBackedOp."
+ "Expected only one block in fusionOp.\n"
+ "Expected to only find one unique core op."
+ "Failed to extract fpValues from the operand"
+ "Failed to extract the stride and interleave info"
+ "Failed to get the file size for "
+ "Failed to open resource file at "
+ "Failed to parse at : "
+ "Failed to parse int at : "
+ "Failed to read resource at "
+ "Failed type inference"
+ "File Name"
+ "Found unsupported constant operand"
+ "FunctionInterfaces.h.inc"
+ "GPUConvolutionOps.h"
+ "GPURegionRuntime"
+ "Got an error serializing: %@"
+ "GraphOp has no concept of 'nested' visibility"
+ "Hashing.h"
+ "INFINITY"
+ "IOSurfaceSharedEvent"
+ "If enabled, dequantize and conv2D ops will be canonicalized as a single-dispatch Fusion op."
+ "If the ratio between the number of the operations in the callee and the number of the operations in the caller exceeds this value (in percentage), then the callee is not inlined even if it is legal to inline it"
+ "If true, features required for AFM model, including 16-bit int support and fused ops."
+ "Incompatible element type for ANE: expected fp16, si8, or ui8"
+ "Incompatible element type for ANE: expected fp16, si8, ui8, si16, or ui16"
+ "Inf"
+ "InputParamType"
+ "InputParams"
+ "Insert a break point on the last enabled count of a chunks list"
+ "Insert metadata generated from the delegate into Init call."
+ "Invalid attribute `deinit_fn` in property conversion: "
+ "Invalid attribute `delegate_id` in property conversion: "
+ "Invalid attribute `delegate_resources_path` in property conversion: "
+ "Invalid attribute `dim` in property conversion: "
+ "Invalid attribute `externAttr` in property conversion: "
+ "Invalid attribute `externalize` in property conversion: "
+ "Invalid attribute `init_fn` in property conversion: "
+ "Invalid attribute `message` in property conversion: "
+ "Invalid attribute `no_inline` in property conversion: "
+ "Invalid attribute `opname` in property conversion: "
+ "Invalid attribute `overflowFlags` in property conversion: "
+ "Invalid attribute `param_decls` in property conversion: "
+ "Invalid attribute `path` in property conversion: "
+ "Invalid attribute `priv` in property conversion: "
+ "Invalid attribute `resource` in property conversion: "
+ "Invalid attribute `roundingmode` in property conversion: "
+ "Invalid attribute `safeTransforms` in property conversion: "
+ "Invalid attribute `static_output_shape` in property conversion: "
+ "Invalid attribute `toImport` in property conversion: "
+ "Invalid cache key"
+ "Invalid coordinate tensor format. Channel dim should be either 1 or 2."
+ "Invalid executable directory path"
+ "Invalid mps::CropResizeAlignmentMode for ANE, only defaultAlignment, alignCorners, and offsetCorners are supported"
+ "Invalid mps::CropResizeCoordinateMode for ANE, only cornersHeightFirst, cornersWidthFirst, centersHeightFirst, and centersWidthFirst are supported"
+ "Invalid mps::SamplingMode for ANE, only bilienar and nearest are supported"
+ "Invalid number of types provided for function "
+ "Invalid package path"
+ "Invalid pattern to convert"
+ "Invalid row alignment value"
+ "Invalid symbol map size"
+ "Invalid warp tensor data type. It should be either F16, UI8 or SI8 since MPS currently doesn't support UI16/SI16 transpose to convert NHWC to NCHW ANEC format."
+ "Invalid weight operand type of "
+ "InvalidUnitLayerNormDimension"
+ "Iter != this->end() && \"DenseMap::at failed due to a missing key\""
+ "Key to Symbol Name"
+ "Late Canonicalization failed for ANE region "
+ "MLIR20.0.0git"
+ "MLLibrary"
+ "MPSConvertF32ToF16Pass"
+ "MPSCopyDataFiles"
+ "MPSGRAPH_DISABLE_QUANTIZED_CONV_FUSION"
+ "MPSGRAPH_DISABLE_QUANTIZED_CONV_FUSION EV is set."
+ "MPSGRAPH_ENABLE_LAYOUT_CONVERSION"
+ "MPSGRAPH_ENABLE_LAYOUT_CONVERSION EV is set to %d.\n"
+ "MPSGRAPH_ENABLE_MEMREF_BUFFERIZATION"
+ "MPSGRAPH_ENABLE_MEMREF_BUFFERIZATION EV is set to %d.\n"
+ "MPSGRAPH_ENABLE_QUANTIZED_CONV_FUSION"
+ "MPSGRAPH_ENABLE_QUANTIZED_CONV_FUSION EV is set."
+ "MPSGRAPH_LOG_PASS_TIMINGS"
+ "MPSGRAPH_LOG_PASS_TIMINGS EV is set."
+ "MPSGraphBufferToTensorOp"
+ "MPSGraphComputePackage_Project.h"
+ "MPSGraphCoreMLCompilerDelegate"
+ "MPSGraphExecutableEntryPoint"
+ "MPSGraphExecutableEntryPointToSymbolAndFileNameMap"
+ "MPSGraphExecutableShapedEntryPoint"
+ "MPSGraphTensorToBufferOp"
+ "MPSLayoutConversion"
+ "MPSMemrefRegion"
+ "MPSReorderOperations"
+ "MPSUnreachableFunctionRemoval"
+ "Marks a region of ops which are using memrefs."
+ "Max distance to move an op to reach goal."
+ "MetalPackage"
+ "Mismatch in fallback module entries"
+ "Missing ANE compiler helper"
+ "Missing file in the existing MPSGraphPackage"
+ "MissingLayerNormEpsilon"
+ "Mutable weights are only supported with new ANEC workflow"
+ "MutableWeights"
+ "N <= SizeTypeMax()"
+ "NegateSrc1"
+ "NegateSrc2"
+ "Neither strides nor row bytes alignment specified"
+ "No conversion."
+ "No entry points were provided"
+ "No stitching expected in this fusionOp.\n"
+ "Non-static shapes for operands are not yet supported."
+ "Non-static shapes for results are not yet supported."
+ "Number of operands mismatch in UseMemrefOp vs corresponding MemrefBackedOp"
+ "Only 2-bit, 4-bit, and 8-bit palettization for convs are supported!"
+ "Only dataLayout NCDHW & NDHWC are supported for Conv3D"
+ "Only dataLayout NCHW is supported for Conv2D"
+ "Only fp16 is supported for A11/A12 Broadcasts."
+ "Only have "
+ "Only one dimension can be interleaved"
+ "Only per-cout LUT is supported!"
+ "Only weights dataLayout OIDHW & DHWIO are supported for Conv3D"
+ "Op is expected to have at least one operand."
+ "Op is expected to have zero operands and one result."
+ "Operand 1 should be constant."
+ "Operation requires exactly one axis for quantization, but got "
+ "Optimized Modules"
+ "Optimized No Device Modules"
+ "Optional prefix the passes add for each payload."
+ "PalettizedConv"
+ "Per-cout LUT dim must be divisible by cout LUT dim!"
+ "Perform aggressive control-flow simplification (e.g. block merging)."
+ "Perform simple control-flow simplifications (e.g. dead args elimination)."
+ "PreScale"
+ "PreScaleType"
+ "Print unique SSA ID numbers for values, block arguments and naming conflicts across all regions"
+ "ProductVersion"
+ "Property conversion failed."
+ "QuantizedConv2D"
+ "QuantizedConv2DOp input should be rank 4"
+ "Reached maxReorderingDistance "
+ "ReduceMin for non fp type is not supported for A13 and below"
+ "Relative"
+ "Remove functions which are not reachable given the entry points."
+ "Reorder Permute MPS ops so that they are next to each other and can then potentially be combined/removed in canonicalization."
+ "ReplaceGraphBodyWithDelegateCall"
+ "Resize alignCorners == centerResult == true is not supported on A14-class ANEs."
+ "Resize with custom scale and offset values not supported on ANE."
+ "Result not found in MemrefBufferization results map."
+ "RingBufferReaderOffsetInfo"
+ "RingBufferReaderOutputSizeInfo"
+ "RingBufferWriterInfo"
+ "RuntimeSpecialization"
+ "RuntimeSpecializationsCache"
+ "Scale"
+ "ScaleType"
+ "Segment all ops to the given delegate."
+ "SegmentAllOpsToDelegate"
+ "Skip regions when printing ops."
+ "Smallest stride dimension was not channels, it's likely there is an assumption being violated, aborting."
+ "States"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::BatchMatmulOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::BroadcastInDimsOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::CastOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::ConcatOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::ConstantOpLowering]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::Conv2dOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::DimOfReshapeOp]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::DropDelinearizeOfSingleLoop]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::DropUnitExtentBasis]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::FoldConsecutiveConstantPadding]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::FoldEmptyCopy]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::ForallOpIterArgsFolder]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::GatherNdOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::GeluOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::GraphOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::InvokeOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::LLOModuleOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::OutputOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::ReducePattern<mlir::ODIE::Compiler::CoreML::ReduceMeanOp, mlir::mps::ReductionMeanOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::ReducePattern<mlir::ODIE::Compiler::CoreML::ReduceSumOp, mlir::mps::ReductionSumOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SelectI1ToNot]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SelectOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SingleInputConcatOp]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SliceOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SliceUpdateOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SplitOpPattern]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::AddOp, mlir::mps::AddOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::AndOp, mlir::mps::AndOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::CosOp, mlir::mps::CosOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::DivideOp, mlir::mps::DivideOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::EqualOp, mlir::mps::EqualToOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::ExpandDimsOp, mlir::mps::ExpandDimsOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::FloorDivideOp, mlir::mps::FloorDivideOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::GreaterOp, mlir::mps::GreaterThanOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::LogOp, mlir::mps::LogarithmOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::MaximumOp, mlir::mps::MaximumOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::MinimumOp, mlir::mps::MinimumOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::ModuloOp, mlir::mps::ModuloOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::MulOp, mlir::mps::MultiplyOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::NotEqualOp, mlir::mps::NotEqualToOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::OrOp, mlir::mps::OrOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::PowOp, mlir::mps::PowerOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::ReLUOp, mlir::mps::ReluOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::ReshapeOp, mlir::mps::ReshapeOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::RsqrtOp, mlir::mps::ReciprocalSquareRootOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::ShrinkDimsOp, mlir::mps::SqueezeOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::SigmoidOp, mlir::mps::SigmoidOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::SiluOp, mlir::mps::SwishOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::SinOp, mlir::mps::SinOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::SoftmaxOp, mlir::mps::SoftmaxOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::SqrtOp, mlir::mps::SquareRootOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::SubOp, mlir::mps::SubtractOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::TanhOp, mlir::mps::TanhOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::TransposeOp, mlir::mps::PermuteOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::TrivialPattern<mlir::ODIE::Compiler::CoreML::WhereOp, mlir::mps::SelectOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::WhileOpAlignBeforeArgs]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = FoldConstantCase]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertBroadcast<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertCrop<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertDivide<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertExpandDims<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertFloorDivide<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertFusionOp]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertMatMul<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertPadding<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertPalettizedConvPatternToFusionOp]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReadDataFromFile]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReadVariable]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReductionArg<mlir::mps::ReductionArgMaxOp, mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReductionArg<mlir::mps::ReductionArgMinOp, mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReshape<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertResize<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReverse<mlir::anec::Family::A11Legacy>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReverse<mlir::anec::Family::A12>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReverse<mlir::anec::Family::A13>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReverse<mlir::anec::Family::A14>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReverse<mlir::anec::Family::A15>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReverse<mlir::anec::Family::A16>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReverse<mlir::anec::Family::A17>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReverse<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertRingBufferReaderPatternToFusionOp]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertRingBufferWriterPatternToFusionOp]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertSampleGrid]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertSlice<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertSquareA13Minus]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertSquareA14Plus]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertSqueeze<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertState]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertStridedSlice<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertTensorBufferPatternToFusionOp]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertTranspose<mlir::anec::Family::A18>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeCollapseOfExpandOp<mlir::memref::CollapseShapeOp, mlir::memref::ExpandShapeOp, mlir::memref::CastOp, mlir::memref::DimOp, mlir::MemRefType>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeCollapseOfExpandOp<mlir::tensor::CollapseShapeOp, mlir::tensor::ExpandShapeOp, mlir::tensor::CastOp, mlir::tensor::DimOp, mlir::RankedTensorType>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeReassociativeReshapeOps<mlir::memref::CollapseShapeOp, mlir::ReshapeOpKind::kCollapse>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeReassociativeReshapeOps<mlir::memref::ExpandShapeOp, mlir::ReshapeOpKind::kExpand>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeReassociativeReshapeOps<mlir::tensor::CollapseShapeOp, mlir::ReshapeOpKind::kCollapse>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeReassociativeReshapeOps<mlir::tensor::ExpandShapeOp, mlir::ReshapeOpKind::kExpand>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ConvertToLLVMPatternInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::DialectResourceBlobHandle<mlir::ODIE::Compiler::CoreML::CoreMLDialect>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferShapedTypeOpInterface::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::InferShapedTypeOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ConditionallyFoldable::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ConditionallyFoldable]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ExternAttr]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ImportableOpInterface::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ImportableOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::KernelTypeInference::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::KernelTypeInference]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ParamDeclArrayAttr]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ParamScopeOpInterface::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ParamScopeOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ReplaceBroadcastToWithBroadcastInDims]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ReplaceWithOneBlock]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ReplaceWithReshape<mlir::ODIE::Compiler::CoreML::ExpandDimsOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ReplaceWithReshape<mlir::ODIE::Compiler::CoreML::ShrinkDimsOp>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::CallOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ClassOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ConstantOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::DeinitDelegateOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::DelegateOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ErrorOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::FuncOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::GraphOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ImportOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::InitDelegateOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::InvokeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::IsolatedGroupOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::MemberOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ModuleOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::PlaceholderOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::KeywordPrintableAttr::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::KeywordPrintableAttr]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::ODIXSerializableAttr::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::ODIXSerializableAttr]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::ParamAttrInterface::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ODIE::Compiler::ParamAttrInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParallelRegion<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::ODIE::Compiler::CoreML::ClassOp>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::ODIE::Compiler::CoreML::FuncOp>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::ODIE::Compiler::CoreML::GraphOp>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::ODIE::Compiler::CoreML::WhileOp>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::mpsx::MemrefBackedOp>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::scf::ExecuteRegionOp, mlir::scf::ForOp, mlir::scf::IfOp, mlir::scf::IndexSwitchOp, mlir::scf::WhileOp>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::NOperands<6>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::NOperands<7>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::ODIE::Compiler::CoreML::KernelNotImplemented<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::ODIE::Compiler::CoreML::TokenType>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::SingleBlockImplicitTerminator<mlir::ODIE::Compiler::CoreML::YieldOp>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::SingleBlockImplicitTerminator<mlir::scf::ReduceOp>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::VariadicRegions<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::anec::MinimumFamily<mlir::anec::Family::A18>::Impl<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::RuntimeVerifiableOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::SelectLikeOpInterface::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::SelectLikeOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::SubsetExtractionOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::SubsetInsertionOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::SubsetOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::TilingInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ValueBoundsOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ValueSemantics<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::VerifiableTensorEncoding::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::anec::(anonymous namespace)::CanonicalizePlacementRegionEnter]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::anec::(anonymous namespace)::CanonicalizePlacementRegionExit]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::ArithIntegerOverflowFlagsInterface::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::ArithIntegerOverflowFlagsInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::ArithRoundingModeInterface::Trait<Empty>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::ArithRoundingModeInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::IntegerOverflowFlagsAttr]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::RoundingModeAttr]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::detail::AddIOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::detail::ExtFOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::detail::MulIOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::detail::ShLIOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::detail::SubIOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::arith::detail::TruncFOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::bufferization::AllocationOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::bufferization::BufferDeallocationOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::bufferization::BufferizableOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::detail::DenseArrayAttrImpl<int8_t>]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::CanonicalizeQuantizedConvPatternToFusionOp]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::CanonicalizeReadStateTensorBuffer]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::CanonicalizeTensorBuffer]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::CanonicalizeWriteStateTensorBuffer]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::ConvertOperation]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::ReshapeSDPAReshape]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::SpaceToBatchDWConvBatchToSpace]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::pdl_to_pdl_interp::ConstraintPosition]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::tensor::detail::ConcatOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::transform::FindPayloadReplacementOpInterface]"
+ "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ub::PoisonAttrInterface::Trait<Empty>]"
+ "Structured control flow ops `for` and `while` and Conv ops are not yet supported."
+ "Sum of split sizes ("
+ "SumSquare"
+ "Symbol"
+ "T@\"MPSGraphExecutableEntryPointToSymbolAndFileNameMap\",&,V_perEntryPointToSymbolAndFileNameMap"
+ "T@\"NSArray\",R,V_inputTypes"
+ "T@\"NSArray\",R,V_shapedInputTypes"
+ "T@\"NSDictionary\",R,V_perEntryPointMap"
+ "T@\"NSString\",R,V_entryFunctionName"
+ "TB,N,V_enableANECValidationWorkflow"
+ "TB,V_isCoreMLBytecode"
+ "TQ,N,V_layoutConversionPassConfig"
+ "TQ,V_reducedPrecisionFastMath"
+ "Tensor size on reduction axis ("
+ "TensorBufferOps"
+ "Terminator is expected to be mpsx::UseMemrefOp."
+ "The delegate ID to segment to."
+ "The directory of the input files."
+ "The input of tensor_buffer_to_tensor must be a block argument"
+ "The optimizer pipeline used for callables that do not have a dedicated optimizer pipeline in opPipelineList"
+ "The output of tensor_to_tensor_buffer must be a region return"
+ "The type of conversion to perform on the data inputs to operations in a model (default unchanged)."
+ "The type of conversion to perform on the weights inputs to operations in a model (default unchanged)."
+ "Transform CoreML ops to MPS ops"
+ "Trying to execute procedure which was not compiled"
+ "Type mismatch (getDimSize) in UseMemrefOp vs corresponding MemrefBackedOp"
+ "Type mismatch (getElementType) in UseMemrefOp vs corresponding MemrefBackedOp"
+ "Type mismatch (hasRank) in UseMemrefOp vs corresponding MemrefBackedOp"
+ "Type mismatch (hasStaticShape) in UseMemrefOp vs corresponding MemrefBackedOp"
+ "UInt16 so that it could be supported on ANE."
+ "UInt32"
+ "UInt64"
+ "UUID"
+ "UUIDString"
+ "Ua9enable_ifI"
+ "Unable to determine A11/A12 Broadcast."
+ "Unable to find the corresponding op id from "
+ "Unable to get input data type"
+ "Unable to get input shape type"
+ "Unable to get output data type"
+ "Unable to get output shape type"
+ "Unable to get output tensor with MemRefType"
+ "Unable to get palettized kernel format and mode"
+ "Unable to get the GOC constant value. Only integer or float element type are allowed"
+ "Unexpected codepath for fusion op"
+ "Unhandled MPS layout. Acceptable layouts are: HW, CHW, HWC, NCHW, NHWC"
+ "Unranked input types or dynamic shapes are not supported on ANEs"
+ "Unsupported A11/A12 Broadcast."
+ "Unsupported GOC scale/bias data type"
+ "Unsupported alignCorners, centerResult for Resize"
+ "Unsupported padding values for Conv2D"
+ "Unsupported padding values for Conv3D"
+ "Unsupported promoted rank."
+ "Unsupported state-wrapped type found"
+ "Unsupported weightsLayout for Conv2D"
+ "Unterminated brace sequence. Escape with {{ for a literal brace."
+ "Used In Cache"
+ "WeightFileProperties"
+ "WriteA18PlistPass"
+ "[shapedEntryPoints count] == cacheEntries.size()"
+ "] is "
+ "] is 0"
+ "] is expected to be "
+ "]>"
+ "^ios\\d+\\.quantize$"
+ "^v16@0:8"
+ "^v48@0:8@16^v24@32@40"
+ "^v60@0:8@16^v24@32@40B48r^v52"
+ "__init"
+ "_dims length must match the size of last dimension of indices"
+ "_disableQuantizedConvFusion"
+ "_enableANECValidationWorkflow"
+ "_enableQuantizedConvFusion"
+ "_forceTimingPasses"
+ "_funcNamesInOriginalModule"
+ "_inputTypes"
+ "_isChannelAndInterleaveSame"
+ "_isCoreMLBytecode"
+ "_isTensorBufferOp"
+ "_isTopLevelRuntime"
+ "_jsonSerializer"
+ "_layoutConversionPassConfig"
+ "_lazyCopyDataFiles"
+ "_lookupTable"
+ "_ml"
+ "_moduleCacheMutex"
+ "_mu"
+ "_optimizedModules"
+ "_optimizedNoDeviceModules"
+ "_perEntryFuncOpSymbolMap"
+ "_perEntryPointMap"
+ "_perEntryPointToSymbolAndFileNameMap"
+ "_perFuncOpANEFileSymbolsUsed"
+ "_reducedPrecisionFastMath"
+ "_runtimeCache"
+ "_runtimeCacheMutex"
+ "_shapedInputTypes"
+ "_specializedCompiledANEProduct"
+ "_specializedModule"
+ "_temporaryPackageFileLock"
+ "_vscale"
+ "_writingLockGuard"
+ "`basis` is not upper bound"
+ "`linear_index` is not loop induction variable"
+ "add-init-op-for-delegate"
+ "addDataFileNames:"
+ "affine map expect at least one result"
+ "aggressive"
+ "allValues"
+ "allocateTensorDataTargetsForDevice:shapedEntryPoint:"
+ "aneInfo->aneRegionCallOpHandler"
+ "ane_family"
+ "anec.A18"
+ "anec.layer_norm"
+ "anec.resample"
+ "anec.ring_buffer_reader"
+ "anec.ring_buffer_writer"
+ "anec.scaled_elementwise"
+ "anec.state"
+ "anec.tensor_buffer_to_tensor"
+ "anec.tensor_to_tensor_buffer"
+ "appendString:"
+ "applyEntryPointToSymbolAndFileNameMap:device:compilationDescriptor:"
+ "applyInputTypes:toFunction:"
+ "applyOptimizationPassesWithDevice:module:compilationID:compilationDescriptor:"
+ "applyOptionsToEntryPoint:compilationDescriptor:"
+ "arith.fastmath"
+ "arith.overflow"
+ "as"
+ "async.value"
+ "bitWidth < 8"
+ "bufferToTensorWithTensor:name:"
+ "bufferToTensorWithTensor:shape:type:interleave:isTensorBufferOp:isChannelAndInterleaveSame:name:"
+ "buffer_ptr == buffer_end"
+ "builtin.affine_map"
+ "builtin.array"
+ "builtin.bf16"
+ "builtin.call_site_loc"
+ "builtin.complex"
+ "builtin.dense_array"
+ "builtin.dense_int_or_fp_elements"
+ "builtin.dense_resource_elements"
+ "builtin.dense_string_elements"
+ "builtin.dictionary"
+ "builtin.distinct"
+ "builtin.f128"
+ "builtin.f16"
+ "builtin.f32"
+ "builtin.f4E2M1FN"
+ "builtin.f64"
+ "builtin.f6E2M3FN"
+ "builtin.f6E3M2FN"
+ "builtin.f80"
+ "builtin.f8E3M4"
+ "builtin.f8E4M3"
+ "builtin.f8E4M3B11FNUZ"
+ "builtin.f8E4M3FN"
+ "builtin.f8E4M3FNUZ"
+ "builtin.f8E5M2"
+ "builtin.f8E5M2FNUZ"
+ "builtin.file_line_loc"
+ "builtin.float"
+ "builtin.function"
+ "builtin.fused_loc"
+ "builtin.index"
+ "builtin.integer"
+ "builtin.integer_set"
+ "builtin.memref"
+ "builtin.name_loc"
+ "builtin.none"
+ "builtin.opaque"
+ "builtin.opaque_loc"
+ "builtin.sparse_elements"
+ "builtin.strided_layout"
+ "builtin.string"
+ "builtin.symbol_ref"
+ "builtin.tensor"
+ "builtin.tf32"
+ "builtin.tuple"
+ "builtin.type"
+ "builtin.unit"
+ "builtin.unknown_loc"
+ "builtin.unranked_memref"
+ "builtin.unranked_tensor"
+ "builtin.vector"
+ "cacheEntries.size()"
+ "cacheEntries.size() == 1"
+ "calcStrides MemRef rank should not be 0"
+ "calling function here with specialized signature "
+ "cannot fold PadOps with different or non-constant padding values"
+ "casted_input"
+ "casted_min"
+ "casted_scale"
+ "casted_zeroPoint"
+ "centered"
+ "channels-first"
+ "channels-last"
+ "checkSpecializationValidForSingleEntry"
+ "codeSnippet"
+ "command line argument"
+ "complex.number"
+ "complexTy && isa<FloatType>(complexTy.getElementType()) && \"must be a complex float attr\""
+ "componentsJoinedByString:"
+ "concat"
+ "concatenation dim must be less than the tensor rank"
+ "constExpr is not natievly supported and has mutable attributes"
+ "content"
+ "coordinate_type"
+ "copyDataFiles:currentBasePath:location:"
+ "copyFrom"
+ "coreMLBytecode"
+ "coreMLDirectory"
+ "coreml"
+ "coreml-to-mps"
+ "coreml.add"
+ "coreml.all"
+ "coreml.and"
+ "coreml.any"
+ "coreml.array"
+ "coreml.async.await"
+ "coreml.async.value"
+ "coreml.avg_pool_2d"
+ "coreml.batch_matmul"
+ "coreml.batchnorm"
+ "coreml.broadcast_in_dims"
+ "coreml.broadcast_shapes"
+ "coreml.broadcast_to"
+ "coreml.cast"
+ "coreml.concat"
+ "coreml.condition"
+ "coreml.constant"
+ "coreml.conv2d"
+ "coreml.cos"
+ "coreml.create_complex"
+ "coreml.create_token"
+ "coreml.deinit_delegate"
+ "coreml.delegate"
+ "coreml.divide"
+ "coreml.equal"
+ "coreml.error"
+ "coreml.exp"
+ "coreml.expand_dims"
+ "coreml.extern"
+ "coreml.file_resource"
+ "coreml.fill"
+ "coreml.floor_divide"
+ "coreml.gather_nd"
+ "coreml.gelu"
+ "coreml.get_shape"
+ "coreml.graph"
+ "coreml.greater"
+ "coreml.handle"
+ "coreml.if"
+ "coreml.imaginary_part"
+ "coreml.import"
+ "coreml.init_delegate"
+ "coreml.intent"
+ "coreml.invoke"
+ "coreml.isolated_group"
+ "coreml.join_token"
+ "coreml.llo.call"
+ "coreml.llo.class"
+ "coreml.llo.func"
+ "coreml.llo.member"
+ "coreml.llo.placeholder"
+ "coreml.llo.return"
+ "coreml.log"
+ "coreml.max_pool_2d"
+ "coreml.maximum"
+ "coreml.minimum"
+ "coreml.module"
+ "coreml.modulo"
+ "coreml.mul"
+ "coreml.not"
+ "coreml.not_equal"
+ "coreml.odie_location_frame_attr"
+ "coreml.opaque"
+ "coreml.or"
+ "coreml.output"
+ "coreml.param.bind"
+ "coreml.param.constant"
+ "coreml.param.decl"
+ "coreml.param.decl.array"
+ "coreml.param.ref"
+ "coreml.param_ref"
+ "coreml.pow"
+ "coreml.range"
+ "coreml.read_handle"
+ "coreml.real_part"
+ "coreml.reduce_max"
+ "coreml.reduce_mean"
+ "coreml.reduce_sum"
+ "coreml.relu"
+ "coreml.reshape"
+ "coreml.rsqrt"
+ "coreml.scatter_nd"
+ "coreml.select"
+ "coreml.shrink_dims"
+ "coreml.sigmoid"
+ "coreml.silu"
+ "coreml.sin"
+ "coreml.slice"
+ "coreml.slice_update"
+ "coreml.softmax"
+ "coreml.split"
+ "coreml.sqrt"
+ "coreml.stack"
+ "coreml.sub"
+ "coreml.symbol"
+ "coreml.symbol_ref"
+ "coreml.tanh"
+ "coreml.tensor_encoding"
+ "coreml.tile"
+ "coreml.token"
+ "coreml.torch_location_extras"
+ "coreml.transform.cast"
+ "coreml.transpose"
+ "coreml.type"
+ "coreml.where"
+ "coreml.while"
+ "coreml.write_handle"
+ "coreml.yield"
+ "could not copy file at path "
+ "could not copy from "
+ "could not detect reshape->sdpa->reshape op pattern"
+ "could not detect s2b->dwConv->b2s op pattern"
+ "could not find file at path "
+ "could not resolve the callee to a `coreml.graph` or a `coreml.import`"
+ "could not resolve the callee to a `coreml.llo.func` or a `coreml.import`"
+ "createMetalPackageAtURL:descriptor:"
+ "createToPerEntryFuncOpSymbolMap"
+ "current-base-path"
+ "data type expected to be "
+ "data-conversion-type"
+ "debug-counter-break-on-last"
+ "default value type and member type must match"
+ "deinit_fn"
+ "delegate-id"
+ "delegate_id"
+ "delegate_resources_path"
+ "deviceCacheKeys.size() == [transformedEntryPoints count]"
+ "deviceCacheKeysSet.size() == perEntryPointFuncOpMLIRName.size()"
+ "dialect "
+ "dilation must be > 0"
+ "dim.getIndex does not dominate reshape."
+ "dim.getIndex is not defined before reshape in the same block."
+ "dims rank must be 1"
+ "disabled"
+ "does not match inferred shape "
+ "downward"
+ "dst index must be a valid dimension or symbol identifier"
+ "empty"
+ "enable-afm-mlir-features"
+ "enable-quantized-conv-fusion"
+ "enableANECValidationWorkflow"
+ "enableLayoutConversion:dataChannelsLast:weightsChannelsLast:"
+ "encoding dimension order should be permutation of the shape."
+ "encoding rank is different than tensor shape."
+ "entities 'kernel_palettized_LUT' failed to satisfy constraint: 'is nullptr'"
+ "entry-points"
+ "entryFuncOp"
+ "entryFuncOps.size() == 1"
+ "evaluateOps"
+ "exceeds the maximum value of UInt16 ("
+ "expect exactly two elements for "
+ "expect two elements in dilation"
+ "expect two elements in padding"
+ "expect two elements in strides"
+ "expected a ShapedType for all inputs to concat"
+ "expected a callee expression of type `symbol`"
+ "expected a parameter attribute if the callee is not resolved"
+ "expected a parameter expression of type `symbol`"
+ "expected a parameter expression of type `type`"
+ "expected a result of type "
+ "expected a single axis, but found "
+ "expected a single dimension along which to concat"
+ "expected a single operand of type `!coreml.async.value`"
+ "expected a size expression of any integer type, got "
+ "expected all input shapes to match along all dimensions other than the concat dimension"
+ "expected all input tensors to have the same rank"
+ "expected an argument of type "
+ "expected an element type expression of type `type`, got "
+ "expected collapsed rank ("
+ "expected exactly 1 operand"
+ "expected exactly 2 operands"
+ "expected input token '"
+ "expected no operands"
+ "expected number of static shape bounds to be equal to the output rank ("
+ "expected number of static shape dims to be equal to the output rank ("
+ "expected one axis only."
+ "expected operand to be ranked tensor"
+ "expected the 'coreml.output' terminator"
+ "expected the expanded type, "
+ "expected the same element type for all inputs to concat"
+ "expected the type of the callee: "
+ "expected two block arguments with type "
+ "expected type "
+ "expected valid keyword or string"
+ "expected valid symbol name."
+ "expects body to terminate with 'scf.reduce'"
+ "expects type of "
+ "extern"
+ "externAttr"
+ "externalize"
+ "f4E2M1FN"
+ "f6E2M3FN"
+ "f6E3M2FN"
+ "f8E3M4"
+ "f8E4M3"
+ "failed to copy files"
+ "failed to create GOC constants out of scalar values."
+ "failed to create link "
+ "failed to create unique file "
+ "failed to downgrade: requested target version is {0}, but 3-bit palettization is only supported from version {1}"
+ "failed to downgrade: requested target version is {0}, but 6-bit palettization is only supported from version {1}"
+ "failed to downgrade: requested target version is {0}, but uint3 data is only supported from version {1}"
+ "failed to downgrade: requested target version is {0}, but uint6 data is only supported from version {1}"
+ "failed to legalize unresolved materialization from ("
+ "failed to obtain absolute path for "
+ "failed to open file "
+ "failed to parse Arith_IntegerOverflowAttr parameter 'value' which is to be a `::mlir::arith::IntegerOverflowFlags`"
+ "failed to parse COREML_AsyncValueType parameter 'innerType' which is to be a `::mlir::Type`"
+ "failed to parse COREML_ExternAttr parameter 'library' which is to be a `::llvm::StringRef`"
+ "failed to parse COREML_FileResourceElementsAttr parameter 'rawHandle' which is to be a `CoreDialectResourceBlobHandle`"
+ "failed to parse COREML_HandleType parameter 'innerType' which is to be a `::mlir::Type`"
+ "failed to parse COREML_IntentAttr parameter 'value' which is to be a `mlir::ODIE::Compiler::CoreML::Intent`"
+ "failed to parse COREML_ODIELocationFrameAttr parameter 'codeSnippet' which is to be a `StringAttr`"
+ "failed to parse COREML_ODIELocationFrameAttr parameter 'frontendAttribute' which is to be a `std::optional<::mlir::ODIE::Compiler::ODIXSerializableAttr>`"
+ "failed to parse COREML_ODIELocationFrameAttr parameter 'method' which is to be a `StringAttr`"
+ "failed to parse COREML_ParamRefType parameter 'param' which is to be a `TypedAttr`"
+ "failed to parse COREML_TorchLocationExtrasAttr parameter 'stackTrace' which is to be a `::llvm::ArrayRef<StringAttr>`"
+ "failed to parse CoreMLTensorEncodingAttr parameter 'dimsOrdering' which is to be a `::llvm::ArrayRef<int32_t>`"
+ "failed to parse ParamDeclArrayAttr parameter 'value' which is to be a `::llvm::ArrayRef<ParamDeclAttr>`"
+ "failed to parse the attribute dictionary"
+ "failed to parse the body region"
+ "failed to parse the function signature"
+ "failed to read version int"
+ "failed to remove lockfile "
+ "failed to satisfy constraint: dequantize has 0D / 1D parameters"
+ "failed to verify 'elementType': integer or index or floating-point"
+ "failed to verify that Operands should have same element type."
+ "failed to verify that Operands should have same shape."
+ "failed to verify that Operation must have at least two operands."
+ "failed to verify that Result 0 and operand 0 must have the same inner element type."
+ "failed to verify that Result 0 and operand 0 must have the same rank."
+ "failed to verify that Result 0 and operand 0 must have the same shape."
+ "failed to verify that Result 0 and operand 4 must have the same rank."
+ "failed to verify that Result 0 element type must match element type of operand 0."
+ "failed to verify that Result 0 element type must match element type of operand 1."
+ "failed to verify that Result 0 element type must match element type of operand 2."
+ "failed to verify that Result 0 element type must match element type of operand 4."
+ "failed to verify that condition is signless i1 or has matching shape"
+ "failed to verify that input and output have the same tensor dimensions"
+ "failed to verify that input token must come from an operation on the same handle"
+ "failed to verify that number of dims >=2 and last dim of operand 0 equals second last dim of operand 1"
+ "failed to verify that number of handle inputs must match number of token outputs"
+ "failed to write to "
+ "failed: Canonicalized varFromTensor op not found"
+ "failed: ConvertBinaryCompare expects the second operand to be non-zero."
+ "failed: ConvertBinaryCompareToZero expects the second operand to be zero."
+ "failed: Could not extract valid positive and rank-promoted axes."
+ "failed: Dequantize cannot be converted to N-D since input rank is unknown"
+ "failed: DequantizeND with dynamic shapes not supported"
+ "failed: F32 I/Os not supported for this ANE architecture"
+ "failed: Flatten2DOp axis argument was not a constant."
+ "failed: NonZeroOp is currently supported with ranked inputs only."
+ "failed: Original buffer 2 tensor op not found"
+ "failed: Original tensor 2 buffer op not found"
+ "failed: POOLING_TRANSFORM macro is undefined. Ensure it is defined to support mps.pool op for ANE."
+ "failed: Permute can be lowered to Transpose only if indices argument is a constant"
+ "failed: Placement while entering a region did not match"
+ "failed: Reshape target shape must be NxCx1x1 to be lowered as Flatten on ANEs."
+ "failed: State read tensor buffer pattern did not match"
+ "failed: State write tensor buffer pattern did not match"
+ "failed: TensorBuffer pattern did not match"
+ "failed: amount_before value {0} and amount_after value {1} do not fit dimension size ({2})"
+ "failed: bufferToTensor op needs to have shape attribute"
+ "failed: can not retrieve source op ids"
+ "failed: can not retrive the offset info."
+ "failed: can only support divide by a constant on A11/A12 class ANEs"
+ "failed: cannot handle a non constant amount_after value on ANEs."
+ "failed: cannot handle a non constant amount_before value on ANEs."
+ "failed: cannot handle a non constant length value on ANEs."
+ "failed: cannot handle a non constant start value on ANEs."
+ "failed: cannot handle a non-constant axis on ANEs."
+ "failed: cannot reshape a non-constant quantized value"
+ "failed: could not extract positive axes"
+ "failed: gather with non-constant axis is not supported on ANEs."
+ "failed: invalid begin and end values based on stride direction."
+ "failed: invalid begin and/or end values of strided slice op."
+ "failed: multiplier numbers must be greater than 3"
+ "failed: only 2-bit, 4-bit, and 8-bit palettization is supported"
+ "failed: only DequantizeLUT with constant operands is supported"
+ "failed: only constant axes are supported on ANEs."
+ "failed: only constant multipliers are supported on ANEs."
+ "failed: only scalar boolean conditionals are valid"
+ "failed: operation is not defined with constant axes and cannot be lowered on ANEs"
+ "failed: output shape requires a reshape, but the op is not available on A12/A13-class ANEs."
+ "failed: state must come from function block arguments."
+ "failed: stride must have non-zero value"
+ "failed: tensor buffer with custom layout is not supported."
+ "failed: the stride should be 1 for slice update on ANE."
+ "failed: the stride should be 1 for strided slice on ANE."
+ "file at path "
+ "filePath.size()"
+ "file_resource"
+ "from"
+ "frontendAttribute"
+ "functionNames"
+ "getArgAttrDict"
+ "getCompiledANEProduct"
+ "getDefaultEntryPointWithShapes:"
+ "getDeviceCacheKeyForEntryPoint:device:compilationDescriptor:"
+ "getDeviceCacheKeyForTransformedEntryPoint:device:compilationDescriptor:"
+ "getInitializedCoreMLBytecode"
+ "getInitializedCoreMLBytecodeWithPayloadPrefix:delegateId:"
+ "getInputShapesForFuncOp:"
+ "getInputShapesForFunction:"
+ "getJsonData"
+ "getMpsgraphPackageName"
+ "getNewRuntimeForDevice:specializedModule:shapedEntryPoints:compilationDescriptor:"
+ "getNewRuntimeForDevice:specializedModule:shapedEntryPoints:compilationDescriptor:fallingBack:fallbackRuntimeKey:"
+ "getNumBuckets() == other.getNumBuckets()"
+ "getOptimizedModules"
+ "getOptimizedModulesSize"
+ "getOptimizedNoDeviceModules"
+ "getOptimizedNoDeviceModulesSize"
+ "getOrCreateSpecializationForMap:perEntryFuncOpSymbolMap:"
+ "getOutputShapesForFuncOp:"
+ "getOutputShapesForFunction:"
+ "getOutputTypesWithDevice:entryPoint:compilationDescriptor:"
+ "getOutputTypesWithDevice:shapedEntryPoint:compilationDescriptor:"
+ "getProcedureInfo"
+ "getResultAttrDict"
+ "getSegmentedCoreMLBytecode"
+ "getSegmentedCoreMLBytecodeWithDelegateId:"
+ "getSpecializationOrNilForMap:"
+ "getSpecializedModule"
+ "getSymbolMapForCurrentEntryPoint"
+ "getTensorDataArraysWithDevice:feedsDictionary:resultsDictionary:inputsArray:resultsArray:executableExecutionDescriptor:"
+ "graphs do not allow the default symbol visibility attr"
+ "graphs marked 'externalize' must not be private"
+ "group"
+ "h18"
+ "has source rank "
+ "hash_combine_range_impl"
+ "iOS18.4.0"
+ "idx < size() && \"index out of bounds\""
+ "incorrect number of indices for load, expected "
+ "index < (*static_cast<ConcreteOp *>(this)).getNumArguments() && \"invalid argument number\""
+ "index < (*static_cast<ConcreteOp *>(this)).getNumResults() && \"invalid result number\""
+ "index must be a valid dimension or symbol identifier"
+ "inf"
+ "inferred return types did not match actual return types"
+ "initWithCoreMLBytecode:coreMLDirectory:"
+ "initWithDevice:ndArrayConvolution2DDescriptor:dataQuantizationDescriptor:weightsQuantizationDescriptor:"
+ "initWithEntryFunctionName:inputTypes:"
+ "initWithGraph:inputTensors:controlDependencies:shape:type:interleave:isTensorBufferOp:isChannelAndInterleaveSame:name:"
+ "initWithMLIRCoreML:executableDescriptor:error:"
+ "initWithPackageURL:temporaryPackageURL:"
+ "initWithPerEntryFuncOpSymbolMap:perFuncOpANEFileSymbolsUsed:runtime:"
+ "initWithPerEntryPointMap:"
+ "initWithRuntime:"
+ "initWithUTF8String:"
+ "init_fn"
+ "inlining-threshold"
+ "innermost dimension of indices "
+ "inout"
+ "input rank is "
+ "input rank must be >= 1"
+ "input/output rank must be >= 1"
+ "input2"
+ "inputNamesForFuncOp:"
+ "inputNamesForFunction:"
+ "inputTypes"
+ "inputs and result element type must match"
+ "intent"
+ "intializing scalable vectors with elements attribute is not supported unless it's a vector splat"
+ "invalid kind of Type specified"
+ "invalid output shape provided at pos "
+ "invalid tile factor or output size provided. Only full tiles are supported when padding_value is not set"
+ "is a native dequantize type supported by MPS"
+ "is not supported for A13 and below"
+ "isChannelAndInterleaveSame"
+ "isCoreMLBytecode"
+ "isEqualToArray:"
+ "isEqualToDictionary:"
+ "isEqualToEntryPoint:"
+ "isEqualToPerEntryPointMap:"
+ "isSingleEntry"
+ "isTensorBufferOp"
+ "is_dynamic_offsets"
+ "kCFAllocatorNull"
+ "kernel_palettized_LUT"
+ "l2_pool"
+ "layoutConversionPassConfig"
+ "library.mpsgraphpackage"
+ "live_in_params%d"
+ "llvm::divideCeil(numElements * bitWidth, 8) == inData.size()"
+ "loadModelNewInstance:options:modelInstParams:qos:error:"
+ "lockPath"
+ "loop lower bound is not zero"
+ "loop step is not one"
+ "macOS15.4.0"
+ "major"
+ "manifest.json"
+ "max-reordering-distance"
+ "memref-region"
+ "message"
+ "metadata-byte-array"
+ "method"
+ "min_add"
+ "minor"
+ "mismatch in dynamic dims in output_shape and static_output_shape: static_output_shape has "
+ "mismatch in result shape and permutation. resultShape["
+ "mismatch in slice shape. Expected shape: "
+ "mlir-print-skip-regions"
+ "mlir-print-unique-ssa-ids"
+ "mlir::ODIE::Compiler::CoreML::Intent"
+ "modelWithCacheURLIdentifier:"
+ "mps ops with unranked output types or dynamic shapes are not supported on ANEs"
+ "mps-convert-f32-to-f16"
+ "mps-copy-data-files"
+ "mps-layout-conversion"
+ "mps-reorder-operations"
+ "mps-unreachable-function-removal"
+ "mps.buffer_tensor"
+ "mps.call_inline_mode"
+ "mps.crop_resize_alignment_mode"
+ "mps.crop_resize_coordinate_mode"
+ "mps.device_hint"
+ "mps.enableANECValidationWorkflow"
+ "mps.fft_scaling_mode"
+ "mps.gru_gate_layout"
+ "mps.lstm_gate_layout"
+ "mps.nearest_rounding_mode"
+ "mps.nf4"
+ "mps.padding_mode"
+ "mps.padding_style"
+ "mps.pooling_indices_mode"
+ "mps.pruning_metric"
+ "mps.pruning_structure"
+ "mps.random_normal_sampling_method"
+ "mps.reducedPrecisionFastMath"
+ "mps.reduction_mode"
+ "mps.rnn_activation"
+ "mps.sampling_mode"
+ "mps.scatter_mode"
+ "mps.similarity_type"
+ "mps.sparse_tensor_storage"
+ "mps.stencil_padding_mode"
+ "mps.tensor_data_layout"
+ "mps.texture_tensor_pixel_format"
+ "mpsExecutable.mpsgraphpackage"
+ "mpsgraphPackageName"
+ "mpspkgname"
+ "mpsx.buffer_to_tensor"
+ "mpsx.fusion_type"
+ "mpsx.list_type"
+ "mpsx.memref_backed"
+ "mpsx.quantized_conv2d"
+ "mpsx.tensor_to_buffer"
+ "mpsx.use_memref"
+ "mpsx::ListType for operands is not yet supported."
+ "mpsx::ListType for results is not yet supported."
+ "mtlpackage"
+ "mul"
+ "must have type "
+ "negate_src1"
+ "negate_src2"
+ "network should not be nullptr"
+ "new-base-path"
+ "newBasePath has not been set"
+ "no value attribute provided"
+ "no_inline"
+ "noinline"
+ "non-concatenated dimension "
+ "non-fusion op should only have 1 op ID"
+ "non-private graphs must have a body"
+ "normal"
+ "nsw"
+ "number of dims must match, got "
+ "number of elements in dims must be equal to input rank"
+ "number of handle inputs must match number of token outputs"
+ "nuw"
+ "odie_location_frame_attr"
+ "only contiguous layout is supported"
+ "only handling rank 4 or 5 input"
+ "only supporting NCHW in Depth <-> Space -> Channel <-> Space"
+ "opaque"
+ "operand 0 of native code call '::mlir::success(::mlir::matchPattern($_self->getResult(0), ::mlir::m_Constant(&$0)))' failed to satisfy constraint: 'constant attribute 0'"
+ "opname"
+ "optimizedModuleWithSignature:"
+ "optimizedNoDeviceModuleWithSignature:"
+ "out"
+ "out_token"
+ "output rank is "
+ "output shape["
+ "output type expected to be "
+ "outputNamesForFuncOp:"
+ "outputNamesForFunction:"
+ "outputPath.size()"
+ "overflowFlags"
+ "pad"
+ "pad_type"
+ "padding must be <= kernel_size / 2"
+ "padding must be >= 0"
+ "param.bind"
+ "param.constant"
+ "param.decl"
+ "param.decl.array"
+ "param.ref"
+ "param_decls"
+ "param_ref"
+ "patch"
+ "payload-prefix"
+ "pdl.value"
+ "perEntryPointFuncOpMLIRName.size() == 1"
+ "perEntryPointMap"
+ "perEntryPointToSymbolAndFileNameMap"
+ "perEntryPointTypes.size() == perEntryPointFuncOpMLIRName.size()"
+ "permutation must only hold values between 0 and "
+ "pkgtype"
+ "placement.region_type"
+ "placement.timer"
+ "poison"
+ "postHandlerCreationInit"
+ "pre_scale"
+ "priv"
+ "procedureDataWithSymbol:weightArray:"
+ "producer is not a foldable tensor.pad op"
+ "r"
+ "rank of concatenated inputs must match result rank"
+ "reducedPrecisionFastMath"
+ "reduction bodies must be terminated with an 'scf.reduce.return' op"
+ "removeObjectForKey:"
+ "removeSpecializationForMap:"
+ "replace graph body with delegate call payload"
+ "replace-graph-body-with-delegate-call"
+ "replaceItemAtURL:withItemAtURL:backupItemName:options:resultingItemURL:error:"
+ "requires at least one input"
+ "requires attribute 'ane_family'"
+ "requires attribute 'coordinate_type'"
+ "requires attribute 'delegate_id'"
+ "requires attribute 'delegate_resources_path'"
+ "requires attribute 'dim'"
+ "requires attribute 'interleave'"
+ "requires attribute 'is_dynamic_offsets'"
+ "requires attribute 'message'"
+ "requires attribute 'offsets'"
+ "requires attribute 'opname'"
+ "requires attribute 'param_decls'"
+ "requires attribute 'resource'"
+ "requires attribute 'slice_size'"
+ "requires attribute 'static_output_shape'"
+ "requires attribute 'toImport'"
+ "requires attribute 'warp_coordinate_mode'"
+ "requires attribute's elements to be float or integer attributes"
+ "requires that either input or output has a complex type"
+ "ret.second"
+ "return"
+ "returning an operation from a constraint is not supported"
+ "roundingmode"
+ "roundingmode attribute specification: \""
+ "runtime"
+ "safeTransforms"
+ "same"
+ "same_lower"
+ "scaled"
+ "segment-all-ops-to-delegate"
+ "setEnableANECValidationWorkflow:"
+ "setIsCoreMLBytecode:"
+ "setLayoutConversionPassConfig:"
+ "setOptimizedModule:withSignature:"
+ "setOptimizedNoDeviceModule:withSignature:"
+ "setPerEntryPointToSymbolAndFileNameMap:"
+ "setReducedPrecisionFastMath:"
+ "set_allocation_range"
+ "shape for result is not static"
+ "shapedInputTypes"
+ "skipping unfoldable pad"
+ "slice_size"
+ "so the 32 bit output type could not be safely converted to "
+ "sortedArrayUsingSelector:"
+ "source-directory"
+ "specializeWithDevice:entryPoints:compilationDescriptor:"
+ "specializeWithDevice:shapedEntryPoint:compilationDescriptor:"
+ "specializeWithDevice:shapedEntryPoints:compilationDescriptor:"
+ "specializedModuleForRuntime"
+ "specializedModuleWithDevice:shapedEntryPoints:compilationDescriptor:fallingBack:fallbackRuntimeKey:"
+ "src index must be a valid dimension or symbol identifier"
+ "stack trace must not be empty"
+ "state == llvm::LockFileManager::LFS_Shared"
+ "static concatenation size mismatch along "
+ "static_output_shape"
+ "stride["
+ "strongToStrongObjectsMapTable"
+ "subcommand"
+ "symbol's parent must have the SymbolTable trait"
+ "symbol_ref"
+ "tag index must be a valid dimension or symbol identifier"
+ "temporary.metalpackage"
+ "tensor.concat"
+ "tensorToBufferWithTensor:name:"
+ "tensorToBufferWithTensor:shape:type:interleave:isTensorBufferOp:isChannelAndInterleaveSame:name:"
+ "tensor_encoding"
+ "than the collapsed type, "
+ "thread constructor failed"
+ "to MaxPool, AveragePool or Conv for A13 and below on ane is not supported"
+ "toImport"
+ "to_nearest_away"
+ "to_nearest_even"
+ "token"
+ "torch_location_extras"
+ "toward_zero"
+ "try_emplace_with_hash"
+ "tvOS18.4.0"
+ "ub"
+ "unable to convert type for "
+ "unchanged"
+ "unknown error"
+ "unloadEntryPointToSymbolAndFileNameMap:device:compilationDescriptor:"
+ "unloadModel"
+ "updates rank is "
+ "updates shape["
+ "upward"
+ "useMemrefOp->getNumOperands() is expected to match memrefBackedBuffers.size()."
+ "v28@0:8B16B20B24"
+ "v32@0:8r^v16{FuncOp=^{Operation}}24"
+ "v32@?0@\"MPSGraphExecutableEntryPoint\"8Q16^B24"
+ "v32@?0@\"MPSGraphExecutableShapedEntryPoint\"8@\"NSDictionary\"16^B24"
+ "v48@0:8@16{ModuleOp=^{Operation}}24Q32@40"
+ "v48@0:8{ArrayRef<std::string>=^vQ}16@32{Location={LocationAttr=^{AttributeStorage}}}40"
+ "valid"
+ "vector elements must be int/index/float type but got "
+ "vector types must have positive constant sizes but got "
+ "version mismatch, and no upgrader defined"
+ "visionOS2.4.0"
+ "warp"
+ "warp_coordinate_mode"
+ "weight operand is not a constant!"
+ "weightWithSymbolAndURL:weightURL:"
+ "weights-conversion-type"
+ "withProcedureData:procedureArray:"
+ "write-A18-plist"
+ "{DenseMap<MPSGraphModuleKey, MPSGraphExecutableCacheValue, MPSGraphModuleKeyInfo, llvm::detail::DenseMapPair<MPSGraphModuleKey, MPSGraphExecutableCacheValue>>=\"Buckets\"^v\"NumEntries\"I\"NumTombstones\"I\"NumBuckets\"I}"
+ "{DenseMap<const MPSGraphExecutableSpecializedModule *, std::unique_ptr<RuntimeCacheEntry>, llvm::DenseMapInfo<const MPSGraphExecutableSpecializedModule *>, llvm::detail::DenseMapPair<const MPSGraphExecutableSpecializedModule *, std::unique_ptr<RuntimeCacheEntry>>>=\"Buckets\"^v\"NumEntries\"I\"NumTombstones\"I\"NumBuckets\"I}"
+ "{DenseMap<llvm::DenseSet<MPSGraphModuleKey, MPSGraphModuleKeyInfo>, std::unique_ptr<MPSGraphExecutableSpecializedModule>, MPSGraphModuleKeysSetInfo, llvm::detail::DenseMapPair<llvm::DenseSet<MPSGraphModuleKey, MPSGraphModuleKeyInfo>, std::unique_ptr<MPSGraphExecutableSpecializedModule>>>=\"Buckets\"^v\"NumEntries\"I\"NumTombstones\"I\"NumBuckets\"I}"
+ "{DenseMap<mlir::func::FuncOp, NSDictionary<NSString *,NSString *> *, llvm::DenseMapInfo<mlir::func::FuncOp>, llvm::detail::DenseMapPair<mlir::func::FuncOp, NSDictionary<NSString *,NSString *> *>>=\"Buckets\"^v\"NumEntries\"I\"NumTombstones\"I\"NumBuckets\"I}"
+ "{DenseMap<mlir::func::FuncOp, llvm::DenseMap<mlir::placement::RegionCall, llvm::StringSet<>>, llvm::DenseMapInfo<mlir::func::FuncOp>, llvm::detail::DenseMapPair<mlir::func::FuncOp, llvm::DenseMap<mlir::placement::RegionCall, llvm::StringSet<>>>>=\"Buckets\"^v\"NumEntries\"I\"NumTombstones\"I\"NumBuckets\"I}"
+ "{MPSGraphExecutableCacheValue=^{MPSGraphExecutableSpecializedModule}^{LazyLoadableModuleRef}{basic_string<char, std::char_traits<char>, std::allocator<char>>={__compressed_pair<std::basic_string<char>::__rep, std::allocator<char>>=(__rep={__short=[23c][0C]b7b1}{__long=*Qb63b1})}}}40@0:8@16@24@32"
+ "{MPSGraphModuleKey={SmallVector<long long, 6U>=^vII[48c]}@@@Q}40@0:8@16@24@32"
+ "{SmallVector<MPSGraphExecutableCacheValue, 1U>=^vII[40c]}52@0:8@16@24@32B40r^v44"
+ "{optional<std::unordered_set<std::string>>=\"\"(?=\"__null_state_\"c\"__val_\"{unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>=\"__table_\"{__hash_table<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string>>=\"__bucket_list_\"{unique_ptr<std::__hash_node_base<std::__hash_node<std::string, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>=\"__ptr_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>>=\"__value_\"^^v\"__value_\"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>=\"__data_\"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::string, void *> *> *>>=\"__value_\"Q}}}}\"__p1_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::string, void *> *>, std::allocator<std::__hash_node<std::string, void *>>>=\"__value_\"{__hash_node_base<std::__hash_node<std::string, void *> *>=\"__next_\"^v}}\"__p2_\"{__compressed_pair<unsigned long, std::hash<std::string>>=\"__value_\"Q}\"__p3_\"{__compressed_pair<float, std::equal_to<std::string>>=\"__value_\"f}}})\"__engaged_\"B}"
+ "{unique_ptr<GPU::ANECompilerHelper::CompiledProduct, std::default_delete<GPU::ANECompilerHelper::CompiledProduct>>=\"__ptr_\"{__compressed_pair<GPU::ANECompilerHelper::CompiledProduct *, std::default_delete<GPU::ANECompilerHelper::CompiledProduct>>=\"__value_\"^{CompiledProduct}}}"
+ "{unique_ptr<InProcessPackageWritingGuard::LockGuard, std::default_delete<InProcessPackageWritingGuard::LockGuard>>=\"__ptr_\"{__compressed_pair<InProcessPackageWritingGuard::LockGuard *, std::default_delete<InProcessPackageWritingGuard::LockGuard>>=\"__value_\"^{LockGuard}}}"
+ "{unique_ptr<LazyCopyDataFiles, std::default_delete<LazyCopyDataFiles>>=\"__ptr_\"{__compressed_pair<LazyCopyDataFiles *, std::default_delete<LazyCopyDataFiles>>=\"__value_\"^{LazyCopyDataFiles}}}"
+ "{unique_ptr<llvm::LockFileManager, std::default_delete<llvm::LockFileManager>>=\"__ptr_\"{__compressed_pair<llvm::LockFileManager *, std::default_delete<llvm::LockFileManager>>=\"__value_\"^{LockFileManager}}}"
+ "{unordered_map<std::string, MPSGraphExecutableCacheValue, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, MPSGraphExecutableCacheValue>>>=\"__table_\"{__hash_table<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, std::hash<std::string>, std::equal_to<std::string>>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, std::equal_to<std::string>, std::hash<std::string>>, std::allocator<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>>>=\"__bucket_list_\"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *> *> *>>>=\"__ptr_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *> *> *>>>=\"__value_\"^^v\"__value_\"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *> *> *>>=\"__data_\"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *> *> *>>=\"__value_\"Q}}}}\"__p1_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *>>>=\"__value_\"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, void *> *>=\"__next_\"^v}}\"__p2_\"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, std::hash<std::string>, std::equal_to<std::string>>>=\"__value_\"Q}\"__p3_\"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, MPSGraphExecutableCacheValue>, std::equal_to<std::string>, std::hash<std::string>>>=\"__value_\"f}}}"
+ "{unordered_map<std::string, std::unique_ptr<LazyLoadableModuleRef>, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, std::unique_ptr<LazyLoadableModuleRef>>>>=\"__table_\"{__hash_table<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, std::hash<std::string>, std::equal_to<std::string>>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, std::equal_to<std::string>, std::hash<std::string>>, std::allocator<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>>>=\"__bucket_list_\"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *> *> *>>>=\"__ptr_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *> *> *>>>=\"__value_\"^^v\"__value_\"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *> *> *>>=\"__data_\"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *> *> *>>=\"__value_\"Q}}}}\"__p1_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *>>>=\"__value_\"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, void *> *>=\"__next_\"^v}}\"__p2_\"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, std::hash<std::string>, std::equal_to<std::string>>>=\"__value_\"Q}\"__p3_\"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, std::unique_ptr<LazyLoadableModuleRef>>, std::equal_to<std::string>, std::hash<std::string>>>=\"__value_\"f}}}"
+ "\x81"
+ "\xf0\xf0!"
+ "\xf0\xf0\x91B\xf0A\xf4\x114"
- "\x03#\x11"
- "\x05D\x11"
- "\n -> \n"
- " \t\r"
- " \n"
- "  This option category has no options.\n"
- " (the type of the enclosing ReduceOp)"
- " <= result rank "
- " >= result rank "
- " does not end with -skip or -count\n"
- " does not match transposed input type "
- " is a ranked tensor or a ranked memref"
- " is not a number\n"
- " must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got "
- " must be 4D/5D memref of 32-bit float or 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got "
- " must be 5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got "
- " must be tensor of mps native type or complex or quantized values or memref of mps native type or complex or quantized values, but got "
- " must be variadic of 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got "
- " of operation '"
- " of same rank as expanded memref("
- " only handling rank 4 or 5 input"
- " that remained live after conversion, type was "
- " to be the same as result type: "
- " to be valid and contiguous"
- " to have higher rank than the type = "
- "!_aneRegionCallOpHandler"
- "!_tiAndFoldHelper->hasType(value) && \"static type already defined\""
- "\"\x11B"
- "%arg"
- "'\n"
- "' marked as erased"
- "' that remained live after conversion"
- "'aggregate' must be statically shaped tensor of any type values, but got "
- "'anec.input_view' op attribute 'step' failed to satisfy constraint: 64-bit unsigned integer attribute"
- "(all) "
- "(getNumBuckets() & (getNumBuckets()-1)) == 0 && \"# initial buckets must be a power of two!\""
- ") expanded into multiple dynamic dims ("
- ") to be the number of reassociation maps("
- "), but got "
- ", with target type "
- "-[MPSGraphExecutable optimizationPassesWithDevice:sourceModule:compilationID:compilationDescriptor:]"
- "-[MPSGraphExecutable specializedModuleWithDevice:inputShapes:compilationDescriptor:fallingBack:fallbackRuntimeKey:]"
- "0 && \"Unknown GRU Grad DagID\""
- "0 && \"Unknown LSTM DagID\""
- "18.0.0git"
- "180300"
- "5.2.3"
- "8 % bitwith == 0"
- ": Unknown command line argument '"
- "<<UNLINKED BLOCK>>\n"
- "<UNINITIALIZED>"
- "<UNKNOWN>"
- "<tombstone>"
- ">>"
- "ANE Concat supports only supports const positive axis \n"
- "An ANERegion input must always be produced by TensorToMemref op"
- "Attempted to subdivide a range that isn't large enough. This usually happens when the requested alignment is incompatible with your tensor shapes. The required alignment was: "
- "Attribute 'constant_values' do not represent a 16-bit integer or floating-point attribute "
- "Attribute 'constant_values' do not represent a single-element integer or floating-point attribute "
- "Axis value is incorrect for Op"
- "B > 0 && \"Bit width can't be 0.\""
- "BatchToSpace batch_axis operand must be constant\n"
- "BatchToSpace batch_axis operand must match with ANEC batch axis\n"
- "BatchToSpace block_dimensions operand must be constant\n"
- "BatchToSpace spatial_axes operand must match with ANEC spatial axes\n"
- "BatchToSpace spatial_axis operand must be constant\n"
- "BiasAdd invalid channel or not a constant bias\n"
- "CWConv3DOp must have 4D inputs\n"
- "Cannot pack an OffsetLatticeValue that contains ranges that were already allocated to different buffers. This is an invalid program state."
- "Channel <-> Space supports only 1 axis \n"
- "Collapsing dimension for Op"
- "Concat supports only 1 axis \n"
- "Conv dilation must be 1 for batch / channel axis\n"
- "Conv stride must be 1 for batch axis\n"
- "Convert fp32 tensors to fp16."
- "Error: failed to create module"
- "Expected to only find one core op."
- "Failed to extract fpValues from Operand "
- "Failed to get the file size."
- "Failed to lock resource file."
- "Failed to open resource file."
- "Failed to read resource file."
- "Failed to retrieve serialized module."
- "MLIR18.0.0git"
- "MPSGRAPH_SPECIALIZATION_COUNT_MAX"
- "MPSGRAPH_SPECIALIZATION_COUNT_MAX EV is set to %lu.\n"
- "MathExtras.h"
- "Only dataLayout NCDHW & NDHWC are supported for Conv3D\n"
- "Only dataLayout NCHW is supported for Conv2D\n"
- "Only fp16 is supported for A11/A12 Broadcasts. \n"
- "Only weights dataLayout OIDHW & DHWIO are supported for Conv3D\n"
- "Operand 1 should be constant. \n"
- "Operands 'y' and 'y0' must be equal"
- "Operands were allocated into multiple buffers. This is an invalid program state."
- "Optimized"
- "Optimized No Device"
- "PointerUnion.h"
- "ReduceMin for non fp type: "
- "Resize alignCorners == centerResult == true is not supported on A14-class ANEs. \n"
- "Resize with custom scale and offset values not supported on ANE.\n"
- "SignExtend64"
- "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::LastTensorLoadCanonicalization]"
- "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SelectAndCond]"
- "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SelectAndNotCond]"
- "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SelectOrCond]"
- "StringRef llvm::getTypeName() [DesiredTypeName = (anonymous namespace)::SelectOrNotCond]"
- "StringRef llvm::getTypeName() [DesiredTypeName = ArithBitcast]"
- "StringRef llvm::getTypeName() [DesiredTypeName = SelectI1Simplify]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertF32ToF16Pass]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReductionArg<mlir::mps::ReductionArgMaxOp, mlir::anec::Family::A11Legacy>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::(anonymous namespace)::ConvertReductionArg<mlir::mps::ReductionArgMinOp, mlir::anec::Family::A11Legacy>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeCollapseOfExpandOp<mlir::memref::CollapseShapeOp, mlir::memref::ExpandShapeOp, mlir::memref::CastOp>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeCollapseOfExpandOp<mlir::tensor::CollapseShapeOp, mlir::tensor::ExpandShapeOp, mlir::tensor::CastOp>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeReassociativeReshapeOps<mlir::memref::CollapseShapeOp>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeReassociativeReshapeOps<mlir::memref::ExpandShapeOp>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeReassociativeReshapeOps<mlir::tensor::CollapseShapeOp>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::ComposeReassociativeReshapeOps<mlir::tensor::ExpandShapeOp>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MemoryMapperInterface]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MinimumAlignmentInterface::Trait<Empty>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::MinimumAlignmentInterface]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::scf::ExecuteRegionOp, mlir::scf::ForOp, mlir::scf::IfOp, mlir::scf::IndexSwitchOp, mlir::scf::ParallelOp, mlir::scf::WhileOp>::Impl<Empty>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::PassExecutionAction]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::bufferization::detail::ToMemrefOpGenericAdaptorBase::Properties]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::bufferization::detail::ToTensorOpGenericAdaptorBase::Properties]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::CFGEdge]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::Executable]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::Lattice<mlir::dataflow::ConstantValue>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::Lattice<mlir::dataflow::OffsetLatticeValue>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::dataflow::PredecessorState]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::CanonicalizeQuantizedLayerScale<mlir::mps::Conv2DOp>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::CanonicalizeQuantizedLayerScale<mlir::mps::DepthwiseConv3DDataGradientOp>]"
- "StringRef llvm::getTypeName() [DesiredTypeName = mlir::mps::(anonymous namespace)::CanonicalizeQuantizedLayerScale<mlir::mps::DepthwiseConv3DOp>]"
- "T@\"NSDictionary\",&,V_fileSymbolMap"
- "The default optimizer pipeline used for callables"
- "Unable to determine A11/A12 Broadcast. \n"
- "Unsupported A11/A12 Broadcast. \n"
- "Unsupported alignCorners, centerResult for Resize\n"
- "Unsupported padding values for Conv2D\n"
- "Unsupported padding values for Conv3D\n"
- "Unsupported rank for input tensor."
- "Unsupported weightsLayout for Conv2D\n"
- "] provenance: "
- "^v48@0:8@16{ModuleOp=^{Operation}}24@32@40"
- "^v60@0:8@16{ModuleOp=^{Operation}}24@32@40B48r^v52"
- "_alignBytes can only be 0 or 16384"
- "_aneRegionCallOpHandler"
- "_enableANECModuleValidation"
- "_fileSymbolMap"
- "_newRuntimeCache"
- "_specializationCount"
- "_specializationCountMax"
- "addOptimizedMLIRFile:withSignature:"
- "addOptimizedNoDeviceMLIRFile:withSignature:"
- "allocateTensorDataTargetsForDevice:inputsArray:"
- "anec.A12r0"
- "at most one dimension in a reassociation group may be dynamic"
- "bitwith < 8"
- "bufferization.to_memref"
- "bufferization.to_tensor"
- "cast_if_present"
- "colors"
- "complexTy && complexTy.getElementType().isa<FloatType>() && \"must be a complex float attr\""
- "dead"
- "dst index must be a dimension or symbol identifier"
- "erase\n"
- "expected key entry for activation in DictionaryAttr to set Properties."
- "expected key entry for alignment in DictionaryAttr to set Properties."
- "expected key entry for attributeValueNames in DictionaryAttr to set Properties."
- "expected key entry for batch_dims in DictionaryAttr to set Properties."
- "expected key entry for begin_mask in DictionaryAttr to set Properties."
- "expected key entry for benefit in DictionaryAttr to set Properties."
- "expected key entry for block_size in DictionaryAttr to set Properties."
- "expected key entry for callee in DictionaryAttr to set Properties."
- "expected key entry for caseValues in DictionaryAttr to set Properties."
- "expected key entry for case_operand_segments in DictionaryAttr to set Properties."
- "expected key entry for cases in DictionaryAttr to set Properties."
- "expected key entry for constantValue in DictionaryAttr to set Properties."
- "expected key entry for count in DictionaryAttr to set Properties."
- "expected key entry for data_layout in DictionaryAttr to set Properties."
- "expected key entry for dilation_rates in DictionaryAttr to set Properties."
- "expected key entry for dtype in DictionaryAttr to set Properties."
- "expected key entry for end_mask in DictionaryAttr to set Properties."
- "expected key entry for epsilon in DictionaryAttr to set Properties."
- "expected key entry for explicit_padding in DictionaryAttr to set Properties."
- "expected key entry for file_path in DictionaryAttr to set Properties."
- "expected key entry for function_type in DictionaryAttr to set Properties."
- "expected key entry for gather_dims in DictionaryAttr to set Properties."
- "expected key entry for groups in DictionaryAttr to set Properties."
- "expected key entry for index in DictionaryAttr to set Properties."
- "expected key entry for inlineMode in DictionaryAttr to set Properties."
- "expected key entry for inner_dims_pos in DictionaryAttr to set Properties."
- "expected key entry for inputAttributeNames in DictionaryAttr to set Properties."
- "expected key entry for isDataCache in DictionaryAttr to set Properties."
- "expected key entry for isWrite in DictionaryAttr to set Properties."
- "expected key entry for kernel_sizes in DictionaryAttr to set Properties."
- "expected key entry for kind in DictionaryAttr to set Properties."
- "expected key entry for layout in DictionaryAttr to set Properties."
- "expected key entry for localityHint in DictionaryAttr to set Properties."
- "expected key entry for lowerBoundMap in DictionaryAttr to set Properties."
- "expected key entry for lowerBoundsGroups in DictionaryAttr to set Properties."
- "expected key entry for lowerBoundsMap in DictionaryAttr to set Properties."
- "expected key entry for map in DictionaryAttr to set Properties."
- "expected key entry for mode in DictionaryAttr to set Properties."
- "expected key entry for msg in DictionaryAttr to set Properties."
- "expected key entry for name in DictionaryAttr to set Properties."
- "expected key entry for offset in DictionaryAttr to set Properties."
- "expected key entry for operandSegmentSizes in DictionaryAttr to set Properties."
- "expected key entry for paddingMode in DictionaryAttr to set Properties."
- "expected key entry for padding_mode in DictionaryAttr to set Properties."
- "expected key entry for padding_style in DictionaryAttr to set Properties."
- "expected key entry for permutation in DictionaryAttr to set Properties."
- "expected key entry for pixel_format in DictionaryAttr to set Properties."
- "expected key entry for predicate in DictionaryAttr to set Properties."
- "expected key entry for reassociation in DictionaryAttr to set Properties."
- "expected key entry for reductions in DictionaryAttr to set Properties."
- "expected key entry for resultElementType in DictionaryAttr to set Properties."
- "expected key entry for result_element_type in DictionaryAttr to set Properties."
- "expected key entry for rewriter in DictionaryAttr to set Properties."
- "expected key entry for sampling_mode in DictionaryAttr to set Properties."
- "expected key entry for scaling_mode in DictionaryAttr to set Properties."
- "expected key entry for scatter_dims in DictionaryAttr to set Properties."
- "expected key entry for shrink_axis_mask in DictionaryAttr to set Properties."
- "expected key entry for staticLowerBound in DictionaryAttr to set Properties."
- "expected key entry for staticStep in DictionaryAttr to set Properties."
- "expected key entry for staticUpperBound in DictionaryAttr to set Properties."
- "expected key entry for static_high in DictionaryAttr to set Properties."
- "expected key entry for static_inner_tiles in DictionaryAttr to set Properties."
- "expected key entry for static_low in DictionaryAttr to set Properties."
- "expected key entry for static_offsets in DictionaryAttr to set Properties."
- "expected key entry for static_sizes in DictionaryAttr to set Properties."
- "expected key entry for static_strides in DictionaryAttr to set Properties."
- "expected key entry for step in DictionaryAttr to set Properties."
- "expected key entry for steps in DictionaryAttr to set Properties."
- "expected key entry for storage_type in DictionaryAttr to set Properties."
- "expected key entry for strides in DictionaryAttr to set Properties."
- "expected key entry for sym_name in DictionaryAttr to set Properties."
- "expected key entry for symbolName in DictionaryAttr to set Properties."
- "expected key entry for type in DictionaryAttr to set Properties."
- "expected key entry for type_constraint in DictionaryAttr to set Properties."
- "expected key entry for types in DictionaryAttr to set Properties."
- "expected key entry for upperBoundMap in DictionaryAttr to set Properties."
- "expected key entry for upperBoundsGroups in DictionaryAttr to set Properties."
- "expected key entry for upperBoundsMap in DictionaryAttr to set Properties."
- "expected key entry for value in DictionaryAttr to set Properties."
- "expected key entry for weights_layout in DictionaryAttr to set Properties."
- "expected key entry for window_sizes in DictionaryAttr to set Properties."
- "expected non-zero memref ranks"
- "expected rank expansion, but found source rank "
- "expected rank of the collapsed type("
- "expected rank reduction, but found source rank "
- "expected the type "
- "expected to collapse or expand dims"
- "expects body to terminate with 'scf.yield'"
- "expects two arguments to reduce block of type "
- "expects type of reduce: "
- "failed to legalize unresolved materialization from "
- "failed to materialize conversion for block argument #"
- "failed to materialize conversion for result #"
- "failed to verify that condition is scalar or has matching shape"
- "failed: ConvertBinaryCompare expects the second operand to be non-zero. \n"
- "failed: ConvertBinaryCompareToZero expects the second operand to be zero. \n"
- "failed: Could not extract valid positive and rank-promoted axes. \n"
- "failed: F32 I/Os not supported for ANE devices prior to A15"
- "failed: Flatten2DOp axis argument was not a constant. \n"
- "failed: Permute can be lowered to Transpose only if indices argument is a constant \n"
- "failed: Reshape target shape must be NxCx1x1 to be lowered as Flatten on ANEs.\n"
- "failed: amount_before value {0} and amount_after value {1} do not fit dimension size ({1})"
- "failed: can only support divide by a constant on A11/A12 class ANEs \n"
- "failed: mps ops with unranked output types or dynamic shapes are not supported on ANEs."
- "failed: non strictly positive strides are not supported"
- "failed: unranked input types or dynamic shapes are not supported on ANEs."
- "fileSymbolMap"
- "found live user of result #"
- "front"
- "getEntryFuncOp"
- "getNewRuntimeForDevice:module:inputShapes:compilationDescriptor:fallingBack:fallbackRuntimeKey:"
- "getNewRuntimeForDevice:module:inputsArray:compilationDescriptor:"
- "getOptimizedMLIRLibrary"
- "getOptimizedNoDeviceMLIRLibrary"
- "getTensorDataArraysWithDevice:feedsDictionary:resultsDictionary:inputsArray:resultsArray:"
- "has an empty opname for dialect '"
- "iOS18.2.0"
- "incorrect number of indices for load"
- "index must be a dimension or symbol identifier"
- "initializeForExecution"
- "invalid tile factor provided. Only full tiles are supported when padding_value is not set"
- "invalid to have a single dimension ("
- "invalid to reshape tensor/memref with non-unit extent dimensions to zero-rank tensor/memref"
- "is not supported for A13 and below\n"
- "isa<T>(*this) && \"Invalid accessor called\""
- "isa<X>(Val) && \"cast_if_present<Ty>() argument of incompatible type!\""
- "live"
- "llvm::divideCeil(numElements, 8) == inData.size()"
- "macOS15.2.0"
- "match"
- "moveItemAtURL:toURL:error:"
- "mpsx.aneFamily"
- "needs to have type "
- "not allowed to have operands inside '"
- "only supporting NCHW in Depth <-> Space -> Channel <-> Space\n"
- "optimizationPassesWithDevice:sourceModule:compilationID:compilationDescriptor:"
- "optimizedFileExistsWithSignature:"
- "optimizedModule_%lu"
- "optimizedNoDeviceFileExistsWithSignature:"
- "predecessors:\n"
- "q2\xf0\xc1\xf4\x114"
- "reductionOperator"
- "requires attribute's elements to be float attributes"
- "requires input or output is a complex type"
- "setFileSymbolMap:"
- "setSpecializationCountMax:"
- "specializeWithDevice:inputsArray:compilationDescriptor:"
- "specializedModuleWithDevice:inputShapes:compilationDescriptor:fallingBack:fallbackRuntimeKey:"
- "src index must be a dimension or symbol identifier"
- "succeeded(result) && \"expected ConstantLike op to be foldable\""
- "tag index must be a dimension or symbol identifier"
- "tensor dimensions must be non-negative"
- "the block inside reduce should be terminated with a 'scf.reduce.return' op"
- "the block inside reduce should not be empty"
- "this->size() >= N && \"Dropping more elements than exist\""
- "to MaxPool, AveragePool or Conv for A13 and below on ane is not supported \n"
- "try_emplace"
- "tvOS18.2.0"
- "unknown program point kind"
- "unpackBooleanData"
- "vector elements must be int/index/float type"
- "vector types must have positive constant sizes"
- "vin-f32-to-f16"
- "visionOS2.2.0"
- "weight operand is not a constant!\n"
- "{DenseMap<MPSGraphModuleKey, std::unique_ptr<LazyLoadableModuleRef>, MPSGraphModuleKeyInfo, llvm::detail::DenseMapPair<MPSGraphModuleKey, std::unique_ptr<LazyLoadableModuleRef>>>=\"Buckets\"^v\"NumEntries\"I\"NumTombstones\"I\"NumBuckets\"I}"
- "{DenseMap<const void *, std::unique_ptr<RuntimeCacheEntry>, llvm::DenseMapInfo<const void *>, llvm::detail::DenseMapPair<const void *, std::unique_ptr<RuntimeCacheEntry>>>=\"Buckets\"^v\"NumEntries\"I\"NumTombstones\"I\"NumBuckets\"I}"
- "{FuncOp=^{Operation}}16@0:8"
- "{ModuleOp=^{Operation}}40@0:8@16@24@32"
- "{ModuleOp=^{Operation}}52@0:8@16@24@32B40r^v44"
- "{OwningOpRef<mlir::ModuleOp>={ModuleOp=^{Operation}}}48@0:8@16^v24Q32@40"
- "{recursive_mutex=\"__m_\"{_opaque_pthread_mutex_t=\"__sig\"q\"__opaque\"[56c]}}"
- "{unordered_map<std::string, LazyLoadableModuleRef, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, LazyLoadableModuleRef>>>=\"__table_\"{__hash_table<std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::hash<std::string>, std::equal_to<std::string>>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::equal_to<std::string>, std::hash<std::string>>, std::allocator<std::__hash_value_type<std::string, LazyLoadableModuleRef>>>=\"__bucket_list_\"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *>>>=\"__ptr_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *>>>=\"__value_\"^^v\"__value_\"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *>>=\"__data_\"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *>>=\"__value_\"Q}}}}\"__p1_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *>>>=\"__value_\"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *>=\"__next_\"^v}}\"__p2_\"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::hash<std::string>, std::equal_to<std::string>>>=\"__value_\"Q}\"__p3_\"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::equal_to<std::string>, std::hash<std::string>>>=\"__value_\"f}}}"

```
