## TextToSpeechMauiSupport

> `/System/Library/PrivateFrameworks/TextToSpeechMauiSupport.framework/TextToSpeechMauiSupport`

```diff

-73.0.3.0.0
-  __TEXT.__text: 0x4d3dc4
-  __TEXT.__auth_stubs: 0x1920
+73.0.7.0.0
+  __TEXT.__text: 0x4dd91c
+  __TEXT.__auth_stubs: 0x1970
   __TEXT.__objc_methlist: 0x524
-  __TEXT.__const: 0xb2ca8
-  __TEXT.__cstring: 0x51adf
+  __TEXT.__const: 0xc45c8
+  __TEXT.__cstring: 0x44a8f
   __TEXT.__oslogstring: 0x46a
-  __TEXT.__gcc_except_tab: 0x42cc
+  __TEXT.__gcc_except_tab: 0x44e0
   __TEXT.__ustring: 0x6c
-  __TEXT.__swift5_typeref: 0x2b6
-  __TEXT.__swift5_capture: 0x90
+  __TEXT.__swift5_typeref: 0x2dc
+  __TEXT.__swift5_capture: 0xa0
   __TEXT.__constg_swiftt: 0x3a4
   __TEXT.__swift5_reflstr: 0x291
   __TEXT.__swift5_fieldmd: 0x2d4

   __TEXT.__swift5_assocty: 0x18
   __TEXT.__swift5_proto: 0xc
   __TEXT.__swift5_types: 0x30
-  __TEXT.__unwind_info: 0xae4c
+  __TEXT.__unwind_info: 0xb04c
   __TEXT.__eh_frame: 0x6c0
   __TEXT.__objc_classname: 0xb6
-  __TEXT.__objc_methname: 0x1b33
+  __TEXT.__objc_methname: 0x1b27
   __TEXT.__objc_methtype: 0x4d7
   __TEXT.__objc_stubs: 0x13e0
-  __DATA_CONST.__got: 0x178
-  __DATA_CONST.__const: 0x10028
+  __DATA_CONST.__got: 0x1a0
+  __DATA_CONST.__const: 0x10038
   __DATA_CONST.__objc_classlist: 0x28
   __DATA_CONST.__objc_protolist: 0x38
   __DATA_CONST.__objc_imageinfo: 0x8
   __DATA_CONST.__objc_const: 0xeb0
   __DATA_CONST.__objc_selrefs: 0x708
   __AUTH_CONST.__cfstring: 0x580
-  __AUTH_CONST.__const: 0xf850
+  __AUTH_CONST.__const: 0xf720
   __AUTH_CONST.__objc_const: 0x168
   __AUTH_CONST.__objc_intobj: 0x48
   __AUTH_CONST.__auth_ptr: 0x8
-  __AUTH_CONST.__auth_got: 0xca8
+  __AUTH_CONST.__auth_got: 0xcd0
   __AUTH.__objc_data: 0xf0
   __AUTH.__data: 0x30
   __AUTH.__const_weak: 0x910
-  __DATA.__got_weak: 0x188
+  __DATA.__got_weak: 0x190
   __DATA.__objc_protorefs: 0x18
   __DATA.__objc_classrefs: 0x110
   __DATA.__objc_superrefs: 0x18

   - /System/Library/Frameworks/CoreMedia.framework/CoreMedia
   - /System/Library/Frameworks/Foundation.framework/Foundation
   - /System/Library/PrivateFrameworks/AXCoreUtilities.framework/AXCoreUtilities
+  - /System/Library/PrivateFrameworks/BiomePubSub.framework/BiomePubSub
   - /System/Library/PrivateFrameworks/TextToSpeech.framework/TextToSpeech
   - /System/Library/PrivateFrameworks/TextToSpeechBundleSupport.framework/TextToSpeechBundleSupport
   - /usr/lib/libAccessibility.dylib

   - /usr/lib/swift/libswift_StringProcessing.dylib
   - /usr/lib/swift/libswiftos.dylib
   - /usr/lib/swift/libswiftsimd.dylib
-  Functions: 14508
-  Symbols:   21924
-  CStrings:  12566
+  Functions: 14673
+  Symbols:   22181
+  CStrings:  12573
 
Symbols:
+ GCC_except_table100
+ GCC_except_table112
+ GCC_except_table130
+ GCC_except_table133
+ GCC_except_table148
+ GCC_except_table150
+ GCC_except_table152
+ GCC_except_table159
+ GCC_except_table161
+ GCC_except_table162
+ GCC_except_table164
+ GCC_except_table170
+ GCC_except_table172
+ GCC_except_table174
+ GCC_except_table177
+ GCC_except_table179
+ GCC_except_table37
+ GCC_except_table61
+ GCC_except_table72
+ GCC_except_table88
+ GCC_except_table92
+ _OP_MEM_CALLBACKS
+ _OP_STEREO_DOWNMIX
+ _OP_STEREO_DOWNMIX_Q14
+ __PROTOCOLS__TtC23TextToSpeechMauiSupport17MauiAUSPAudioUnit.10
+ __Z21create_decoder_engine10EngineType15ModelParameters16VisemeParametersPvNSt3__110shared_ptrI17IExternalServicesEE
+ __ZN14IDecoderEngine11run_decoderERNSt3__16vectorIfN5ENTTS9AllocatorIfEEEERNS1_ImNS3_ImEEEEbb
+ __ZN14IDecoderEngine12do_inferenceERNSt3__16vectorIfN5ENTTS9AllocatorIfEEEERNS1_ImNS3_ImEEEES6_S9_S6_S9_bb
+ __ZN14IDecoderEngine20set_model_parametersER15ModelParameters
+ __ZN14IDecoderEngine21set_viseme_parametersER16VisemeParameters
+ __ZN14IDecoderEngineD2Ev
+ __ZN15ModelParametersC2Ev
+ __ZN15ModelParametersD1Ev
+ __ZN16PipelineServices22read_numpy_and_cast_16ENSt3__112basic_stringIcNS0_11char_traitsIcEEN5ENTTS9AllocatorIcEEEERNS0_6vectorImNS5_ImEEEERNS8_IDhNS5_IDhEEEEb
+ __ZN16VisemeParametersC1ENSt3__110shared_ptrI12IJsonWrapperEE
+ __ZN16VisemeParametersC2ENSt3__110shared_ptrI12IJsonWrapperEE
+ __ZN16VisemeParametersD1Ev
+ __ZN17DecoderNeonEngine17do_inference_loopERNSt3__16vectorIfN5ENTTS9AllocatorIfEEEEib
+ __ZN17DecoderNeonEngineD2Ev
+ __ZN3npy18LoadArrayFromNumpyEPcmRNSt3__16vectorImN5ENTTS9AllocatorImEEEERNS2_IDhNS4_IDhEEEE
+ __ZN3npy18LoadArrayFromNumpyEPcmRNSt3__16vectorImN5ENTTS9AllocatorImEEEERNS2_IfNS4_IfEEEE
+ __ZN3npy27LoadArrayFromNumpy_16_or_32ERNSt3__113basic_istreamIcNS0_11char_traitsIcEEEERNS0_6vectorImN5ENTTS9AllocatorImEEEERNS6_IDhNS8_IDhEEEE
+ __ZN5ENTTS9AllocatorIDhE8allocateEmPKv
+ __ZN5ENTTS9AllocatorINSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEEE8allocateEmPKv
+ __ZN9TC2Engine12do_inferenceERNSt3__16vectorIiN5ENTTS9AllocatorIiEEEERNS1_ImNS3_ImEEEERNS1_IfNS3_IfEEEES9_SC_S9_yb
+ __ZNKSt3__129_AllocatorDestroyRangeReverseIN5ENTTS9AllocatorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEPS8_EclB7v160006Ev
+ __ZNKSt3__16vectorIDhN5ENTTS9AllocatorIDhEEE20__throw_length_errorB7v160006Ev
+ __ZNKSt3__16vectorIDhN5ENTTS9AllocatorIDhEEE20__throw_out_of_rangeB7v160006Ev
+ __ZNKSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS6_EEE20__throw_length_errorB7v160006Ev
+ __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC1ERKS5_
+ __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEaSERKS5_
+ __ZNSt3__114__split_bufferIDhRN5ENTTS9AllocatorIDhEEED2Ev
+ __ZNSt3__121__unwrap_and_dispatchB7v160006INS_10__overloadINS_11__copy_loopINS_17_ClassicAlgPolicyEEENS_14__copy_trivialEEEPNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESD_SD_Li0EEENS_4pairIT0_T2_EESF_T1_SG_
+ __ZNSt3__128__exception_guard_exceptionsINS_29_AllocatorDestroyRangeReverseIN5ENTTS9AllocatorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEPS9_EEED2B7v160006Ev
+ __ZNSt3__128__exception_guard_exceptionsINS_6vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS7_EEE16__destroy_vectorEED2B7v160006Ev
+ __ZNSt3__130__uninitialized_allocator_copyB7v160006IN5ENTTS9AllocatorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEEPS8_SA_SA_EET2_RT_T0_T1_SB_
+ __ZNSt3__16vectorIDhN5ENTTS9AllocatorIDhEEE16__destroy_vectorclB7v160006Ev
+ __ZNSt3__16vectorIDhN5ENTTS9AllocatorIDhEEE6resizeEm
+ __ZNSt3__16vectorIDhN5ENTTS9AllocatorIDhEEE8__appendEm
+ __ZNSt3__16vectorIDhN5ENTTS9AllocatorIDhEEED2B7v160006Ev
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEEN5ENTTS9AllocatorIcEEEENS5_IS7_EEE13__vdeallocateEv
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEEN5ENTTS9AllocatorIcEEEENS5_IS7_EEE6assignIPS7_Li0EEEvT_SC_
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS6_EEE11__vallocateB7v160006Em
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS6_EEE13__vdeallocateEv
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS6_EEE16__destroy_vectorclB7v160006Ev
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS6_EEE6assignIPS6_Li0EEEvT_SD_
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS6_EEE7__clearB7v160006Ev
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS6_EEEC2ERKSA_
+ __ZNSt3__16vectorINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEN5ENTTS9AllocatorIS6_EEED2B7v160006Ev
+ __ZTV14IDecoderEngine
+ __os_body_expand
+ __os_lacing_expand
+ __os_update_crc
+ __packetout
+ _audiofetch_FetchThroughBroker
+ _audiofetch_FetchThroughCup
+ _audiofetch_IsURIWithinCup
+ _audiofetch_Ogg2Wav.WAV_HEADER_TEMPLATE
+ _block_copy_helper.22
+ _block_copy_helper.31
+ _block_copy_helper.37
+ _block_copy_helper.49
+ _block_descriptor.24
+ _block_descriptor.33
+ _block_descriptor.39
+ _block_descriptor.51
+ _block_destroy_helper.23
+ _block_destroy_helper.32
+ _block_destroy_helper.38
+ _block_destroy_helper.50
+ _crc_lookup
+ _gEncryptedScript
+ _getExtendedReferences_LuaParameters
+ _get_left_channel
+ _get_mono_channel
+ _get_right_channel
+ _mask
+ _mask8B
+ _objc_retain_x28
+ _ogg_packet_clear
+ _ogg_page_bos
+ _ogg_page_checksum_set
+ _ogg_page_continued
+ _ogg_page_eos
+ _ogg_page_granulepos
+ _ogg_page_packets
+ _ogg_page_pageno
+ _ogg_page_serialno
+ _ogg_page_version
+ _ogg_stream_check
+ _ogg_stream_clear
+ _ogg_stream_destroy
+ _ogg_stream_eos
+ _ogg_stream_flush
+ _ogg_stream_flush_fill
+ _ogg_stream_flush_i
+ _ogg_stream_init
+ _ogg_stream_iovecin
+ _ogg_stream_packetin
+ _ogg_stream_packetout
+ _ogg_stream_packetpeek
+ _ogg_stream_pagein
+ _ogg_stream_pageout
+ _ogg_stream_pageout_fill
+ _ogg_stream_reset
+ _ogg_stream_reset_serialno
+ _ogg_sync_buffer
+ _ogg_sync_check
+ _ogg_sync_clear
+ _ogg_sync_destroy
+ _ogg_sync_init
+ _ogg_sync_pageout
+ _ogg_sync_pageseek
+ _ogg_sync_reset
+ _ogg_sync_wrote
+ _oggpackB_adv
+ _oggpackB_adv1
+ _oggpackB_bits
+ _oggpackB_bytes
+ _oggpackB_get_buffer
+ _oggpackB_look
+ _oggpackB_look1
+ _oggpackB_read
+ _oggpackB_read1
+ _oggpackB_readinit
+ _oggpackB_reset
+ _oggpackB_write
+ _oggpackB_writealign
+ _oggpackB_writecheck
+ _oggpackB_writeclear
+ _oggpackB_writecopy
+ _oggpackB_writeinit
+ _oggpackB_writetrunc
+ _oggpack_adv
+ _oggpack_adv1
+ _oggpack_bits
+ _oggpack_bytes
+ _oggpack_get_buffer
+ _oggpack_look
+ _oggpack_look1
+ _oggpack_read
+ _oggpack_read1
+ _oggpack_readinit
+ _oggpack_reset
+ _oggpack_write
+ _oggpack_writealign
+ _oggpack_writecheck
+ _oggpack_writeclear
+ _oggpack_writecopy
+ _oggpack_writecopy_helper
+ _oggpack_writeinit
+ _oggpack_writetrunc
+ _op_bitrate
+ _op_bitrate_instant
+ _op_buffer_continued_data
+ _op_calc_bitrate
+ _op_channel_count
+ _op_clear
+ _op_collect_audio_packets
+ _op_current_link
+ _op_decode
+ _op_extract_gif_params
+ _op_extract_jpeg_params
+ _op_extract_png_params
+ _op_fetch_and_process_page
+ _op_fetch_headers
+ _op_filter_read_native
+ _op_find_final_pcm_offset
+ _op_find_initial_pcm_offset
+ _op_free
+ _op_get_link_from_serialno
+ _op_get_next_page
+ _op_get_packet_duration
+ _op_granpos_add
+ _op_head
+ _op_init_buffer
+ _op_is_gif
+ _op_link_count
+ _op_make_decode_ready
+ _op_mem_close
+ _op_mem_read
+ _op_mem_seek
+ _op_mem_stream_create
+ _op_mem_tell
+ _op_open2
+ _op_open_callbacks
+ _op_open_memory
+ _op_pcm_seek
+ _op_pcm_tell
+ _op_pcm_total
+ _op_raw_seek
+ _op_raw_tell
+ _op_raw_total
+ _op_read
+ _op_read_float
+ _op_read_float_stereo
+ _op_read_native
+ _op_read_stereo
+ _op_rescale64
+ _op_seek_helper
+ _op_seekable
+ _op_serialno
+ _op_set_decode_callback
+ _op_set_dither_enabled
+ _op_set_gain_offset
+ _op_short2float_filter
+ _op_short2float_stereo_filter
+ _op_stereo_filter
+ _op_strdup_with_len
+ _op_strncasecmp
+ _op_tags
+ _op_tags_ensure_capacity
+ _op_test
+ _op_test_callbacks
+ _op_test_memory
+ _op_test_open
+ _op_update_gain
+ _opus_copy_channel_out_float
+ _opus_copy_channel_out_short
+ _opus_granule_sample
+ _opus_head_parse
+ _opus_multistream_decode
+ _opus_multistream_decode_float
+ _opus_multistream_decode_native
+ _opus_multistream_decoder_create
+ _opus_multistream_decoder_ctl
+ _opus_multistream_decoder_destroy
+ _opus_multistream_decoder_get_size
+ _opus_multistream_decoder_init
+ _opus_picture_tag_clear
+ _opus_picture_tag_init
+ _opus_picture_tag_parse
+ _opus_tagcompare
+ _opus_tagncompare
+ _opus_tags_add
+ _opus_tags_add_comment
+ _opus_tags_clear
+ _opus_tags_copy
+ _opus_tags_get_album_gain
+ _opus_tags_get_binary_suffix
+ _opus_tags_get_gain
+ _opus_tags_get_track_gain
+ _opus_tags_init
+ _opus_tags_parse
+ _opus_tags_parse_impl
+ _opus_tags_query
+ _opus_tags_query_count
+ _opus_tags_set_binary_suffix
+ _sentpar_loc_Align
+ _symbolic So32AVSpeechSynthesisProviderRequestC
+ _validate_layout
- GCC_except_table108
- GCC_except_table117
- GCC_except_table137
- GCC_except_table17
- GCC_except_table69
- GCC_except_table76
- GCC_except_table82
- GCC_except_table90
- GCC_except_table95
- _IInetspi
- _InetModule
- _TTSRosebudLogger
- __PROTOCOLS__TtC23TextToSpeechMauiSupport17MauiAUSPAudioUnit.7
- __Z12entts_deleteI17DecoderNeonEngineEvPT_
- __Z21create_decoder_engine10EngineType15ModelParametersPvNSt3__110shared_ptrI17IExternalServicesEE
- __ZN14IDecoderEngine11run_decoderERNSt3__16vectorIfN5ENTTS9AllocatorIfEEEERNS1_ImNS3_ImEEEEb
- __ZN14IDecoderEngine12do_inferenceERNSt3__16vectorIfN5ENTTS9AllocatorIfEEEERNS1_ImNS3_ImEEEES6_S9_S6_S9_b
- __ZN17DecoderNeonEngine17do_inference_loopERNSt3__16vectorIfN5ENTTS9AllocatorIfEEEEi
- __ZN3npy18LoadArrayFromNumpyIfEEvPcmRNSt3__16vectorImN5ENTTS9AllocatorImEEEERNS3_IT_NS5_IS9_EEEE
- __ZN9TC2Engine12do_inferenceERNSt3__16vectorIiN5ENTTS9AllocatorIiEEEERNS1_ImNS3_ImEEEERNS1_IfNS3_IfEEEES9_SC_S9_y
- ___39-[TTSMauiSpeechEngine _preprocessText:]_block_invoke
- ___block_descriptor_40_e8_32r_e37_v32?0"NSTextCheckingResult"8Q16^B24lr32l8
- _block_copy_helper.19
- _block_copy_helper.28
- _block_copy_helper.34
- _block_copy_helper.46
- _block_descriptor.21
- _block_descriptor.30
- _block_descriptor.36
- _block_descriptor.48
- _block_destroy_helper.20
- _block_destroy_helper.29
- _block_destroy_helper.35
- _block_destroy_helper.47
- _brkhlp_InitializeONNX
- _inet_CacheClose
- _inet_CacheObjClose
- _inet_CacheObjOpen
- _inet_CacheOpen
- _inet_CacheRead
- _inet_CacheUnlock
- _inet_CacheWrite
- _inet_InetClassClose
- _inet_InetClassOpen
- _inet_InetErrorQueueEnd
- _inet_InetErrorQueueFree
- _inet_InetErrorQueueStart
- _inet_InetFetch
- _inet_InetFetchClose
- _inet_InetFetchFree
- _inet_InetFetchGetData
- _inet_InetFetchOpen
- _inet_InetFetchRead
- _inet_InetFetchUnloadData
- _inet_InetGetAbsoluteURI
- _inet_InetGetCookieJar
- _inet_InetObjClose
- _inet_InetObjOpen
- _inet_InetObjReopen
- _inet_InetSetCookieJar
- _inet_InetSetProxyRules
- _inet_MapClone
- _inet_MapCloneProperty
- _inet_MapCreate
- _inet_MapCreateHandle
- _inet_MapDeleteProperty
- _inet_MapDestroy
- _inet_MapFreeParam
- _inet_MapFromSOAPString
- _inet_MapGetNextProperty
- _inet_MapGetProperty
- _inet_MapIteratorCreate
- _inet_MapIteratorDestroy
- _inet_MapSetProperty
- _inet_MapToSOAPString
- _inet_VectorAddElement
- _inet_VectorClone
- _inet_VectorCreate
- _inet_VectorDestroy
- _inet_VectorFreeParam
- _inet_VectorFromSOAPString
- _inet_VectorGetElement
- _inet_VectorLength
- _inet_VectorSetElement
- _inet_VectorToSOAPString
- _inet_loc_ObjcInetFetchData
- _inet_loc_ObjcUnloadInetFetchData
- _inetlite_ElemCopyParam
- _inetlite_ElemFreeParam
- _inetlite_ParseUri
- _inetspi_GetInterface
CStrings:
+ ".ogg"
+ ".opus"
+ "<f2"
+ "<f4"
+ "Entering bet7_featex_loc_RunInitLuaFunction"
+ "FAILURE"
+ "Leaving bet7_featex_loc_RunInitLuaFunction"
+ "METADATA_BLOCK_PICTURE"
+ "OggS"
+ "R128_ALBUM_GAIN"
+ "R128_TRACK_GAIN"
+ "ar"
+ "audio/ogg"
+ "before wordpar_loc_Align()"
+ "extendedreferences"
+ "fa"
+ "get_extended_references"
+ "image/"
+ "image/gif"
+ "image/jpeg"
+ "image/png"
+ "jobIdentifier"
+ "libopus 1.1-fixed"
+ "liddigitmain"
+ "xref"
- "\n-- GENLUA ---------------------------------------------------\n-- GENLUA BEGIN file engine_utils.lua\n\nload_module_engine_utils = function()\n\n\n-- READ_ONLY SCRIPT - DO NOT MODIFY !!\n-- COMPILED INSIDE THE ENGINE\n-- Please contact NLP or SW team in case some changes are required.\n\nlocal engine_utils = {}\n\n\n-- Basic check if the words in tnplus_words have all the fields required (different from nil)\n-- If over time this structure would change, e.g. fields being added in newer versions of the engine, \n-- and perhaps only used for a particular language or voice, then we probably do not want to change this\n-- current function : this function is shared (in data) across languages/voices, and we may introduce \n-- a dependency on a particular engine which is perhaps not needed for all languages/voices. \n-- Please check with other teams (SW, NLP, Voices) in such case.\nfunction engine_utils.tnplus_words_sanity_check (tnplus_words)\n  \n  Log.log(\"Entering 'tnplus_words_sanity_check'\")\n  \n  bOk = true\n  for wordIdx, tnplus_word in ipairs(tnplus_words) do\n    if bOk == false then\n      break\n    end\n    \n    if type(tnplus_word.orth) ~= \"string\" then\n      bOk = false\n    elseif type(tnplus_word.phon) ~= \"string\" then\n      bOk = false\n    elseif type(tnplus_word.punc_beg) ~= \"string\" then\n      bOk = false\n    elseif type(tnplus_word.punc_end) ~= \"string\" then\n      bOk = false\n    elseif tnplus_word.metadata == nil then\n      bOk = false\n    elseif type(tnplus_word.metadata.token) ~= \"string\" or\n           type(tnplus_word.metadata.spell) ~= \"boolean\" or\n           type(tnplus_word.metadata.stylename) ~= \"string\" or\n           type(tnplus_word.metadata.styleintensity) ~= \"string\" or\n           type(tnplus_word.metadata.compound) ~= \"boolean\" or\n           type(tnplus_word.metadata.oriorthjoined) ~= \"boolean\" or\n           type(tnplus_word.metadata.phrasetype) ~= \"string\" or\n           type(tnplus_word.metadata.language) ~= \"string\" or\n           type(tnplus_word.metadata.audiosrc) ~= \"string\" or\n           type(tnplus_word.metadata.origortho) ~= \"string\" or\n           type(tnplus_word.metadata[\"break\"]) ~= \"string\" or\n           type(tnplus_word.metadata.userphon) ~= \"boolean\" or\n           type(tnplus_word.metadata.tone) ~= \"string\" or\n           type(tnplus_word.metadata.sildur) ~= \"number\" then    \n      bOk = false\n    elseif type(tnplus_word.metadata.volume) ~= \"number\" or\n           type(tnplus_word.metadata.pitch) ~= \"number\" or\n           type(tnplus_word.metadata.rate) ~= \"number\" or\n           type(tnplus_word.metadata.timbre) ~= \"number\" then\n        if _G[\"dev_environment\"] == false then\n           bOk = false\n        -- BE json files do not specify volume/pitch/rate/timbre\n        -- Decided not to output either.\n        -- If we want to output default values, then enable following lines           \n        -- else \n           -- tnplus_word.metadata.volume=80\n           -- tnplus_word.metadata.pitch=100\n           -- tnplus_word.metadata.rate=100\n           -- tnplus_word.metadata.timbre=100\n        end\n    end\n  end\n  \n  if bOk == false then\n    engine_utils.log_important_message (\"Error: 'tnplus_words_sanity_check' failed\")\n  end\n  \n  Log.log(\"Done 'tnplus_words_sanity_check'\")\n  \n  return bOk\nend\n\n\nfunction engine_utils.tokenize_phonetics(tnplus_words)  \n  for wordIdx, tnplus_word in ipairs(tnplus_words) do     \n    if tnplus_words[wordIdx].phon ~= nil and #tnplus_words[wordIdx].phon > 0 then\n      tnplus_words[wordIdx].tokenized_phon = engine_utils.split(CLM.TokenizeLHP(tnplus_words[wordIdx].phon), \"%s\")\n      tnplus_words[wordIdx].num_phon=#tnplus_words[wordIdx].tokenized_phon\n    else \n      tnplus_words[wordIdx].tokenized_phon = {}\n      tnplus_words[wordIdx].num_phon = 0\n    end\n  end \nend\n\n\nfunction engine_utils.tokenize_tones(tnplus_words)\n  \n  for wordIdx, tnplus_word in ipairs(tnplus_words) do\n    tnplus_word.tokenized_tone = {}\n    \n    syllables = engine_utils.split(tnplus_word.phon, \"%.\")\n    \n    res = 1\n    while res > 0 do\n      -- replace empty tone values by -1 to preserve 1-to-1 alignment between \"syllables\" and \"tones\"\n      tnplus_word.metadata.tone, res = tnplus_word.metadata.tone:gsub(\"%.%.\", \".-1.\", 1)\n    end\n    tones = engine_utils.split(tnplus_word.metadata.tone, \"%.\")\n    \n    -- Populate new tnplus_word.tokenized_phon layer\n    if #syllables == #tones then\n      index = 1\n      patterns = {}\n      bMatch = false\n      for _, phon in ipairs(tnplus_word.tokenized_phon) do\n        if #patterns == 0 then\n          for _, pattern in ipairs(def_vowel_patterns_esc) do\n            if string.find(syllables[index], pattern) then\n              patterns = def_vowel_patterns\n              break\n            end\n          end\n          if #patterns == 0 then\n            for _, pattern in ipairs(def_syllabic_patterns_esc) do\n              if string.find(syllables[index], pattern) then\n                patterns = def_syllabic_patterns\n                break\n              end\n            end\n          end\n        end\n          \n        if phon == \".\" then\n          table.insert(tnplus_word.tokenized_tone, \".\")\n          bMatch = false\n          index = index + 1\n          patterns = {}\n        else\n          if #patterns > 0 and engine_utils.has_element(patterns, phon) and not bMatch then\n            table.insert(tnplus_word.tokenized_tone, tones[index])\n            bMatch = true\n          else\n            table.insert(tnplus_word.tokenized_tone, \"\")\n          end\n        end\n      end\n    end\n    \n    -- Process syllable boundaries\n    if not syllable_boundary then\n      tnplus_word.phon = tnplus_word.phon:gsub(\"%.\", \"\")\n      engine_utils.remove_element(tnplus_word.tokenized_phon, \".\")\n      engine_utils.remove_element(tnplus_word.tokenized_tone, \".\")\n      tnplus_word.num_phon = #tnplus_word.tokenized_phon\n    end\n  \n  end\n\nend\n\n\n--function engine_utils.tnplus_words_normalize_language_value (tnplus_words, language_mapping)\n  \n--  for wordIdx, tnplus_word in ipairs(tnplus_words) do \n--    -- lowercase language value\n--    tnplus_word.metadata.language = string.lower(tnplus_word.metadata.language)\n--    -- replace language value with another \n--    -- should be done for example for \"enx\"-->\"enu\"\n--    -- could also be used to map \"latin\" to a real language code.\n--    if language_mapping ~= nil then\n--      for map_lang_from, map_lang_to in pairs(language_mapping) do      \n--        if tnplus_word.metadata.language == map_lang_from then\n--          tnplus_word.metadata.language = map_lang_to\n--          break\n--        end\n--      end\n--    end\n--  end\n  \n--end\n\n\n--------------------------------------------------------\n--  Convert result object to a JSON string\n--  In case we are running in the dev-environment, \n--  will also return the list of features (needed to\n--  be able to compare with the output of existing python \n--  implementations)\n---------------------------------------------------------\n\n--------------------------------------------------------\n--  Don't change below strings!  \n--------------------------------------------------------\n\nengine_utils.KEY_TYPE=\"type\"\nengine_utils.KEY_TYPE_AUDIOSRC=\"audiosrc\"\nengine_utils.KEY_TYPE_PHON=\"phon\"\nengine_utils.KEY_TYPE_PUNC=\"punc\"\nengine_utils.KEY_TYPE_SUPRASEGMENTAL=\"suprasegm\"\nengine_utils.KEY_TYPE_INTERWORD=\"interword\"\nengine_utils.KEY_TYPE_SILENCE=\"silence\"\nengine_utils.KEY_TYPE_ENDOFSEQUENCE=\"end-of-sequence\"\nengine_utils.KEY_TYPE_ENDOFSENTENCE=\"end-of-sentence\"\n\n\nengine_utils.KEY_FEAT=\"feat\"\nengine_utils.KEY_ATTR=\"attr\"  \nengine_utils.KEY_DURMSEC=\"dur\"\n   \n    \nlocal function json_serialize_bet7featex_chunk (chunk, result_chunks)\n  result_chunk={}\n  for _, elem in ipairs(chunk) do\n    result_elem={}\n    if elem[\"attr\"] ~= nil then\n      -- if we have a backslash or a double quote, then preceed with escape character ''\n      table.insert(result_elem, '\"attr\"'.. \":\" ..'\"' .. elem[\"attr\"]:gsub('[\\\\\"]', \"\\\\%1\") .. '\"' )\n    end\n    if elem[\"dur\"] ~= nil then\n      table.insert(result_elem, '\"dur\"'.. \":\" ..tostring(elem[\"dur\"]))\n    end\n    if elem[\"feat\"] ~= nil then\n      table.insert(result_elem, '\"feat\"'.. \":\" ..tostring(elem[\"feat\"]))\n    end\n    if elem[\"pitch\"] ~= nil then\n      table.insert(result_elem, '\"pitch\"'.. \":\" ..tostring(elem[\"pitch\"]))\n    end\n    if elem[\"rate\"] ~= nil then\n      table.insert(result_elem, '\"rate\"'.. \":\" ..tostring(elem[\"rate\"]))\n    end\n    if elem[\"styleintensity\"] ~= nil then\n      table.insert(result_elem, '\"styleintensity\"'.. \":\" ..'\"'..elem[\"styleintensity\"]..'\"')\n    end\n    if elem[\"stylename\"] ~= nil then\n      table.insert(result_elem, '\"stylename\"'.. \":\" ..'\"'..elem[\"stylename\"]..'\"')\n    end\n    if elem[\"timbre\"] ~= nil then\n      table.insert(result_elem, '\"timbre\"'.. \":\" ..tostring(elem[\"timbre\"]))\n    end\n    if elem[\"type\"] ~= nil then\n      table.insert(result_elem, '\"type\"'.. \":\" ..'\"'..elem[\"type\"]..'\"')\n    end\n    if elem[\"volume\"] ~= nil then\n      table.insert(result_elem, '\"volume\"'.. \":\" ..tostring(elem[\"volume\"]))\n    end  \n    table.insert(result_chunk,  \"{\" .. table.concat(result_elem, \",\") .. \"}\" )\n  end\n  table.insert(result_chunks, \"[\" .. table.concat(result_chunk, \",\") .. \"]\" )\nend\n\nlocal function bet7featex_result_to_json (result)  \n  result_chunks={}\n  for _, chunk in ipairs(result) do \n    json_serialize_bet7featex_chunk(chunk, result_chunks)\n  end  \n  return \"[\" .. table.concat(result_chunks, \",\") .. \"]\" \nend\n\nfunction engine_utils.result_to_json(result)\n  \n  Log.log(\"Entering 'result_to_json'\")\n  \n  if _G[\"dev_environment\"]== true and _G[\"generate_idx\"]==true then\n    TC2_frame_length = (256 / 22050) * 1000    -- AI Team uses 11.6 ms\n    indices={}\n    for iChunk, chunk in ipairs(result) do\n      sildurfrms=nil\n      for i, elem in ipairs (chunk) do        \n        if elem[engine_utils.KEY_FEAT] ~= nil then\n          table.insert(indices, elem[engine_utils.KEY_FEAT])\n        end\n        if elem[engine_utils.KEY_DURMSEC] ~= nil then          \n          sildurfrms=tonumber(string.format(\"%.0f\", elem[engine_utils.KEY_DURMSEC] / TC2_frame_length))\n        end\n      end -- for i\n      if sildurfrms == nil then\n        error(\"something wrong\")\n      end      \n      table.insert(indices, sildurfrms)\n    end  -- for iChunk\n  end -- dev_environment\n    \n  jsonout=bet7featex_result_to_json (result) \n  Log.log(\"Done 'result_to_json'\")\n  \n  if _G[\"dev_environment\"]== true then\n    return jsonout, indices\n  else\n    return jsonout\n  end\n  \nend\n\n\n\n----------------------------------------------------\n--  SOME GENERIC FUNCTIONS\n----------------------------------------------------\n\n-- Split text (\"in_text\") according to separator (\"separator\")\nfunction engine_utils.split(in_text, separator)\n  local out_text={}\n  if separator == nil then\n    separator = \"%s\"\n  end\n  for s in string.gmatch(in_text, \"([^\"..separator..\"]+)\") do\n    table.insert(out_text, s)\n  end\n  return out_text\nend\n\n\n-- Check whether table (\"in_table\") contains one element (\"in_element\")\nfunction engine_utils.has_element(in_table, in_element)\n  for valueIdx, value in ipairs(in_table) do\n    if value == in_element then\n      return true\n    end\n  end\n  return false\nend\n\n\n-- Remove all occurrences of one element (\"in_element\") from table (\"in_table\")\nfunction engine_utils.remove_element(in_table, in_element)\n  for i=#in_table,1,-1 do\n    if in_table[i] == in_element then\n      table.remove(in_table, i)\n    end\n  end\nend\n\n\n-- Compute length of table (\"in_table\")\nfunction engine_utils.length(in_table)\n  local count = 0\n  for valueIdx, value in pairs(in_table) do\n    count = count + 1\n  end\n  return count\nend\n\n\n-- Escape lua magic characters in string (\"in_string\")\nfunction engine_utils.escape(in_string)\n  local magic_characters = {\"(\", \")\", \".\", \"%\", \"+\", \"-\", \"*\", \"?\", \"[\", \"^\", \"$\"}\n  for _, character in ipairs(magic_characters) do\n    patt = \"%\" .. character\n    if character == \"%\" then\n      repl = \"%%%\" .. character\n    else\n      repl = \"%%\" .. character\n    end\n    in_string = in_string:gsub(patt, repl)\n  end\n  return in_string\nend\n\n\n-- Log important messages\nfunction engine_utils.log_important_message(message)\n  if _G[\"dev_environment\"]== true then\n    -- When running in dev environment, always print this message\n    if _G[\"current_file\"] ~= nil then\n      print (_G[\"current_file\"]..\": \"..message)\n    else\n      print(message)\n    end\n  else\n    -- Otherwise depends on Log.bLoggingEnabled (when running in the dev environment, see log stub) \n    -- or on the log level set in the product (when running in the engine)\n    Log.log(message)\n  end\nend\n\nfunction engine_utils.abs(val)\n  if val < 0 then\n    return 0-val\n  else\n    return val\n  end\nend\n\n\nreturn engine_utils\n\nend\n\n-- GENLUA END   file engine_utils.lua\n-- GENLUA ---------------------------------------------------\n\n\n-- GENLUA ---------------------------------------------------\n-- GENLUA BEGIN file engine_config.lua\n\nload_module_engine_config = function()\n\n\n-- READ_ONLY SCRIPT - DO NOT MODIFY !!\n-- COMPILED INSIDE THE ENGINE\n-- Please contact NLP or SW team in case some changes are required.\n\n-- GENLUA engine_utils=require(\"engine_utils\")\n-- GENLUA --require(\"dict_phon_and_punc\")  -- voice dependent \n\nlocal engine_config={}\n\nengine_config.SSFT_PARAMC_BET7TOKENCONVERTER_MODEL=\"bet7tokenconverter_model\"\nengine_config.SSFT_PARAMC_BET7FEATEX_CHUNK_ON_MARKUP=\"bet7featex_chunkonmarkup\"\nengine_config.SSFT_PARAMC_BET7FEATEX_MAXWORDSPERCHUNK=\"bet7featex_maxwordsperchunk\"\nengine_config.SSFT_PARAMC_BET7FEATEX_MAXPHONSPERCHUNK=\"bet7featex_maxphonsperchunk\"\nengine_config.SSFT_PARAMC_BET7FEATEX_MAXPHRASESPERCHUNK=\"bet7featex_maxphrasesperchunk\"\n\n\nfunction engine_config.init_for_tc2()\n  \n  if engine_config.model == \"tc2\" then \n    return -- already initialized\n  end  \n  Log.log(\"Entering 'engine_config.init_for_tc2'\")\n  engine_config.model=\"tc2\"\n  -- TC2 does not support \"volume\", \"rate\" and \"pitch\" changes yet (future support will be implemented using post-processing),\n  -- so also don't chunk on those changes.\n  -- engine_config.chunk_on_markup={\"stylename\", \"styleintensity\", \"sildur\", \"audiosrc\", \"volume\", \"rate\", \"pitch\", \"timbre\"}  \n  engine_config.chunk_on_markup={\"stylename\", \"styleintensity\", \"sildur\", \"audiosrc\", \"timbre\"}    \n  Log.log(\"Done 'engine_config.init_for_tc2'\")\nend\n\nfunction engine_config.init_for_parlotron()\n  \n  if engine_config.model == \"parlotron\" then \n    return -- already initialized\n  end\n  Log.log(\"Entering 'engine_config.init_for_parlotron'\")\n  engine_config.model=\"parlotron\"\n  engine_config.chunk_on_markup={\"stylename\", \"styleintensity\", \"sildur\", \"audiosrc\"}  \n  -- Determine the index corresponding to the silence\n  -- If it is not explicitly defined, which is the default, the index is assume to be the \n  -- highest index corresponding to a phoneme.\n  if parlotron_silence_to_idx == nil then\n    parlotron_silence_to_idx=0\n    -- find the highest index\n    for phon, idx in pairs(dict_phon_to_idx) do\n      if idx > parlotron_silence_to_idx then\n        parlotron_silence_to_idx = idx\n      end\n    end\n    -- and increase with one : that is the index corresponding with the silence\n    parlotron_silence_to_idx = parlotron_silence_to_idx + 1\n  end    \n    \n  -- for all tables : shift the index with one\n  for punc, idx in pairs(dict_punc_to_idx) do\n    if idx >= parlotron_silence_to_idx then\n      dict_punc_to_idx[punc]=idx+1\n    end\n  end\n  \n  for phon, idx in pairs(dict_phon_to_idx) do\n    if idx >= parlotron_silence_to_idx then\n      dict_phon_to_idx[punc]=idx+1\n    end\n  end  \n  \n  for punc, idx in pairs(dict_open_punc_to_idx) do\n    if idx >= parlotron_silence_to_idx then\n      dict_open_punc_to_idx[punc]=idx+1\n    end\n  end\n    \n  for punc, idx in pairs(dict_close_punc_to_idx) do\n    if idx >= parlotron_silence_to_idx then\n      dict_close_punc_to_idx[punc]=idx+1\n    end\n  end\n  \n  -- and now add to the dict_phon_to_idx\n  dict_phon_to_idx[\"#\"] = parlotron_silence_to_idx\n  \n  Log.log(\"Done 'engine_config.init_for_parlotron'\")\nend \n\n\nfunction engine_config.set_chunk_on_markup(chunk_on_markup)\n  elems=engine_utils.split(chunk_on_markup, \", \")\n  if elems ~= nil and #elems > 0 then\n    engine_config.chunk_on_markup={}\n    for i, elem in ipairs (elems) do\n      table.insert(engine_config.chunk_on_markup, elem)\n    end\n  end\nend\n\n\nfunction engine_config.init(mode)\n  \n  if mode ~= nil and string.lower(mode) == \"embedded\" then\n    Log.log(\"Entering 'engine_config.init' (embedded mode)\")\n    bEmbedded=true\n  else\n    Log.log(\"Entering 'engine_config.init'\")\n    bEmbedded=false\n  end\n  \n  model=Parameters.get(engine_config.SSFT_PARAMC_BET7TOKENCONVERTER_MODEL)\n  if model == nil or model==\"\" then\n    model=\"tc2\"\n  end\n  \n  model =string.lower(model)\n  if model == \"parlotron\" then\n    engine_config.init_for_parlotron()\n  else\n    engine_config.init_for_tc2()\n  end\n    \n  Log.log(\"Chunking parameter 'engine_config.chunk_on_markup':\")\n  strValue=Parameters.get(engine_config.SSFT_PARAMC_BET7FEATEX_CHUNK_ON_MARKUP)  \n  if strValue ~= nil and #strValue > 0 then\n    engine_config.set_chunk_on_markup(strValue) -- comma separated list of markup ids on which we want to do chunking\n    Log.log(\"  using value from engine parameter <\"..engine_config.SSFT_PARAMC_BET7FEATEX_CHUNK_ON_MARKUP..\"> : \" .. table.concat(engine_config.chunk_on_markup, \", \"))\n  else\n    Log.log(\"  using default value : \" .. table.concat(engine_config.chunk_on_markup, \", \"))\n  end\n  \n  Log.log(\"Chunking parameter 'engine_config.max_words_per_chunk':\")\n  strValue = Parameters.get(engine_config.SSFT_PARAMC_BET7FEATEX_MAXWORDSPERCHUNK)\n  if strValue ~= nil and #strValue > 0 then    \n    max_words_per_chunk = tonumber(strValue)\n    Log.log(\"  using value from engine parameter <\"..engine_config.SSFT_PARAMC_BET7FEATEX_MAXWORDSPERCHUNK..\"> :  \".. tostring(max_words_per_chunk))\n  elseif bEmbedded == true and max_words_per_chunk_embedded ~= nil then\n    max_words_per_chunk = max_words_per_chunk_embedded\n    Log.log(\"  using embedded-specific value :  \".. tostring(max_words_per_chunk))    \n  else\n    Log.log(\"  using default value : \"..tostring(max_words_per_chunk))\n  end\n  \n  Log.log(\"Chunking parameter 'engine_config.max_phons_per_chunk':\")\n  strValue = Parameters.get(engine_config.SSFT_PARAMC_BET7FEATEX_MAXPHONSPERCHUNK)\n  if strValue ~= nil and #strValue > 0 then    \n    max_phons_per_chunk = tonumber(strValue)\n    Log.log(\"  using value from engine parameter <\"..engine_config.SSFT_PARAMC_BET7FEATEX_MAXPHONSPERCHUNK..\"> : \".. tostring(max_phons_per_chunk))\n  elseif bEmbedded == true and max_phons_per_chunk_embedded ~= nil then\n    max_phons_per_chunk = max_phons_per_chunk_embedded\n    Log.log(\"  using embedded-specific value :  \".. tostring(max_phons_per_chunk))\n  else\n    Log.log(\"  using default value : \" ..tostring(max_phons_per_chunk))\n  end\n  \n  Log.log(\"Chunking parameter 'engine_config.max_phrases_per_chunk':\")\n  strValue = Parameters.get(engine_config.SSFT_PARAMC_BET7FEATEX_MAXPHRASESPERCHUNK)\n  if strValue ~= nil and #strValue > 0 then    \n    max_phrases_per_chunk = tonumber(strValue)\n    Log.log(\"  using value from engine parameter <\"..engine_config.SSFT_PARAMC_BET7FEATEX_MAXPHRASESPERCHUNK..\"> : \".. tostring(max_phrases_per_chunk))\n  elseif bEmbedded == true and max_phrases_per_chunk_embedded ~= nil then\n    max_phrases_per_chunk = max_phrases_per_chunk_embedded\n    Log.log(\"  using embedded-specific value :  \".. tostring(max_phrases_per_chunk))\n  elseif max_phrases_per_chunk == nil then\n    Log.log(\"  not used\")\n  else\n    Log.log(\"  using default value : \" ..tostring(max_phrases_per_chunk))\n  end\n  \n  Log.log(\"Done 'engine_config.init'\")\n                   \nend\n\nreturn engine_config\n\nend\n\n-- GENLUA END   file engine_config.lua\n-- GENLUA ---------------------------------------------------\n\n\n-- GENLUA ---------------------------------------------------\n-- GENLUA BEGIN file engine_bet7_featex.lua\n\nload_module_engine_bet7_featex = function()\n\n\n-- READ_ONLY SCRIPT - DO NOT MODIFY !!\n-- COMPILED INSIDE THE ENGINE\n-- Please contact NLP or SW team in case some changes are required.\n\n-- GENLUA local engine_config=require(\"engine_config\")\n-- GENLUA local engine_utils=require(\"engine_utils\")\n--\n-- GENLUA require(\"dict_phon_and_punc\")\n-- GENLUA require(\"dict_chunking\")\n\nlocal engine_bet7_featex={}\n\n----------------------------------------------------\n-- Initialization\n-- Should be called only once.\n----------------------------------------------------\n\nlocal function init_variables()\n  -- Default values for variables and tables that can be customized by the user (to ensure compatibility with existing voices)\n  if syllable_boundary == nil then\n    -- keep ('true') or remove ('false') syllable boundaries\n    syllable_boundary = false\n  end\n  if primary_stress == nil then\n    -- keep ('true') or remove ('false') primary stresses\n    primary_stress = true\n  end\n  if secondary_stress == nil then\n    -- keep ('true') or remove ('false') secondary stresses\n    secondary_stress = false\n  end\n  if punc_oriorthjoined == nil then\n    -- keep ('true') or remove ('false') \"DASH\", \"OPEN_DASH\" and \"DASHHYPHEN_LINK\" when tnplus_word.metadata.bOriOrthJoined set to 'true'\n    punc_oriorthjoined = true\n  end\n  if soft_question == nil then\n    -- disable soft-question support\n    soft_question = false\n  end\n  if tones == nil then\n    -- add tones from TN+ JSON metadata layer ('true') or not ('false')\n    tones = false\n  end\n  if def_vowel_patterns == nil then\n    -- vowel patterns definition, in case tones have to be added from TN+ JSON metadata layer\n    def_vowel_patterns = {}\n  end\n  if def_syllabic_patterns == nil then\n    -- syllabic patterns definition, in case tones have to be added from TN+ JSON metadata layer\n    def_syllabic_patterns = {}\n  end\n  if dict_phon_to_phon == nil then\n    -- optional phonetic mapping\n    dict_phon_to_phon = {}\n  end\n  if dict_open_punc_to_open_punc == nil then\n    -- optional open punctuation mapping\n    dict_open_punc_to_open_punc = {}\n  end\n  if dict_close_punc_to_close_punc == nil then\n    -- optional close punctuation mapping\n    dict_close_punc_to_close_punc = {}\n  end  \n  \n  -- Finally, call the language/voice specific function, if any.\n  if customized_init_variables ~= nil then\n    customized_init_variables()\n  end\n  \nend\n\n\n-- For mode==\"embedded\", the feature extractor will use the embedded (voice specific) chunking parameters.\n-- Otherwise the default (voice specific) parameters will be used.\nfunction bet7_featex_init(mode)\n  engine_config.init(mode)\n  init_variables() -- In case some customization would be required,see the call to function voice_init_variables()\n  return \"\" -- dummy return\nend\n\n----------------------------------------------------\n-- Main entry point function\n----------------------------------------------------\nfunction bet7_featex_process(tnplus_words)    \n    \n  outJSON = \"\"\n  \n  -- Basic check if the words in tnplus_words have all the fields required (different from nil).\n  -- That should actually always be the case, and if not, that may indicate a bug, or perhaps shortage in memory?\n  if engine_utils.tnplus_words_sanity_check(tnplus_words) == true then  \n      \n      ---------------------------------------------------------\n      -- (0) Remove words with empty phonetics. \n      --     We do so because they are unexpected/invalid\n      --     and we do not want to bother with those words\n      --     in further processing\n      --     Note however that we may still end up with\n      --     empty phonetics in case the full phonetic \n      --     transcription was invalid (but that we know only later on).\n      ---------------------------------------------------------\n      remove_words_with_empty_phonetics (tnplus_words)      \n      \n      \n      ---------------------------------------------------------\n      -- (1) Set chunk boundaries based on the markup\n      ---------------------------------------------------------\n      pre_chunk_based_on_markup (tnplus_words)      \n      \n      \n      ---------------------------------------------------------\n      -- (2) Apply TN+ word adaptations\n      ---------------------------------------------------------      \n      if customized_apply_adaptations == nil then\n        -- Use the implementation in the shared engine's lua code.\n        -- Should be the main workflow.\n        apply_adaptations(tnplus_words)\n      else\n        -- Use language/voice customized implementation.\n        -- !! This path should be trigged only exceptionally !!\n        -- !! Please check with NLP / SW team. !!\n        customized_apply_adaptations(tnplus_words)\n      end\n      \n      \n      ---------------------------------------------------------\n      -- (3) Tokenize the phonetics\n      ---------------------------------------------------------      \n      -- For efficiency : tokenize and count the phonetics only once.\n      -- This function sets the tnplus_word.tokenized_phon and tnplus_word.num_phon\n      engine_utils.tokenize_phonetics(tnplus_words)\n      \n      \n      ---------------------------------------------------------\n      -- (4) Optionally tokenize the tones\n      ---------------------------------------------------------      \n      if tones then\n        \n        def_vowel_patterns_esc = {}\n        if #def_vowel_patterns > 0 then\n          for patternIdx, pattern in ipairs(def_vowel_patterns) do\n            table.insert(def_vowel_patterns_esc, engine_utils.escape(pattern))\n          end\n        else\n          engine_utils.log_important_message(\"Error: 'def_vowel_patterns' empty or not defined in 'dict_phon_and_punc.lua'!\")\n        end\n        \n        def_syllabic_patterns_esc = {}\n        if #def_syllabic_patterns > 0 then\n          for patternIdx, pattern in ipairs(def_syllabic_patterns) do\n            table.insert(def_syllabic_patterns_esc, engine_utils.escape(pattern))\n          end\n        else\n          engine_utils.log_important_message(\"Error: 'def_syllabic_patterns' empty or not defined in 'dict_phon_and_punc.lua'!\")\n        end\n        \n        engine_utils.tokenize_tones(tnplus_words)\n        \n      end\n      \n      \n      ---------------------------------------------------------\n      -- (5) Mark chunk boundaries\n      ---------------------------------------------------------            \n      if customized_mark_chunk_boundaries == nil then        \n      -- Use the implementation in the shared engine's lua code.\n      -- Should be the main workflow.\n        mark_chunk_boundaries(tnplus_words)\n      else\n      -- Use language/voice customized implementation.\n      -- !! This path should be trigged only exceptionally !!\n      -- !! Please check with NLP / SW team. !!\n        customized_mark_chunk_boundaries(tnplus_words)\n      end\n      \n      \n      ---------------------------------------------------------\n      -- (6) Apply postchunk TN+ word adaptations\n      ---------------------------------------------------------\n      if customized_postchunk_apply_adaptations ~= nil then\n        customized_postchunk_apply_adaptations(tnplus_words)\n      end\n      \n      \n      ---------------------------------------------------------------------\n      -- (7) Convert phonemes/punctuations sequence into integers sequence\n      ---------------------------------------------------------------------\n      if customized_interleave_phon_punc_chunk == nil then\n      -- Use the implementation in the shared engine's lua code.\n      -- Should be the main workflow\n        result = interleave_phon_punc_chunk(tnplus_words)  \n      else\n      -- Use language/voice customized implementation.\n      -- !! This path should be trigged only exceptionally !!\n      -- !! Please check with NLP / SW team !!\n        result = customized_interleave_phon_punc_chunk(tnplus_words)\n      end      \n\n\n      ---------------------------------------------------------------------\n      -- (8) Save integers sequence to JSON format\n      ---------------------------------------------------------------------      \n      -- convert to json\n      -- indices used in dev environement only (to compare with python impl) and will be nil in the product.  \n      outJSON, indices = engine_utils.result_to_json(result)\n  \n  end\n  \n  \n  return outJSON,indices\n  \nend\n\n\n\n\nfunction apply_adaptations(tnplus_words)\n  \n  -- Apply TN+ word adaptations (language-(in)dependent)\n  \n  Log.log(\"Entering 'apply_adaptations'\")\n  \n  -- add EOS FULL_STOP if missing \n  bEOS = false\n  punctuations = engine_utils.split(tnplus_words[#tnplus_words].punc_end, \"|\")\n  if tnplus_words[#tnplus_words].punc_end == nil or\n     tnplus_words[#tnplus_words].punc_end == \"\" then\n    tnplus_words[#tnplus_words].punc_end = \"FULL_STOP\"\n    bEOS = true\n  elseif punctuations[#punctuations] == \"QUOTE\" or\n         punctuations[#punctuations] == \"EMPH_QUOTE\" or\n         punctuations[#punctuations] == \"SHRTMSG_QUOTE\" or\n         punctuations[#punctuations] == \"LONGMSG_QUOTE\" or\n         punctuations[#punctuations] == \"SQUOTE\" or\n         punctuations[#punctuations] == \"EMPH_SQUOTE\" or\n         punctuations[#punctuations] == \"SHRTMSG_SQUOTE\" or\n         punctuations[#punctuations] == \"LONGMSG_SQUOTE\" or\n         punctuations[#punctuations] == \"PAIRED_PARENTH\" or\n         punctuations[#punctuations] == \"PAIRED_SQUAREBRACKET\" or\n         punctuations[#punctuations] == \"PAIRED_CURLYBRACKET\" then\n    tnplus_words[#tnplus_words].punc_end = tnplus_words[#tnplus_words].punc_end .. \"|FULL_STOP\"    \n    bEOS = true    \n  end\n  \n  if bEOS == true then\n    engine_utils.log_important_message(\"Warning: missing final punctuation or final punctuation composed only by quotes/parentheses/brackets. Full-stop inserted.\")\n  end\n  \n  for wordIdx, tnplus_word in ipairs(tnplus_words) do\n    -- replace underscore symbol with syllable boundary (dot) symbol in TN+ JSON phonetic stream\n    strPhon = tnplus_word.phon:gsub(\"_\", \".\")\n    if strPhon ~= tnplus_word.phon then\n      engine_utils.log_important_message(\"Warning: underscore symbol found TN+ JSON phonetic stream for word '\" .. tnplus_word.orth .. \"' ('\" .. tnplus_word.phon .. \"'). Replacing with syllable boundary (dot) symbol.\")\n      tnplus_word.phon = strPhon\n    end\n  end\n  \n  if tnplus_words[#tnplus_words].metadata[\"break\"] ~= \"sent\" then\n    tnplus_words[#tnplus_words].metadata[\"break\"] = \"sent\"\n    engine_utils.log_important_message(\"Warning: wrong EOS break in TN+ JSON metadata stream. Corrected to 'sent'.\")\n  end\n  \n  if not syllable_boundary and not tones then\n    -- remove syllable boundaries\n    for wordIdx, tnplus_word in ipairs(tnplus_words) do\n      tnplus_word.phon = tnplus_word.phon:gsub(\"%.\", \"\")\n    end\n  end\n  \n  if not primary_stress then\n    -- remove primary stresses\n    for wordIdx, tnplus_word in ipairs(tnplus_words) do\n      tnplus_word.phon = tnplus_word.phon:gsub(\"'([^2])\", \"%1\")\n    end\n  end\n  \n  if not secondary_stress then\n    -- remove secondary stresses\n    for wordIdx, tnplus_word in ipairs(tnplus_words) do\n      tnplus_word.phon = tnplus_word.phon:gsub(\"'2\", \"\")\n    end\n  end\n  \n  for wordIdx, tnplus_word in ipairs(tnplus_words) do\n    -- optional open punctuation mapping\n    if next(dict_open_punc_to_open_punc) ~= nil then\n      if tnplus_word.punc_beg ~= \"\" then\n        punctuations = engine_utils.split(tnplus_word.punc_beg, \"|\")\n        punctuations_pp = {}\n        for punctuationIdx, punctuation in ipairs(punctuations) do\n          punc = dict_open_punc_to_open_punc[punctuation]\n          if punc == nil then\n            table.insert(punctuations_pp, punctuation)\n          else\n            if punc ~= \"\" then\n              table.insert(punctuations_pp, punc)\n            end\n          end\n        end\n        tnplus_word.punc_beg = table.concat(punctuations_pp, \"|\")\n      end\n    end\n    \n    -- optional close punctuation mapping\n    if next(dict_close_punc_to_close_punc) ~= nil then\n      if tnplus_word.punc_end ~= \"\" then\n        punctuations = engine_utils.split(tnplus_word.punc_end, \"|\")\n        punctuations_pp = {}\n        for punctuationIdx, punctuation in ipairs(punctuations) do\n          punc = dict_close_punc_to_close_punc[punctuation]\n          if punc == nil then\n            table.insert(punctuations_pp, punctuation)\n          else\n            if punc ~= \"\" then\n              table.insert(punctuations_pp, punc)\n            end\n          end\n        end\n        tnplus_word.punc_end = table.concat(punctuations_pp, \"|\")\n      end\n    end\n  end\n  \n  if soft_question then\n    -- soft-question support\n    for wordIdx, tnplus_word in ipairs(tnplus_words) do\n      if tnplus_words[wordIdx].metadata.phrasetype ~= 'Y' then \n        tnplus_words[wordIdx].punc_end = tnplus_words[wordIdx].punc_end:gsub(\"QUESTION_MARK\", \"SOFT_QUESTION_MARK\")\n      end\n    end\n  end\n  \n  if final_stream_transform ~= nil then\n    -- optional language/voice final stream transformation\n    final_stream_transform(tnplus_words)\n  end\n  \n  Log.log(\"Done 'apply_adaptations'\")\nend\n\nfunction hlp_find_weak_closest_to_middle (tnplus_words, idxStart, idxLast)\n  -- We currently only use this function to find the middle word (in terms of number of phonemes) with \"weak\" boundary, \n  -- but we could possibly also use it for the other options.\n  -- Then simply add a 'chunking_option' parameter to this function, eg\n  --   chunking_option=1 : \"break\" equals \"strong\" or \"sent\"\n  --   chunking_option=2 : \"break\" equals \"weak\"\n  --   chunking_option=3 : punctuation\n  -- And replace the conditions in the while loops with something like:\n --  if (chunking_option == 1 and (tnplus_words[k].metadata[\"break\"] == \"strong\" or tnplus_words[k].metadata[\"break\"] == \"sent\")) or\n --     (chunking_option == 2 and tnplus_words[k].metadata[\"break\"] == \"weak\")  or\n--      (chunking_option == 3 and tnplus_words[k].punc_end ~= \"\" )  then\n \n  local tot_num_phons\n  local middle_num_phons\n  local k  \n  local accum_num_phons = {}\n  local bAtLeastOne = false\n  local best_idx\n  local best_dist\n  \n  -- accum_num_phons[j]                         = number of phonemes in words  [idxStart, idxStart + j - 1 ]\n  -- number of phonemes in words [idxStart, k]  = accum_num_phons[k - idxStart + 1]\n  tot_num_phons = 0\n  bAtLeastOne = false\n  k=idxStart\n  while k <= idxLast do\n    tot_num_phons=tot_num_phons+tnplus_words[k].num_phon\n    table.insert(accum_num_phons,tot_num_phons)\n    if tnplus_words[k].metadata[\"break\"] == \"weak\" then\n      bAtLeastOne = true\n    end\n    k=k+1    \n  end\n  \n  if bAtLeastOne == false then\n    return nil -- we don't have any word with a weak break, no use to continue\n  end\n  \n  -- find the word with a weak break which is the closest to the middle (in terms of number of phonemes)\n  middle_num_phons=tot_num_phons/2  \n  \n  best_idx=nil\n  best_dist=nil\n  k=idxStart\n  while k <= idxLast do\n    if (tnplus_words[k].metadata[\"break\"] == \"weak\")  then\n      dist=engine_utils.abs(accum_num_phons[k - idxStart + 1]-middle_num_phons)\n      if (best_dist == nil or dist < best_dist) then\n        best_dist=dist\n        best_idx=k\n      else\n        -- dist has become >= best_dist, we can stop \n        break\n      end\n    end\n    k=k+1\n  end \n  return best_idx\nend\n\n\n\nfunction mark_chunk_boundaries(tnplus_words)\n  \n  -- CNTTS-based chunking algorithm triggers at sentence level.\n  -- In case of overlong sentence, i.e. when the CNTTS-based chunking algorithm determines that on a particular word, either \"max_words_per_chunk\" or \"max_phons_per_chunk\" limit is exceeded, the algorithm looks behind for the latest Front-End predicted pause (i.e. for a word having break = \"strong\" or \"sent\"), if any: if it finds one, it chunks at that position; if not, it chunks at the current word where at least one of the above-mentioned limit is exceeded. \n  -- Each CNTTS-based chunk should end with a punctuation symbol as defined in \"dict_chunk_split_symbols_strong\". If it is not the case, the current ending punctuation symbol(s), if any, are removed and replaced with the fallback symbol only, as defined in \"dict_chunk_fallback_symbol\".\n  \n  Log.log(\"Entering 'mark_chunk_boundaries'\")\n\n  local num_word = 0\n  local num_phon = 0   \n  \n  -- Robustness check\n  if #tnplus_words == 0 then\n    return\n  end\n  \n  -- First step:  \n  --   Chunk based on punctuation.   \n  for wordIdx, tnplus_word in ipairs(tnplus_words) do \n    punctuations = engine_utils.split(tnplus_word.punc_end, \"|\")\n    -- if we have more than one punctuation at the end, then take the last one\n    if engine_utils.has_element(dict_chunk_split_symbols, punctuations[#punctuations]) then\n      tnplus_word.chunk=true\n    end\n  end\n  --  Also set a chunk boundary at the end of the sentence\n  tnplus_words[#tnplus_words].chunk=true\n    \n      \n  -- Second round: further chunking for the chunks which exceed user-defined max number of words or phonemes\n  idxStartCurrentChunk=1\n  idxWord=idxStartCurrentChunk\n  num_word=0\n  num_phon=0  \n  num_phrase=0\n  while idxWord <= #tnplus_words do    \n    num_word=num_word + 1\n    num_phon=num_phon + tnplus_words[idxWord].num_phon\n    if tnplus_words[idxWord].metadata[\"break\"] == \"strong\" or tnplus_words[idxWord].metadata[\"break\"] == \"sent\" then\n      num_phrase = num_phrase + 1\n    end\n    if ( idxWord > 1 and \n         (num_word > max_words_per_chunk or \n          num_phon > max_phons_per_chunk or \n          (max_phrases_per_chunk ~= nil and num_phrase > max_phrases_per_chunk)\n         ) \n        ) then\n      -- Too many words, phonemes or phrases. Need to chunk.\n      -- Always going from right to left, find a good place to chunk\n      -- (1) first option : do we have \"strong\" or \"sent\" break on which we can chunk?\n      idx=idxWord-1\n      bChunked=false\n      while idx >= idxStartCurrentChunk do\n        --we cannot write .break because that confuses the interpreter\n        if tnplus_words[idx].metadata[\"break\"] == \"strong\" or tnplus_words[idx].metadata[\"break\"] == \"sent\" then\n          tnplus_words[idx].chunk=true\n          idxStartCurrentChunk=idx+1\n          bChunked=true\n          break\n        end\n        idx=idx-1\n      end\n      if bChunked==false then --could not find a \"strong\" or \"sent\" break on which we could chunk...\n        -- (2) Second option : do we have \"weak\" break on which we can chunk? and if so, find the closest one to the middle (in terms of number of phonemes)\n        best_idx=hlp_find_weak_closest_to_middle (tnplus_words, idxStartCurrentChunk, idxWord-1)\n        if best_idx ~= nil then\n          tnplus_words[best_idx].chunk=true\n          idxStartCurrentChunk=best_idx+1\n          bChunked=true        \n        end\n      end\n      if bChunked==false then --still could not find a good place to chunk\n        -- (3) third option : do we have a word with an end-punctuation?\n        idx=idxWord-1\n        while idx >= idxStartCurrentChunk do\n          -- from right to left : do we have a word with an end-punctuation          \n          if tnplus_words[idx].punc_end ~= \"\" then \n            tnplus_words[idx].chunk=true\n            idxStartCurrentChunk=idx+1\n            bChunked=true\n            break\n          end\n          idx=idx-1\n        end\n      end      \n      if bChunked == false then --still could not find a good place to chunk\n        -- (4) last option : force a chunk at the previous word position\n        if idxWord-1 >= idxStartCurrentChunk then \n          tnplus_words[idxWord-1].chunk = true\n          idxStartCurrentChunk=idxWord          \n        else \n          -- Nothing we can do, but should not happen (current word exceeds the max number of phonemes)\n          idxStartCurrentChunk = idxWord + 1\n        end\n      end      \n      num_word=0\n      num_phon=0\n      num_phrase=0\n      idxWord=idxStartCurrentChunk      \n    else\n      if tnplus_words[idxWord].chunk==true then\n        num_word=0\n        num_phon=0\n        num_phrase=0\n        idxStartCurrentChunk=idxWord+1\n      end\n      idxWord=idxWord+1\n    end\n  end\n    \n    \n  -- Assure punctuation at each and every chunk boundary\n  for wordIdx, tnplus_word in ipairs(tnplus_words) do       \n    if tnplus_word.chunk==true then\n      punctuations = engine_utils.split(tnplus_word.punc_end, \"|\")\n      if not engine_utils.has_element(dict_chunk_split_symbols_strong, punctuations[#punctuations]) then\n        tnplus_word.punc_end = dict_chunk_fallback_symbol\n      end\n    end\n  end       \n  \n        \n  Log.log(\"Done 'mark_chunk_boundaries'\")\nend\n\n\n\nfunction add_elem_to_result(result_current_chunk, elem_type, elem_feat, elem_attr, elem_dur, elem_markup)\n  bHandlingSilenceForParlotron=false\n  \n  elem={}\n  if elem_feat ~= nil then\n    elem[engine_utils.KEY_FEAT]=elem_feat\n  end\n  if elem_type ~= nil then\n    elem[engine_utils.KEY_TYPE]=elem_type\n  end\n  if elem_attr ~=  nil then\n    elem[engine_utils.KEY_ATTR]=elem_attr\n  end\n  if elem_dur ~= nil then\n    elem[engine_utils.KEY_DURMSEC]=elem_dur\n    if engine_config.model == \"parlotron\" then\n      elem[engine_utils.KEY_ATTR]=\"#\"\n      elem[engine_utils.KEY_FEAT]=dict_phon_to_idx[\"#\"]\n      bHandlingSilenceForParlotron=true\n    end\n  end\n  if elem_markup ~= nil then\n    for markup_key, markup_val in pairs(elem_markup) do\n      if markup_val ~= nil then\n        elem[markup_key]=markup_val\n      end      \n    end\n  end\n  \n  if bHandlingSilenceForParlotron == true then\n    -- Find the last \"phon\" or \"audiosrc\", after which we will insert the silence\n    bDone=false\n    for iResult=#result_current_chunk,1,-1 do\n      if result_current_chunk[iResult][engine_utils.KEY_TYPE]==engine_utils.KEY_TYPE_PHON or\n         result_current_chunk[iResult][engine_utils.KEY_TYPE]==engine_utils.KEY_TYPE_AUDIOSRC then      \n        table.insert(result_current_chunk, iResult+1, elem)\n        bDone=true\n        break    \n      end\n    end\n    if bDone == false then\n    -- Could not find a \"phon\" or \"audiosrc\" in the current chunk.  Can this happen and what should we do?\n    -- For now, inserting the silence as the first elem\n      table.insert(result_current_chunk, 1, elem)\n    end\n  else\n    table.insert(result_current_chunk, elem)\n  end\n  \nend\n    \n\n\nfunction interleave_phon_punc_chunk(tnplus_words)\n  \n  \n  -- Convert phonemes/punctuations sequence into integers sequence\n  \n  Log.log(\"Entering 'interleave_phon_punc_chunk'\")\n  \n  result = {}  \n  current_chunk=1\n  result[current_chunk]={}\n  \n  for wordIdx, tnplus_word in ipairs(tnplus_words) do    \n    \n    markup = get_markup_for_word (tnplus_words, wordIdx)\n    \n    \n      \n      -- add left punctuation symbol\n      if tnplus_word.punc_beg ~= \"\" then\n        punctuations = engine_utils.split(tnplus_word.punc_beg, \"|\")\n        for punctuationIdx, punctuation in ipairs(punctuations) do          \n          idx = dict_open_punc_to_idx[punctuation]\n          if idx == nil then\n            -- skipping unknown punctuation symbol\n            engine_utils.log_important_message(\"Warning: unknown punctuation symbol '\" .. punctuation .. \"'. Skipping.\")\n          else\n            add_elem_to_result(result[current_chunk], engine_utils.KEY_TYPE_PUNC, idx, punctuation, nil, markup)            \n          end\n        end\n      end\n      \n      -- add individual phonetic symbol(s)\n      if tnplus_word.metadata.audiosrc ~= nil and tnplus_word.metadata.audiosrc ~= \"\" then\n        add_elem_to_result(result[current_chunk], engine_utils.KEY_TYPE_AUDIOSRC, nil, tnplus_word.metadata[\"audiosrc\"], nil, nil)        \n        \n        -- nothing to do\n      elseif tnplus_word.tokenized_phon == nil or tnplus_word.num_phon == 0 then\n        engine_utils.log_important_message(\"Warning: tokenizing phonetic symbol(s) '\" .. tnplus_word.phon .. \"' failed. Skipping.\")\n      else\n        for phnIdx, phn in ipairs(tnplus_word.tokenized_phon) do\n          symType=\"\"\n          if engine_utils.has_element(def_suprasegmentals, phn) then\n            symType=engine_utils.KEY_TYPE_SUPRASEGMENTAL\n          elseif engine_utils.has_element(def_suprasegmentals, dict_phon_to_phon[phn]) then\n            symType=engine_utils.KEY_TYPE_SUPRASEGMENTAL\n          else\n            symType=engine_utils.KEY_TYPE_PHON\n          end\n          sym = dict_phon_to_phon[phn]\n          idx = dict_phon_to_idx[sym]\n          if idx == nil then\n            sym = phn\n            idx = dict_phon_to_idx[phn]\n          end\n          if idx == nil then\n            -- skipping unknown phonetic symbol\n            engine_utils.log_important_message(\"Warning: invalid phonetic symbol(s) '\" .. phn .. \"' in '\" .. tnplus_word.phon .. \"'. Skipping.\")\n          else\n            add_elem_to_result(result[current_chunk], symType, idx, sym, nil, markup)\n            if tones and tnplus_word.tokenized_tone[phnIdx] ~= nil and tnplus_word.tokenized_tone[phnIdx] ~= \"\" then\n              add_elem_to_result(result[current_chunk], engine_utils.KEY_TYPE_SUPRASEGMENTAL, dict_phon_to_idx[tnplus_word.tokenized_tone[phnIdx]], tnplus_word.tokenized_tone[phnIdx], nil, markup)\n            end\n          end\n        end\n      end\n      \n      -- adapt and add right punctuation symbol\n      bTNCommaRm = false\n      if tnplus_word.punc_end ~= \"\" then\n        punctuations = engine_utils.split(tnplus_word.punc_end, \"|\")\n        \n        if tnplus_word.metadata.oriorthjoined then\n          if engine_utils.has_element(punctuations, \"TNCOMMA\") then\n            engine_utils.remove_element(punctuations, \"TNCOMMA\")\n            bTNCommaRm = true\n          end          \n          engine_utils.remove_element(punctuations, \"HYPHEN_LINK\")          \n          if not punc_oriorthjoined then          \n              engine_utils.remove_element(punctuations, \"DASH\")            \n              engine_utils.remove_element(punctuations, \"OPEN_DASH\")            \n              engine_utils.remove_element(punctuations, \"DASHHYPHEN_LINK\")            \n          end\n        end\n        \n        for punctuationIdx, punctuation in ipairs(punctuations) do\n          idx = dict_close_punc_to_idx[punctuation]          \n          if idx == nil then\n            -- skipping unknown punctuation symbol\n            engine_utils.log_important_message(\"Warning: skipping unknown punctuation symbol '\" .. punctuation .. \"'.\")\n          else\n            add_elem_to_result(result[current_chunk], engine_utils.KEY_TYPE_PUNC, idx, punctuation, nil, markup)            \n          end\n        end\n      end\n    \n      \n    -- add inter-word symbol (space, underscore), except at the end of a chunk\n    if tnplus_words[wordIdx].chunk ~= true and wordIdx ~= #tnplus_words then\n      if (tnplus_words[wordIdx].metadata.oriorthjoined and not bTNCommaRm) or\n           (tnplus_words[wordIdx].metadata.spell and\n             ((tnplus_words[wordIdx+1].metadata.spell and tnplus_words[wordIdx].punc_end == \"\") or\n              (string.find(tnplus_words[wordIdx+1].orth, \"%u's\"))\n             )\n           ) then\n        sym=dict_phon_to_phon[\"_\"]\n        idx = dict_punc_to_idx[sym]\n        if idx == nil then\n          sym = \"_\"\n          idx = dict_punc_to_idx[\"_\"]\n        end\n      else\n        sym = \" \"\n        idx = dict_punc_to_idx[\" \"]\n      end\n    \n      -- safety measure: num_phon==0 should not happen, but we have seen this in our testdata\n      if wordIdx < #tnplus_words and tnplus_words[wordIdx+1].num_phon ~= 0 then\n         add_elem_to_result(result[current_chunk], engine_utils.KEY_TYPE_INTERWORD, idx, sym, nil, markup)               \n      end\n    end\n      \n    -- add sildur information\n    if tnplus_word.chunk == true or \n        wordIdx == #tnplus_words or \n        (tnplus_word.metadata[\"break\"]==\"strong\" and engine_config.model == \"parlotron\") then         \n      \n      if (engine_config.model==\"parlotron\" and tnplus_word.chunk == false) or -- for parlotron, if we are not at a chunk boundary, we may have a -1 indicating that the model should predict the duration\n         (tnplus_word.metadata.sildur >= 0) then\n        dur = tnplus_word.metadata.sildur\n      else\n        punctuations = engine_utils.split(tnplus_word.punc_end, \"|\")\n        if punctuations[#punctuations] == dict_chunk_fallback_symbol then\n          -- VO-12457: finetune silence durations\n          if tnplus_word.metadata[\"break\"]==\"strong\" then\n            dur = sildur_phrase\n          else\n            dur  = 0             \n          end\n        else\n          -- note that in an integrated system, we never reach this point, since the silence duration at the end of a sentence is always >=0 (controlled by wait factor)\n          dur = sildur_sentence\n        end        \n      end\n      add_elem_to_result(result[current_chunk], engine_utils.KEY_TYPE_SILENCE, nil, nil, dur, nil)\n        \n    end    \n    \n    if tnplus_word.chunk == true then\n      add_elem_to_result(result[current_chunk], engine_utils.KEY_TYPE_ENDOFSEQUENCE, dict_punc_to_idx[\"~\"], nil, nil, nil)\n      if wordIdx ~= #tnplus_words then\n        current_chunk=current_chunk+1\n        result[current_chunk]={}      \n      end\n    end\n  \n  end\n  \n  elem={}\n  elem[\"type\"]=engine_utils.KEY_TYPE_ENDOFSENTENCE\n  table.insert(result[current_chunk], elem)\n  \n  Log.log(\"Done 'interleave_phon_punc_chunk'\")\n  return result\n  \nend\n\n\nlocal function hlp_pre_chunk_based_on_markup (tnplus_words, wordIdx, fieldName, prevFieldValue, curFieldValue)\n  \n  if curFieldValue ~= prevFieldValue then\n      prevFieldValue=curFieldValue\n      if engine_utils.has_element(engine_config.chunk_on_markup, fieldName) then\n        if wordIdx > 1 then\n          tnplus_words[wordIdx-1].chunk=true\n        end\n      end\n  end\n  return prevFieldValue\nend\n    \n\n\nfunction pre_chunk_based_on_markup (tnplus_words)\n  \n  prevValueOfKey={}\n  prevValueOfKey[\"stylename\"]=\"\"\n  prevValueOfKey[\"styleintensity\"]=\"\"\n  prevValueOfKey[\"volume\"]=-1\n  prevValueOfKey[\"pitch\"]=-1\n  prevValueOfKey[\"rate\"]=-1\n  prevValueOfKey[\"timbre\"]=-1\n  \n\n  for wordIdx, tnplus_word in ipairs(tnplus_words) do\n    \n    tnplus_words[wordIdx].chunk=false\n    \n    -- handle markup for which a value change may (depends on the model and its configuration) result in a chunk boundary\n    for key, prevValue in pairs(prevValueOfKey) do\n      prevValueOfKey[key]=hlp_pre_chunk_based_on_markup(tnplus_words, wordIdx, key, prevValueOfKey[key], tnplus_word.metadata[key])\n    end\n      \n    -- handle sildur\n    if tnplus_word.metadata.sildur >= 0 and engine_utils.has_element(engine_config.chunk_on_markup, \"sildur\") then\n      tnplus_words[wordIdx].chunk=true      \n    end\n    \n    -- handle audiosrc\n    if tnplus_word.metadata.audiosrc ~= \"\" and engine_utils.has_element(engine_config.chunk_on_markup, \"audiosrc\") then\n      if wordIdx > 1 then\n          tnplus_words[wordIdx-1].chunk=true\n      end\n      tnplus_words[wordIdx].chunk=true\n    end\n        \n  end\n  \nend\n\n\nfunction get_markup_for_word (tnplus_words, wordIdx)  \n  \n  markup={}\n  \n  fieldnames={\"stylename\", \"styleintensity\", \"volume\", \"pitch\", \"rate\", \"timbre\"}\n  \n  -- if we have audiosrc, then we don't want to set the other markup\n  if tnplus_words[wordIdx].metadata.audiosrc == \"\" then\n    for i, fieldName in ipairs(fieldnames) do    \n      markup[fieldName]=tnplus_words[wordIdx].metadata[fieldName]\n    end\n  end      \n  -- sildur and audiosrc are handled in a different way\n  \n  return markup\n\nend\n\n\n\nfunction remove_words_with_empty_phonetics (tnplus_words)\n   \n  wordIdx=1\n  while wordIdx <= #tnplus_words do\n    if #tnplus_words > 1 and  -- we don't want to delete the one and only word \n       (tnplus_words[wordIdx].metadata.audiosrc == nil or  tnplus_words[wordIdx].metadata.audiosrc == \"\") and\n       (tnplus_words[wordIdx].orth ~= nil and tnplus_words[wordIdx].orth ~= \"\") and\n       (tnplus_words[wordIdx].phon == nil or tnplus_words[wordIdx].phon ==\"\") then\n       -- let's remove the word\n      engine_utils.log_important_message(\"Warning: removing word with empty phonetics\")\n       -- but before removing the word, we copy over 2 fields to the previous word\n      if wordIdx > 1  then\n        if tnplus_words[wordIdx].metadata[\"break\"] ~= \"none\" then\n          tnplus_words[wordIdx-1].metadata[\"break\"]=tnplus_words[wordIdx].metadata[\"break\"] -- if we are at the last word, will copy over \"sent\"\n        end        \n        if tnplus_words[wordIdx].metadata[\"sildur\"] ~= -1 then\n          if tnplus_words[wordIdx-1].metadata[\"sildur\"] == -1 then\n            tnplus_words[wordIdx-1].metadata[\"sildur\"]=tnplus_words[wordIdx].metadata[\"sildur\"]\n          else\n            tnplus_words[wordIdx-1].metadata[\"sildur\"]=tnplus_words[wordIdx-1].metadata[\"sildur\"]+tnplus_words[wordIdx].metadata[\"sildur\"]\n          end\n        end    \n      end\n      table.remove(tnplus_words, wordIdx)       \n    else\n      wordIdx=wordIdx+1\n    end\n  end\n  \nend\n\nreturn engine_bet7_featex\n\nend\n\n-- GENLUA END   file engine_bet7_featex.lua\n-- GENLUA ---------------------------------------------------\n\n-- GENLUA BEGIN regular module loaders\nengine_utils = load_module_engine_utils()\nengine_config = load_module_engine_config()\nengine_bet7_featex = load_module_engine_bet7_featex()\n\n-- GENLUA END   regular module loaders\n-- GENLUA ---------------------------------------------------\n-- GENLUA BEGIN file engine_dummy_run.lua\n\n\n\n-- READ_ONLY SCRIPT - DO NOT MODIFY !!\n-- COMPILED INSIDE THE ENGINE\n-- Please contact NLP or SW team in case some changes are required.\n\n-- Dummy script - needed for the amalgamation of the engine_*.lua scripts\n\nlocal engine_dummy_run={}\nreturn engine_dummy_run\n\n-- GENLUA END   file engine_dummy_run.lua\n-- GENLUA ---------------------------------------------------\n\n"
- "%@ --> %@"
- ".dct"
- ".ssml"
- ".tdc"
- ".xml"
- "INET_F_PREFIX"
- "OrtGetApiBase"
- "Recieved SSML: %@"
- "Vocalizer Markup: %@"
- "audio/L16;rate=8000"
- "fetchMode"
- "inet.info.absoluteName"
- "inet.info.mimeType"
- "inet.info.sizeBytes"
- "libcs_onnxruntime.so.1.13.1"
- "libopus 1.1-beta-fixed"
- "shouldLogSensitiveSpeech"

```
