## VoiceActions

> `/System/Library/PrivateFrameworks/VoiceActions.framework/VoiceActions`

```diff

-56.0.0.0.0
-  __TEXT.__text: 0x106ddc
-  __TEXT.__auth_stubs: 0x27c0
-  __TEXT.__objc_methlist: 0x10bc
-  __TEXT.__const: 0x7cd2
-  __TEXT.__cstring: 0x8b65
-  __TEXT.__swift5_typeref: 0x1f76
-  __TEXT.__swift5_reflstr: 0x3eb0
-  __TEXT.__swift5_assocty: 0x1e0
-  __TEXT.__constg_swiftt: 0x7828
-  __TEXT.__swift5_fieldmd: 0x409c
-  __TEXT.__swift5_proto: 0x51c
-  __TEXT.__swift5_types: 0x3d8
-  __TEXT.__oslogstring: 0x1e40
-  __TEXT.__swift5_capture: 0x5bc
-  __TEXT.__swift_as_entry: 0x154
-  __TEXT.__swift_as_ret: 0x168
-  __TEXT.__swift5_builtin: 0xc8
-  __TEXT.__swift5_protos: 0x28
+93.0.0.0.0
+  __TEXT.__text: 0x188528
+  __TEXT.__auth_stubs: 0x3130
+  __TEXT.__objc_methlist: 0x1424
+  __TEXT.__const: 0xbab2
+  __TEXT.__cstring: 0xb96f
+  __TEXT.__swift5_typeref: 0x2a5c
+  __TEXT.__swift5_reflstr: 0x5cad
+  __TEXT.__swift5_assocty: 0x450
+  __TEXT.__constg_swiftt: 0x94c0
+  __TEXT.__swift5_fieldmd: 0x5990
+  __TEXT.__swift5_proto: 0x848
+  __TEXT.__swift5_types: 0x50c
+  __TEXT.__oslogstring: 0x41be
+  __TEXT.__swift5_capture: 0x848
+  __TEXT.__swift_as_entry: 0x20c
+  __TEXT.__swift_as_ret: 0x2b4
+  __TEXT.__swift5_protos: 0x3c
+  __TEXT.__swift5_builtin: 0xdc
   __TEXT.__swift5_mpenum: 0x24
-  __TEXT.__gcc_except_tab: 0x1110
-  __TEXT.__unwind_info: 0x4758
-  __TEXT.__eh_frame: 0x9014
-  __TEXT.__objc_classname: 0x55
-  __TEXT.__objc_methname: 0x1e58
-  __TEXT.__objc_methtype: 0xb96
-  __TEXT.__objc_stubs: 0xf80
-  __DATA_CONST.__got: 0x760
-  __DATA_CONST.__const: 0x558
-  __DATA_CONST.__objc_classlist: 0x4a8
-  __DATA_CONST.__objc_protolist: 0x20
+  __TEXT.__gcc_except_tab: 0x113c
+  __TEXT.__unwind_info: 0x6378
+  __TEXT.__eh_frame: 0xd584
+  __TEXT.__objc_classname: 0xd1
+  __TEXT.__objc_methname: 0x2c3b
+  __TEXT.__objc_methtype: 0x876
+  __TEXT.__objc_stubs: 0x19a0
+  __DATA_CONST.__got: 0xa38
+  __DATA_CONST.__const: 0xc80
+  __DATA_CONST.__objc_classlist: 0x590
+  __DATA_CONST.__objc_protolist: 0x48
   __DATA_CONST.__objc_imageinfo: 0x8
-  __DATA_CONST.__objc_selrefs: 0x928
-  __DATA_CONST.__objc_protorefs: 0x18
-  __DATA_CONST.__objc_superrefs: 0x10
-  __AUTH_CONST.__auth_got: 0x13f0
-  __AUTH_CONST.__const: 0x4c68
-  __AUTH_CONST.__cfstring: 0x3e0
-  __AUTH_CONST.__objc_const: 0xb188
-  __AUTH.__objc_data: 0x40c0
-  __AUTH.__data: 0x9588
-  __DATA.__objc_ivar: 0x6c
-  __DATA.__data: 0x17b0
-  __DATA.__bss: 0xa018
-  __DATA.__common: 0x2c0
+  __DATA_CONST.__objc_selrefs: 0xce0
+  __DATA_CONST.__objc_protorefs: 0x30
+  __DATA_CONST.__objc_superrefs: 0x30
+  __DATA_CONST.__objc_arraydata: 0x70
+  __AUTH_CONST.__auth_got: 0x18b0
+  __AUTH_CONST.__const: 0x13658
+  __AUTH_CONST.__cfstring: 0x980
+  __AUTH_CONST.__objc_const: 0xd698
+  __AUTH_CONST.__objc_doubleobj: 0x10
+  __AUTH_CONST.__objc_intobj: 0xd8
+  __AUTH_CONST.__objc_dictobj: 0x28
+  __AUTH.__objc_data: 0x4f88
+  __AUTH.__data: 0xbc70
+  __DATA.__objc_ivar: 0xa8
+  __DATA.__data: 0x1de8
+  __DATA.__bss: 0x10548
+  __DATA.__common: 0x448
   - /System/Library/Frameworks/AVFAudio.framework/AVFAudio
   - /System/Library/Frameworks/Accelerate.framework/Accelerate
+  - /System/Library/Frameworks/Contacts.framework/Contacts
   - /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation
   - /System/Library/Frameworks/CoreML.framework/CoreML
   - /System/Library/Frameworks/CoreMedia.framework/CoreMedia
   - /System/Library/Frameworks/Foundation.framework/Foundation
+  - /System/Library/Frameworks/Intents.framework/Intents
   - /System/Library/Frameworks/Speech.framework/Speech
   - /System/Library/PrivateFrameworks/CollectionsInternal.framework/CollectionsInternal
   - /System/Library/PrivateFrameworks/CoreSpeech.framework/CoreSpeech
   - /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition
   - /System/Library/PrivateFrameworks/Espresso.framework/Espresso
   - /System/Library/PrivateFrameworks/InternalSwiftProtobuf.framework/InternalSwiftProtobuf
+  - /System/Library/PrivateFrameworks/SiriTTSService.framework/SiriTTSService
+  - /System/Library/PrivateFrameworks/TextToSpeech.framework/TextToSpeech
   - /usr/lib/libSystem.B.dylib
   - /usr/lib/libc++.1.dylib
   - /usr/lib/libobjc.A.dylib

   - /usr/lib/swift/libswiftCore.dylib
   - /usr/lib/swift/libswiftCoreAudio.dylib
   - /usr/lib/swift/libswiftCoreFoundation.dylib
+  - /usr/lib/swift/libswiftCoreImage.dylib
+  - /usr/lib/swift/libswiftCoreLocation.dylib
   - /usr/lib/swift/libswiftCoreMIDI.dylib
   - /usr/lib/swift/libswiftCoreMedia.dylib
   - /usr/lib/swift/libswiftDarwin.dylib
   - /usr/lib/swift/libswiftDispatch.dylib
+  - /usr/lib/swift/libswiftMLCompute.dylib
   - /usr/lib/swift/libswiftMetal.dylib
+  - /usr/lib/swift/libswiftNaturalLanguage.dylib
   - /usr/lib/swift/libswiftOSLog.dylib
   - /usr/lib/swift/libswiftObjectiveC.dylib
   - /usr/lib/swift/libswiftQuartzCore.dylib
+  - /usr/lib/swift/libswiftRegexBuilder.dylib
   - /usr/lib/swift/libswiftUniformTypeIdentifiers.dylib
   - /usr/lib/swift/libswiftXPC.dylib
   - /usr/lib/swift/libswift_Builtin_float.dylib
   - /usr/lib/swift/libswift_Concurrency.dylib
+  - /usr/lib/swift/libswift_DarwinFoundation1.dylib
+  - /usr/lib/swift/libswift_DarwinFoundation2.dylib
+  - /usr/lib/swift/libswift_DarwinFoundation3.dylib
   - /usr/lib/swift/libswift_StringProcessing.dylib
-  - /usr/lib/swift/libswift_errno.dylib
-  - /usr/lib/swift/libswift_math.dylib
-  - /usr/lib/swift/libswift_signal.dylib
-  - /usr/lib/swift/libswift_stdio.dylib
-  - /usr/lib/swift/libswift_time.dylib
   - /usr/lib/swift/libswiftos.dylib
   - /usr/lib/swift/libswiftsimd.dylib
-  - /usr/lib/swift/libswiftsys_time.dylib
-  - /usr/lib/swift/libswiftunistd.dylib
-  UUID: 161BF0E1-2659-358A-A474-20CB5C0D4C58
-  Functions: 5372
-  Symbols:   462
-  CStrings:  1760
+  UUID: 3F48D6C1-01A2-30DB-9B47-9ECF19FA8655
+  Functions: 7538
+  Symbols:   537
+  CStrings:  2533
 
Symbols:
+ _CNContactFamilyNameKey
+ _CNContactGivenNameKey
+ _CNContactMiddleNameKey
+ _CNContactNicknameKey
+ _NSLog
+ _NSPOSIXErrorDomain
+ _NSSearchPathForDirectoriesInDomains
+ _OBJC_CLASS_$_CNContactFetchRequest
+ _OBJC_CLASS_$_CNContactStore
+ _OBJC_CLASS_$_CompactVoice
+ _OBJC_CLASS_$_NSConstantDictionary
+ _OBJC_CLASS_$_NSConstantDoubleNumber
+ _OBJC_CLASS_$_NSConstantIntegerNumber
+ _OBJC_CLASS_$_NSMutableSet
+ _OBJC_CLASS_$_NSPersonNameComponentsFormatter
+ _OBJC_CLASS_$_NSPropertyListSerialization
+ _OBJC_CLASS_$_NSSet
+ _OBJC_CLASS_$_NSTextCheckingResult
+ _OBJC_CLASS_$_RDCustomProfile
+ _OBJC_CLASS_$_RDUserData
+ _OBJC_CLASS_$_RDUserProfileImpl
+ _OBJC_CLASS_$_SiriTTSService_TTSAXResourceManager
+ _OBJC_CLASS_$_TTSAXResourceManager
+ _OBJC_CLASS_$__EARUserProfile
+ _OBJC_CLASS_$__EARUserProfileBuilder
+ _OBJC_CLASS_$__EARWordPart
+ _OBJC_CLASS_$__INVocabulary
+ _OBJC_CLASS_$__TtC12VoiceActions20VASpeechAPISpotterV2
+ _OBJC_CLASS_$__TtC12VoiceActions21VANameDetectionResult
+ _OBJC_METACLASS_$_CompactVoice
+ _OBJC_METACLASS_$_RDCustomProfile
+ _OBJC_METACLASS_$_RDUserData
+ _OBJC_METACLASS_$_RDUserProfileImpl
+ _OBJC_METACLASS_$_SiriTTSService_TTSAXResourceManager
+ _OBJC_METACLASS_$__TtC12VoiceActions20VASpeechAPISpotterV2
+ _OBJC_METACLASS_$__TtC12VoiceActions21VANameDetectionResult
+ __Block_object_dispose
+ ___NSArray0__struct
+ ___objc_personality_v0
+ __swift_FORCE_LOAD_$_swiftCoreImage
+ __swift_FORCE_LOAD_$_swiftCoreLocation
+ __swift_FORCE_LOAD_$_swiftMLCompute
+ __swift_FORCE_LOAD_$_swiftNaturalLanguage
+ __swift_FORCE_LOAD_$_swift_DarwinFoundation1
+ __swift_FORCE_LOAD_$_swift_DarwinFoundation2
+ __swift_FORCE_LOAD_$_swift_DarwinFoundation3
+ _class_getName
+ _dispatch_activate
+ _dispatch_after
+ _dispatch_async
+ _dispatch_get_global_queue
+ _dispatch_group_create
+ _dispatch_group_enter
+ _dispatch_group_leave
+ _dispatch_group_notify
+ _dispatch_queue_attr_make_initially_inactive
+ _dispatch_queue_create
+ _dispatch_set_qos_class_fallback
+ _dispatch_set_qos_class_floor
+ _dispatch_set_target_queue
+ _dispatch_time
+ _dispatch_workloop_create_inactive
+ _dispatch_workloop_set_scheduler_priority
+ _e5rt_error_code_get_string
+ _log10f
+ _objc_autoreleasePoolPop
+ _objc_autoreleasePoolPush
+ _objc_opt_class
+ _objc_opt_isKindOfClass
+ _objc_retainBlock
+ _objc_retain_x5
+ _printf
+ _puts
+ _swift_coroFrameAlloc
+ _swift_cvw_initEnumMetadataMultiPayloadWithLayoutString
+ _swift_cvw_multiPayloadEnumGeneric_destructiveInjectEnumTag
+ _swift_cvw_multiPayloadEnumGeneric_getEnumTag
+ _swift_getExistentialTypeMetadata
+ _vDSP_dotpr
+ _vDSP_vclip
+ _vDSP_vfixr16
+ _vDSP_vsmul
+ _vDSP_vsq
- __Znwm
- __swift_FORCE_LOAD_$_swift_errno
- __swift_FORCE_LOAD_$_swift_math
- __swift_FORCE_LOAD_$_swift_signal
- __swift_FORCE_LOAD_$_swift_stdio
- __swift_FORCE_LOAD_$_swift_time
- __swift_FORCE_LOAD_$_swiftsys_time
- __swift_FORCE_LOAD_$_swiftunistd
CStrings:
+ "\tCustom LM: %s"
+ "\tUsing JIT: %s"
+ "\tchecker results: %s, nBest: %s: %s"
+ " frames during speech]"
+ " is not capitalized correctly"
+ " missing enrollment"
+ " not found in keywordsToEnrollments - internal misconfiguration"
+ " not found in keywordsToName - internal misconfiguration"
+ " secs: last partial to final"
+ " secs: partial as final to final"
+ " secs: speech duration"
+ " secs: speech end to final"
+ " secs: speech start to final"
+ " secs: speech start to first token"
+ " total frames after end of speech]"
+ "%@"
+ "%@/mini.json"
+ "%s.%@"
+ "%s: %{bool}d => %{bool}d"
+ "%s: Saved audio to %s"
+ ", debugAudioSamples: "
+ ", debugEndFrame: "
+ ", debugStartFrame: "
+ ", keywordIdentifier: "
+ "-"
+ "-phonetic"
+ "-speech_profile.json"
+ "/AttentionDetection"
+ "/tmp/vanr-debug.json"
+ "/tmp/vanr-override.json"
+ "0 enrollments found"
+ "0 enrollments found for %s"
+ "3b.context.mlmodelc/vocab.txt"
+ "3b.mlmodelc/vocab.txt"
+ "3b.small.context.mlmodelc/vocab.txt"
+ "3b.small.mlmodelc/vocab.txt"
+ "4.0"
+ "<prefix> <name> <suffix>"
+ "@\"NSDictionary\""
+ "@\"NSObject<OS_dispatch_queue>\""
+ "@\"TTSAXResourceManager\""
+ "@\"_EARUserProfile\""
+ "@\"_EARUserProfileBuilder\""
+ "@24@0:8@\"NSCoder\"16"
+ "@44@0:8@16@24@32B40"
+ "ASR mismatch, will not call delegate for %s"
+ "ASR string matching looking for needles: %s in haystacks: %s"
+ "Abstract WordIteratingMatcher used"
+ "Access to Contacts db not granted."
+ "Adding audio to VASpeechCollectionSession %s when state is terminal"
+ "Adding orthography %s with IPA %s, wordTag: %s, frequency: %lu"
+ "African-American"
+ "Asking ASR for nBest because systemConfig.listenToAsrForEnrollments is >0 or as part of a validation. Will look for these nBest when matching this keyword: %s"
+ "AssistantDictation"
+ "Attempted to look at checker window. This is not maintained unless returnKeywordAudio is true."
+ "AttentionDetection"
+ "Audio format is interleaved, which is not the canonical format used by VoiceActions, but shouldn't matter for single channel."
+ "B24@0:8@16"
+ "B8@?0"
+ "Building .custom VAStringMatchingStrategy - this is expected in unit tests but not intended to be used in production. Recommend giving it a name"
+ "Built a new recognizer"
+ "Cancelled sleep task after getting final result"
+ "Checker did not match keyword \"%s\" in \"%s\""
+ "Checker failed for keyword \"%s\""
+ "Checker matched for keyword \"%s\", got \"%s\""
+ "Checker mismatch for keyword \"%s\", got \"%s\""
+ "Checker: look for \"%s\", Jit %{bool}d, contact %{bool}d, custom %{bool}d"
+ "CompactVoice"
+ "Compared keyword %s to silence, got score = %f. Score is between 0 and 1, inferring this is a model on that scale. Using halfway from silenceScore to 1.0 = %f"
+ "Compared keyword %s to silence, got score = %f. Score is negative, inferring this is a DTW model. Using silenceScore / 2 = %f"
+ "Contacts"
+ "Contacts added to profile in %.2fms\n"
+ "Could not find LME bias phrases for locale identifier %s. Using default en-US phrases."
+ "Could not get contacts for offline recognition: %s\n"
+ "Could not get profile data\n"
+ "Could not get pronunciations for name %s"
+ "Could not get silence embeddings when inferring thresholds"
+ "Could not infer threshold for %s. Did not find a score against silence. Using default threshold."
+ "Could not infer threshold for %s. Silence score is >1.0, not sure how to score this model. Using default threshold."
+ "Could not make canonical string for VANRSystemConfigCodable"
+ "Could not parse simulated priors info %s: %s\n"
+ "Could not parse user profile: %s\n"
+ "Could not read simulated priors info %s: %s\n"
+ "Could not save debug audio: %@"
+ "Could not save debugInfo: %@"
+ "Create LME time %f secs"
+ "Creating profile for %@"
+ "Currently, all names must have the same locale"
+ "Custom LM creation took %f seconds"
+ "Decoding result - failed filename"
+ "Decoding result - failed secondPassResult"
+ "Decoding result - falied keyword"
+ "Deserialization of user profile done with size=%lu\n"
+ "Did match %s from keyword %s in \"%s\""
+ "Did not have audioBytes for second pass in keywordSpotterShouldTriggerKeyword"
+ "Did not have runtimeParameters for second pass in keywordSpotterShouldTriggerKeyword"
+ "Did not match %s from keyword %s in \"%s\""
+ "Did not successfully enroll %s"
+ "Elapsed time since last detection: %f secs, stride %f"
+ "Empty data profile"
+ "Empty simulated priors JSON at %s\n"
+ "Empty user profile JSON\n"
+ "Encountered error in VASpeechCollector id: %s  error: %@"
+ "Encountered validation errors when building name recognizer."
+ "End of audio, got partial but no final yet. So send 0 bytes"
+ "End of audio, not a single result...done"
+ "End-of-Audio: %s, currentState %s"
+ "End-of-Speech: %f < %s"
+ "Enrolling %s for \"%s\": %s with gain %f, no padding needed since %u >= required %u"
+ "Enrolling %s for \"%s\": %s with padding of %u samples with gain %f"
+ "Enrolling %s for \"%s\": %s with padding of %u samples without gain"
+ "Enrolling commands from dir : %s"
+ "Enrollment is running long, need to reduce %ld samples > %ld max"
+ "Enrollment number: %ld - Collected enrollment UUID: %s"
+ "Enrollment number: %ld - Name configuration UUID: %s"
+ "Error encoding JSON: "
+ "Error in E5RTWrapper and could not get error string. Code: %s"
+ "Error in E5RTWrapper: %s"
+ "Error in PhoneticDistanceMatcher using phonetic embedder: %@ - will not match"
+ "Error in addNBest: %@"
+ "Error in checking assets: %@"
+ "Error in second pass: %@"
+ "Error running checker for keyword %s: %@"
+ "Error saving debug: %@"
+ "Error saving system config: %@"
+ "Error sleeping wating for final result: %@"
+ "Expect needleWords.count == hayWords.count"
+ "Expected non-nil deferred audio output"
+ "Expected to have cached feature buffer"
+ "Failed to create 0 buffer"
+ "Failed to create audio format"
+ "Failed to create speech detector output stream"
+ "Failed to enroll "
+ "Failed to enroll %ld enrollments."
+ "Failed to get %ld extra bytes"
+ "Failed to get extra bytes"
+ "Failed to update request info"
+ "Fetch audio for checker  %f seconds"
+ "Fetch completed for %s in %.2fms\n"
+ "Fetch completed too late (%.2fsms) for %s\n"
+ "Fetching audio for checker took %f secs"
+ "File path for SRC cache not found : %s"
+ "Finished callback  %f seconds"
+ "Finishing input stream"
+ "Found %lu and added %lu contact(s) for offline recognition\n"
+ "Found %lu and added %lu contact(s) from INVocabulary for offline recognition\n"
+ "Found model %s at path %s"
+ "Getting extra audio for %f secs after keyword"
+ "Got final after padding speech end with %u samples of 0 audio for %f secs"
+ "Got final result before speech ended"
+ "Got final, Cancelling task to feed audio till final result: %@"
+ "Got first partial result after speech ended"
+ "Got locale: %s Checking for Speech asset..."
+ "Got simulated prior file from input: %s\n"
+ "Got speech end after final, nothing to do"
+ "Got speech end before final and %spartial, pad with audio till final"
+ "How is this?"
+ "I am right behind you"
+ "I need your help"
+ "IGNORING AUDIO"
+ "Ignoring audio while feeding 0 buffer"
+ "Ignoring topDetection %s score %f < %f"
+ "Incorrect audio format. Must use single channel, int16, 16khz. "
+ "Inferring threshold for keyword %s"
+ "Internal inconsistency. No configured name for keyword: "
+ "Invalid buffer format"
+ "Invalid int16 data in buffer"
+ "Invalid pron for entry: %s\n"
+ "Invalid state - null VASpeechResult without error from speech API"
+ "Invalid state in builder - keyword "
+ "Invalid state, expect shouldHandleAudioAfterEndOfSpeech == false"
+ "Invalid state. Must have exactly one enrollment per keyword. Expected "
+ "KeyboardDictation"
+ "Keyword: %s - Applying gain: %f"
+ "Keyword: %s - Collected enrollment UUID: %s"
+ "Keyword: %s - Name configuration UUID: %s"
+ "LiveTranscription"
+ "Loading system config from %s"
+ "Locale not supported by ASR: "
+ "Looking for \"%s\" - would match keyword %s - in \"%s\""
+ "Looking for \"%s\" or \"%s\" in \"%s\""
+ "Looking for %s in %s"
+ "Malformed Quasar profile, exiting...\n"
+ "Malformed UDG profile, exiting...\n"
+ "Marking fetch available for %s"
+ "Matched VAKeywordSpottedEvent: %@"
+ "Missing contact data in simulated priors file\n"
+ "Missing orthograpy for entry: %s\n"
+ "Missing threshold for keyword "
+ "Missing threshold for keyword %s"
+ "Missing user contact data in UDG file\n"
+ "NSCoding"
+ "NSSecureCoding"
+ "Name %s untested locale: %s. We have only tested %s"
+ "Nil pronounciations for name "
+ "No SpeechProfile cached for SRC : %s"
+ "No audio bytes to write"
+ "No configured names found. Cannot infer locale."
+ "No enrollment data for "
+ "No enrollments loaded"
+ "No existing cache found"
+ "No final even after padding with bytes for %f ms"
+ "No partials %llu sec after speech end, so send timing info"
+ "No such enrollment JSON file: "
+ "No such enrollment JSON file: %s"
+ "No such enrollment file: "
+ "No such enrollment file: %s"
+ "No symbol for %ld"
+ "Noop setAudioEnrollments"
+ "Not implemented for this platform"
+ "Not including %s in listenToAsrForEnrollments because it is a common word"
+ "OfflineTranscription"
+ "Persisted user profile to path=%s in %.2fms\n"
+ "Persisting user profile to disk failed with error=%s\n"
+ "PhoneticDistanceMatcher "
+ "Picked final \"%s\" from n-best: %s"
+ "Pronounciations: %s"
+ "Prons[%s] = %s"
+ "Q16@0:8"
+ "RDCustomProfile"
+ "RDMainQueue"
+ "RDMainWorkloop"
+ "RDUserData"
+ "RDUserProfileImpl"
+ "Re-using existing profile data"
+ "Rebuilding stale phonetic embedder"
+ "Reset state after getting no results for vad output"
+ "Result: [secondpass: %s] \"%s%s%s\":%s"
+ "Result: [secondpass: %s] \"%s%s%s\":%s %s secs after end of speech"
+ "Resuming audio to detector afer 0 buffer"
+ "Returning a VANRNameRecognizer that reconstructs on start()"
+ "Returning a VANRNameRecognizer that will start() and stop() based on the underlying VAKeywordSpotter"
+ "Reusing custom LM from %s"
+ "Saving debug to %s"
+ "Saving system config to %s"
+ "SeachOrMessaging"
+ "SearchOrMessaging"
+ "Second pass for %f secs took %f secs, didFail %{bool}d, result %s"
+ "Second pass took %f secs"
+ "SecondPass: \"%s\" conf: %f, nBest: \"%s\""
+ "Self is nil in processResults()"
+ "Serialization of user profile done with size=%lu\n"
+ "Serialization of user profile failed with error=%s\n"
+ "Setting bias: %s"
+ "Setting keywordToEmbeddingFraction to reduce non-speech embeddings considered by 1st pass model"
+ "SiriTTSService_TTSAXResourceManager"
+ "Skipping audio enrollment since text only"
+ "Skipping due to debounce"
+ "Skipping enrollment for name %s because it is not in the limit names list."
+ "Skipping entry without word tag: %s\n"
+ "Skipping fetch for  %s because another fetch is still active"
+ "Skipping profile update for %s because user data has not actually changed"
+ "Sorted Enrollment for %s: %s"
+ "Specified extra audio duration with 0 seconds"
+ "Speech API Input stream finished successfully."
+ "Speech API Input stream was cancelled."
+ "Speech API Unknown termination reason."
+ "Speech API actively listening"
+ "Speech API assets not yet installed. Downloading with assetsInstallationRequest"
+ "Speech API is ready"
+ "Speech Detector Output stream finished successfully."
+ "Speech Detector Output stream was cancelled."
+ "Speech Detector output stream: Unknown termination reason."
+ "Speech Profile for debugging: %s"
+ "Speech Profile: %s"
+ "Speech stopped time before any partials, start %llu sec timer"
+ "SpeechDetector: Audio stopped after sending %u bytes after speech end"
+ "SpeechProfile"
+ "Spotter was deallocated during addAudio task"
+ "Start-of-speech: %f < %s"
+ "Start-streaming"
+ "Started an ASR asset download request for %s but ASR reports that the assets are not yet available. Will continue but this may cause errors later on."
+ "Starting spotter for VAD in state "
+ "Starting spotter in state "
+ "State changed from isWaiting"
+ "Stop(): processing was stopped, break out of sendAudioToSpeechApi()"
+ "Stop-streaming"
+ "Stopping recognizer Task"
+ "Stopping speech API Task"
+ "Successfully enrolled %ld enrollments."
+ "Switching to profile of %ld bytes\n"
+ "T@\"NSArray\",&,N,V_allCompactResources"
+ "T@\"NSArray\",R,C,N,V_contactsWords"
+ "T@\"NSDictionary\",R,N,V_dictionaryRepresentation"
+ "T@\"NSString\",&,N,V_language"
+ "T@\"NSString\",&,N,V_name"
+ "T@\"NSString\",&,N,V_path"
+ "T@\"NSString\",C,N,V_assetPath"
+ "T@\"NSString\",C,N,V_language"
+ "T@\"NSString\",R,C,N,V_language"
+ "T@\"TTSAXResourceManager\",&,N,V_axManager"
+ "TB,N,R"
+ "TB,R"
+ "Timed out waiting on %s"
+ "Took %f seconds for prepareSpeechAPI()"
+ "Took %f seconds to check Speech asset availability"
+ "Tried to load override file from %s but encountered error %@"
+ "Trying to finish input strem"
+ "Unable to access channel data to apply gain"
+ "Unable to process request to enter blocked state, already waiting for final result"
+ "Unexpected audio !!!!!!"
+ "Unexpected error: no supported locales found"
+ "Unknown or unsupported modelSelection: "
+ "Using custom model URL: %s"
+ "VAKeywordSpotter - could not create proper audio format"
+ "VANRDelegateBridge speech results: %s"
+ "VANRErrorDelegateDefault: %s"
+ "VANameDetectionResult: "
+ "VANoopVerifier - didStartListening"
+ "VASpeechAPI error: %@"
+ "VASpeechCollectionSessionImpl Could not get int16 data from buffer"
+ "VASpeechCollectionSessionImpl Could not get int16 data from event buffer"
+ "VoiceActions.VANameDetectionResult"
+ "VoiceActions.VASpeechAPISpotterV2"
+ "VoiceActions/VAKeywordSpotterBase.swift"
+ "VoiceActions/aa_encoder_125141826.swift"
+ "VoiceActions/aa_encoder_125141826_nocrop.swift"
+ "VoiceActions/aa_verifier_125141826.swift"
+ "VoiceActions/aa_verifier_125141826_nocrop.swift"
+ "Waiting for speech API readiness"
+ "Will add %s to namesToSearchForIn2ndPass for keyword %s from addNBestPronunciationsBasedOnGrapheme"
+ "Will add %s to namesToSearchForIn2ndPass for keyword %s from nearestGraphemeBasedOnPhoneme"
+ "[%s%s] %s, n-best [%s]"
+ "[Final, SpeechEnd]"
+ "[Partial] %s"
+ "[SpeechEnd, Final]"
+ "\\NT-contact"
+ "\\app-first"
+ "\\b[a-z](\\s+[a-z])+\\b"
+ "\\company-first"
+ "\\contact-first"
+ "\\contact-last"
+ "\\contact-middle"
+ "\\contact-nickname"
+ "\\jit"
+ "_TtC12VoiceActions10SharedBool"
+ "_TtC12VoiceActions11VASpeechAPI"
+ "_TtC12VoiceActions13VACommonWords"
+ "_TtC12VoiceActions13VANRDebugInfo"
+ "_TtC12VoiceActions13VANoopEncoder"
+ "_TtC12VoiceActions13VAVADVerifier"
+ "_TtC12VoiceActions14VANRDebugEvent"
+ "_TtC12VoiceActions17VANRSpotterBridge"
+ "_TtC12VoiceActions17VASpeechCollector"
+ "_TtC12VoiceActions18VAA2AEnrollmentMap"
+ "_TtC12VoiceActions18VAInputStreamActor"
+ "_TtC12VoiceActions18VANRDelegateBridge"
+ "_TtC12VoiceActions20VANRRecognitionEvent"
+ "_TtC12VoiceActions20VASpeechAPISpotterV2"
+ "_TtC12VoiceActions20WordIteratingMatcher"
+ "_TtC12VoiceActions20aa_encoder_125141826"
+ "_TtC12VoiceActions21VAA2AVerifierModelDTW"
+ "_TtC12VoiceActions21VANameDetectionResult"
+ "_TtC12VoiceActions21aa_verifier_125141826"
+ "_TtC12VoiceActions23VANRSystemConfigCodable"
+ "_TtC12VoiceActions23VANRSystemConfiguration"
+ "_TtC12VoiceActions24VANRErrorDelegateDefault"
+ "_TtC12VoiceActions24VAStringMatchingStrategy"
+ "_TtC12VoiceActions25VALanguageModelEnrollment"
+ "_TtC12VoiceActions25VANRNameRecognizerBuilder"
+ "_TtC12VoiceActions25aa_encoder_125141826Input"
+ "_TtC12VoiceActions26VAA2AAudioEncoderModelV3E1"
+ "_TtC12VoiceActions26VAA2AAudioEncoderModelV3E5"
+ "_TtC12VoiceActions26aa_encoder_125141826Output"
+ "_TtC12VoiceActions26aa_verifier_125141826Input"
+ "_TtC12VoiceActions27aa_encoder_125141826_nocrop"
+ "_TtC12VoiceActions27aa_verifier_125141826Output"
+ "_TtC12VoiceActions28VAA2ABuilderEnrollerDelegate"
+ "_TtC12VoiceActions28aa_verifier_125141826_nocrop"
+ "_TtC12VoiceActions29VASpeechCollectionSessionImpl"
+ "_TtC12VoiceActions31VANRUserConfigurationJsonLoader"
+ "_TtC12VoiceActions32aa_encoder_125141826_nocropInput"
+ "_TtC12VoiceActions33VAAttentionDetectionConfiguration"
+ "_TtC12VoiceActions33aa_encoder_125141826_nocropOutput"
+ "_TtC12VoiceActions33aa_verifier_125141826_nocropInput"
+ "_TtC12VoiceActions34aa_verifier_125141826_nocropOutput"
+ "_TtC12VoiceActions35VANRNameRecognizerBuilderRebuilding"
+ "_TtC12VoiceActionsP33_3F6FD2CD511CD61069CACFF4B3E12CAD24SimpleLevenshteinMatcher"
+ "_TtC12VoiceActionsP33_3F6FD2CD511CD61069CACFF4B3E12CAD29EuclidGraphemeDistanceMatcher"
+ "_TtCC12VoiceActions16VATinyASRSpotter14VADOutputActor"
+ "_TtP12VoiceActions24VASpeechDetectorDelegate_"
+ "_allCompactResources"
+ "_assetPath"
+ "_axManager"
+ "_builder"
+ "_contactsWords"
+ "_dictionaryRepresentation"
+ "_fetchContactsWithKeepGoing:"
+ "_id"
+ "_initWithLanguage:"
+ "_language"
+ "_langugage"
+ "_name"
+ "_path"
+ "_userProfile"
+ "_value"
+ "aa_encoder_125141826.mlmodelc"
+ "aa_encoder_143769172.e5"
+ "adaptUserProfileWithUserData:"
+ "addNBestPronunciationsBasedOnGrapheme"
+ "addNBestPronunciationsBasedOnPhoneme"
+ "addPhraseToUserProfileWithIPAprons:wordTag:phrase:pronsArray:"
+ "addPhraseToUserProfileWithTemplateName:wordTag:namesToProns:"
+ "addPhraseToUserProfileWithTemplateName:wordTag:phrase:"
+ "addWordWithParts:templateName:"
+ "addWordsToUserProfileWithTemplateName:wordArrays:"
+ "allCollectedEnrollments"
+ "allCompactResources"
+ "allCompactResourcesForLanguage:"
+ "allFailedEnrollments"
+ "analysisOptions"
+ "applyGainToEnrollmentAudio"
+ "array"
+ "asrLookingFor"
+ "asrNBest"
+ "asrStringMatchingStrategy"
+ "assetPath"
+ "assistant"
+ "assistantDictation"
+ "attentionDetectionConfig"
+ "attentionName %s, keys: %s"
+ "audioBytesSavedTo"
+ "audioFormat16k"
+ "autoConfigureThresholds"
+ "automaticallyPrepareSpeechAPI"
+ "axManager"
+ "blockInferenceRequestPendingFinalResult"
+ "buildVersion"
+ "cachedKeywordBiasData"
+ "cachedPhoneticEmbedder"
+ "callDelegateOnAsrMismatch"
+ "can you hear me?"
+ "canonicalString() not implemented for VANRSystemConfiguration base class. This is used by VANRSystemConfigCodable"
+ "captioning"
+ "checkerWindow"
+ "close"
+ "collectingSpeech"
+ "com.apple.embeddedspeech.FetchSerializer"
+ "com.apple.mind.mi.namex"
+ "com.apple.mind.mi.saveaudio"
+ "com.apple.mind.mi.sharedBoolQueue"
+ "come to the counter"
+ "come to the gate"
+ "confirmation"
+ "contactLMEWithNBestProns"
+ "contactsWords"
+ "contentPath"
+ "createContactProfile:config:lang:isJit:"
+ "createDirectoryAtPath:withIntermediateDirectories:attributes:error:"
+ "currentState"
+ "currentTasrResult"
+ "custom"
+ "customLMWeight"
+ "data"
+ "dataPointer"
+ "dataProfile"
+ "dataWithContentsOfFile:options:error:"
+ "dataWithPropertyList:format:options:error:"
+ "debounce"
+ "debugDescription"
+ "debugInfo"
+ "debugKeywordSpottedEvent"
+ "decodeBoolForKey:"
+ "decodeFloatForKey:"
+ "decodeObjectForKey:"
+ "decodeObjectOfClass:forKey:"
+ "decodePropertyListForKey:"
+ "defaultForVoiceActions"
+ "defaultRequiringMatchAtStartOrEnd"
+ "defaultThreshold"
+ "dictation"
+ "dictationCC"
+ "dictionaryRepresentation"
+ "didDetectEndOfSpeechWithProbability:threshold:hostTime:"
+ "didDetectStartOfSpeechWithProbability:threshold:hostTime:"
+ "done reading vad output"
+ "dumpDebugInfo"
+ "duringSpeechCheckOverride"
+ "e2eDtwThenSpeechApi"
+ "e2eThenSpeechApi"
+ "e2eVadWeightedDtwThenSpeechApi"
+ "en_US_napg.json"
+ "enableSecondPass"
+ "encodeBool:forKey:"
+ "encodeFloat:forKey:"
+ "encodeObject:forKey:"
+ "encodeWithCoder:"
+ "encoder.mlmodelc/vocab.txt"
+ "endOfAudioWithByteCountAfterEndOfSpeech:"
+ "enrolledNameToPronounciations"
+ "enrollmentMap"
+ "enrollmentOptimizations"
+ "enumerateContactsWithFetchRequest:error:usingBlock:"
+ "enumerateKeysAndObjectsUsingBlock:"
+ "enumerateVocabularyUsingBlock:"
+ "errorDelegate"
+ "errorWithDomain:code:userInfo:"
+ "escapedPatternForString:"
+ "euclidDistMedReqMatchAtStartOrEnd"
+ "euclidGraphemeDistanceConservative"
+ "euclidGraphemeDistanceMedium"
+ "euclidGraphemeDistanceNoisy"
+ "events"
+ "extraAudioDurationAfterPredictionWindow"
+ "extraAudioDurationBeforePredictionWindow"
+ "extraTasrBiasString"
+ "failed to compute max value"
+ "familyName"
+ "feedEmptyBufferTillFinalResultTask"
+ "fetchUserDataWithLanguage:completion:"
+ "fetchUserDataWithLanguage:keepGoing:completion:"
+ "fileFormat"
+ "filename"
+ "firstMatchInString:options:range:"
+ "firstObject"
+ "floatChannelData"
+ "foundInCalls"
+ "freq"
+ "frequency"
+ "fuzzyCollapsingInitializations"
+ "fuzzyRemovingSpaces"
+ "fuzzyWithSpaces"
+ "gRDServerQueue"
+ "gain"
+ "gainToApplyToUserSpokenAudio"
+ "gatedMode"
+ "generatedKeyword"
+ "getUserProfileData"
+ "givenName"
+ "gotEndOfSpeech"
+ "gotFinalResult"
+ "gotPartialResult"
+ "hash"
+ "haystackTransforms"
+ "humanReadableName"
+ "ignoreMultiple1stPassResultsInSameStride"
+ "index"
+ "initForReading:commonFormat:interleaved:error:"
+ "initWithCoder:"
+ "initWithConfiguration:language:overrides:sdapiOverrides:emptyVoc:pgVoc:paramsetHolder:"
+ "initWithConfiguration:language:overrides:textNormalizationModelRoot:sdapiOverrides:emptyVoc:pgVoc:paramsetHolder:isJit:"
+ "initWithContentsOfFile:options:error:"
+ "initWithDataPointer:shape:dataType:strides:deallocator:error:"
+ "initWithKeysToFetch:"
+ "initWithLanguage:assetPath:"
+ "initWithOrthography:pronunciations:tag:"
+ "initWithOrthography:pronunciations:tagName:frequency:"
+ "initWithOrthography:pronunciations:tagName:frequency:phoneticOrthography:"
+ "initWithPattern:options:error:"
+ "inputStreamActor"
+ "isEqual:"
+ "isEqualToString:"
+ "isInstalled"
+ "isValid"
+ "isValidating"
+ "jitAndContactLM"
+ "jitAndCustomLM"
+ "jitCustomAndLeftContext"
+ "jsonFile"
+ "justSubstring"
+ "keyboardDictation"
+ "keywordToEmbeddingFraction"
+ "keywordToEnrolledName"
+ "keywordsToAsrMatch"
+ "keywordsToEnrollments"
+ "keywordsToName"
+ "kwsDelegate"
+ "language"
+ "language=%@, contactsWords count=%ld"
+ "language=%@, contactsWords=%@"
+ "lastSaved"
+ "lastUpdated"
+ "limit2ndPassSearchToNBest"
+ "listenToAsrForEnrollments"
+ "listener"
+ "liveTranscription"
+ "locale"
+ "localeOfCachedPhoneticEmbedder"
+ "localizedDescription"
+ "localizedFailureReason"
+ "lowercase"
+ "matchedEnrollmentIds"
+ "matchedNameId"
+ "matchesInString:options:range:"
+ "maxLevDistancePerWord"
+ "maxTextAudioEnrollmentCount"
+ "maximumBufferSamples"
+ "maximumDistance"
+ "may I have your attention"
+ "middleName"
+ "mini.json"
+ "mismatch"
+ "modelOptions"
+ "modelSelection"
+ "mrec.psh"
+ "multiplyScoresByVadOutput"
+ "mustBeAtStartOrEnd"
+ "nBest[isFinal %{bool}d isFinalTerminal: %{bool}d]: %s"
+ "namesToBeDetected"
+ "namesToEnrollmentWavFiles"
+ "namesToEnrollmentWavFilesWithKeywords"
+ "ncs"
+ "needleTransforms"
+ "nickname"
+ "nonSpeechSamplesCollected"
+ "none"
+ "objectAtIndex:"
+ "objectForKey:"
+ "offlineTranscription"
+ "onlyContactLME"
+ "onlyCustomLM"
+ "onlyJITGrammar"
+ "orth"
+ "orthography"
+ "outputFeatureStream"
+ "outputFeatureStreamBuilder"
+ "parameters"
+ "passesMustMatch"
+ "pausedDetector"
+ "personNameComponentsFromString:"
+ "pg.voc"
+ "phonetic"
+ "phoneticEmbedderMade"
+ "postSilenceCheckOverride"
+ "preSilenceCheckOverride"
+ "prepareSpeechAPI() in listeningTask thread finish"
+ "prepareSpeechAPI() in listeningTask thread start"
+ "primaryLanguage"
+ "priorScore"
+ "processSpeechApiResults() is done"
+ "processSpeechApiResultsTask"
+ "processingFormat"
+ "prons"
+ "pronunciations"
+ "pronunciationsForOrthography:"
+ "propertyListWithData:options:format:error:"
+ "range"
+ "rangeOfString:"
+ "readIntoBuffer:error:"
+ "readUserProfile:"
+ "readUserProfileFromCache"
+ "readUserProfileFromCache: Mismatch in speech profile language in content and filename, got %s instead of %s"
+ "readUserProfileFromCache: Profile version on disk (%s) does not match the expected version (%s)"
+ "rebuildSpotterOnRestart"
+ "recent1stPassScores"
+ "recognizer"
+ "removeAllWords"
+ "removeObject:"
+ "requestAccessForEntityType:completionHandler:"
+ "requireExactMatchBelowNeedleWordLength"
+ "resourcesWithType:subType:"
+ "returnAudioForTasrFinalResult"
+ "returnKeywordAudio"
+ "saveAudioQueue"
+ "saveKeywordAudio"
+ "scoreArray"
+ "search"
+ "secondPassDuration: "
+ "secondPassKeywordMatched"
+ "secondPassNBest"
+ "secondPassNBest: "
+ "secondPassResult: "
+ "secondPassTaskHint"
+ "self is nil when executing in actor"
+ "sendAudioToSpeechApiTask"
+ "sendAudioToSpeechApiTask() is done"
+ "set"
+ "setAllCompactResources:"
+ "setAssetPath:"
+ "setAxManager:"
+ "setEnrollmentsToAsrMatch: %s"
+ "setLanguage:"
+ "setName:"
+ "setObject:forKey:"
+ "setPath:"
+ "setWithArray:"
+ "sharedInstance"
+ "shouldPrintScores"
+ "shouldResetData"
+ "simpleLevenshteinConservative"
+ "simpleLevenshteinForgiving"
+ "simpleLevenshteinMedium"
+ "simpleLevenshteinNoisy"
+ "sleepTask"
+ "small_encoder.mlmodelc/vocab.txt"
+ "small_fast_1000_encoder.mlmodelc/vocab.txt"
+ "small_fast_500_encoder.mlmodelc/vocab.txt"
+ "small_fast_encoder.mlmodelc/vocab.txt"
+ "someone's at the door"
+ "speechAPITask"
+ "speechApiStreamingOnly"
+ "speechBiasOptions"
+ "speechCollectedAudio"
+ "speechDetectorAudioOutputStream"
+ "speechDetectorDelegate"
+ "speechDetectorFeatureOutputStream"
+ "speechDetectorMode"
+ "speechEnded"
+ "speechHasEnded"
+ "spellCC"
+ "spelling"
+ "spokenByUser"
+ "spotter"
+ "squardAudioSamplesForVolumeCalculation"
+ "start() called and there is already a listening task"
+ "startedRunning"
+ "strides"
+ "string"
+ "stringByAppendingFormat:"
+ "stringByAppendingPathComponent:"
+ "stringByAppendingString:"
+ "stringByDeletingLastPathComponent"
+ "stringMatchingStrategy"
+ "substringBetweenWordBoundaries"
+ "substringMatcher"
+ "supportsSecureCoding"
+ "sysConfigString"
+ "systemConfig"
+ "systemUptime"
+ "tag"
+ "tagName"
+ "taskHintString"
+ "tasrv1_e2_3bsmall_encoder.e5/vocab.txt"
+ "tasrv1_e2_3bsmall_nocontext.e5/vocab.txt"
+ "textEnrollmentOnly"
+ "textToSpeech"
+ "there is a call for"
+ "there is a call for you"
+ "timeout"
+ "timestamp"
+ "tinyASRModeInferenceMode"
+ "tooMuchSpeech"
+ "topDetection"
+ "transferToMultiArray:"
+ "truncateEmbeddings"
+ "tshot"
+ "updateUserProfileWithPersonalData:"
+ "url"
+ "urn:contacts:com.apple.contact.people"
+ "usePartialResultsForKeywordDetection"
+ "useResultGenerator"
+ "useSingletonNameRecognizer"
+ "userData"
+ "v16@?0@\"RDUserData\"8"
+ "v16@?0@?<v@?>8"
+ "v20@0:8I16"
+ "v20@?0B8@\"NSError\"12"
+ "v24@0:8@\"NSCoder\"16"
+ "v24@?0@\"CNContact\"8^B16"
+ "v32@0:8@16@24"
+ "v32@0:8@16@?24"
+ "v32@0:8f16f20Q24"
+ "v32@?0@\"NSString\"8@\"NSArray\"16^B24"
+ "v32@?0@\"NSString\"8@\"NSString\"16^B24"
+ "v40@0:8@16@?24@?32"
+ "v40@?0@\"NSString\"8q16@\"NSSet\"24^B32"
+ "v48@0:8@16@24@32@40"
+ "vadGated"
+ "vadGatedThenSpeechApi"
+ "vadOutputActor"
+ "vadState"
+ "validationErrors"
+ "valueForKey:"
+ "verbose"
+ "version"
+ "vocdelta.voc"
+ "voicemail"
+ "waitingForFirstSpeech"
+ "warningTooNoisy"
+ "wasAsrMatch"
+ "watchDictation"
+ "writeOutUserDataToJson:withConfig:"
+ "writeToFile:options:error:"
+ "writeUpdatedUserProfileToCache: Error in getting profile path: %s"
+ "writeUserProfileAsJson:"
+ "writeUserProfileToCache"
+ "your coffee is ready"
+ "your order is ready"
+ "{unordered_map<std::string, float, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, float>>>=\"__table_\"{__hash_table<std::__hash_value_type<std::string, float>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, float>, std::hash<std::string>, std::equal_to<std::string>>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, float>, std::equal_to<std::string>, std::hash<std::string>>, std::allocator<std::__hash_value_type<std::string, float>>>=\"__bucket_list_\"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> *>>>=\"__ptr_\"^^v\"__deleter_\"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> *>>=\"__size_\"Q}}\"__first_node_\"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *>=\"__next_\"^v}\"__size_\"Q\"__max_load_factor_\"f}}"
+ "{vector<voiceactions::FstSpotterResults, std::allocator<voiceactions::FstSpotterResults>>=\"__begin_\"^{FstSpotterResults}\"__end_\"^{FstSpotterResults}\"__cap_\"^{FstSpotterResults}}"
+ "âœ… Using static instance"
- " frames last after end of speech]"
- "20enrollments_quant_all_verifier_aa"
- "Escaping loop... non-blank cycle count %ld >= %ld"
- "Expected audioDebugBytesBeforeSpeech != nil"
- "Expected audioDebugBytesBeforeSpeech to be non-nil"
- "Expected audioDebugBytesDuringSpeech != nil"
- "Expected audioDebugBytesDuringSpeech to be non-nil"
- "Expected audioDebugBytesDuringSpeech to be non-nil after VAD inference"
- "Failed to create output stream"
- "Failed to download general ASR model: %@"
- "General ASR model already exists"
- "General ASR model loaded %ld%%"
- "Got %@"
- "Ignoring after stop: %@"
- "Ignoring repeated symbol %s, non-blank cycle count %ld"
- "Incorrect audio format. Must use single channel, int16, 16khz."
- "No results from speech API"
- "No symbol for %d"
- "Output stream finished successfully."
- "Output stream was cancelled."
- "Result: \"%s%s%s\":%s"
- "Result: \"%s%s%s\":%s %s secs after end of speech"
- "Speech stopped time before any partials, start 5 sec timer"
- "VoiceActions/20enrollments_quant_all_verifier_aa.swift"
- "VoiceActions/aa_encoder_20240530.swift"
- "VoiceActions/aa_encoder_rdr_125141826.swift"
- "VoiceActions/aa_verifier_20240530.swift"
- "VoiceActions/aa_verifier_rdr_125141826.swift"
- "VoiceActions/quant_enc_f16_wofeats.swift"
- "VoiceActions/quant_verifier_aa_fp16.swift"
- "_TtC12VoiceActions19aa_encoder_20240530"
- "_TtC12VoiceActions20aa_verifier_20240530"
- "_TtC12VoiceActions21quant_enc_f16_wofeats"
- "_TtC12VoiceActions22quant_verifier_aa_fp16"
- "_TtC12VoiceActions24aa_encoder_20240530Input"
- "_TtC12VoiceActions24aa_encoder_rdr_125141826"
- "_TtC12VoiceActions25aa_encoder_20240530Output"
- "_TtC12VoiceActions25aa_verifier_20240530Input"
- "_TtC12VoiceActions25aa_verifier_rdr_125141826"
- "_TtC12VoiceActions26aa_verifier_20240530Output"
- "_TtC12VoiceActions26quant_enc_f16_wofeatsInput"
- "_TtC12VoiceActions27quant_enc_f16_wofeatsOutput"
- "_TtC12VoiceActions27quant_verifier_aa_fp16Input"
- "_TtC12VoiceActions28quant_verifier_aa_fp16Output"
- "_TtC12VoiceActions29aa_encoder_rdr_125141826Input"
- "_TtC12VoiceActions30aa_encoder_rdr_125141826Output"
- "_TtC12VoiceActions30aa_verifier_rdr_125141826Input"
- "_TtC12VoiceActions31aa_verifier_rdr_125141826Output"
- "_TtC12VoiceActions36_20enrollments_quant_all_verifier_aa"
- "_TtC12VoiceActions41_20enrollments_quant_all_verifier_aaInput"
- "_TtC12VoiceActions42_20enrollments_quant_all_verifier_aaOutput"
- "analysisContext"
- "audioDebugBytesBeforeSpeech"
- "audioDebugBytesDuringSpeech"
- "blockInferenceRequestPending"
- "downloadError"
- "enableSpeechDetector"
- "got final result before end of speech, waiting for end of speech"
- "mustWaitForFinalToStopInference"
- "reset model input from before start of speech after using it"
- "reuseBuffers"
- "speech ended, but waiting for final result"
- "stop(): Nil outputAudioStreamBuilder"
- "transcriber"
- "vadModel is nil when gating tasr with VAD"
- "{unordered_map<std::string, float, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, float>>>=\"__table_\"{__hash_table<std::__hash_value_type<std::string, float>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, float>, std::hash<std::string>, std::equal_to<std::string>>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, float>, std::equal_to<std::string>, std::hash<std::string>>, std::allocator<std::__hash_value_type<std::string, float>>>=\"__bucket_list_\"{unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> *>>>=\"__ptr_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> *>>>=\"__value_\"^^v\"__value_\"{__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> *>>=\"__data_\"{__compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *> *>>=\"__value_\"Q}}}}\"__p1_\"{__compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, float>, void *>>>=\"__value_\"{__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, float>, void *> *>=\"__next_\"^v}}\"__p2_\"{__compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, float>, std::hash<std::string>, std::equal_to<std::string>>>=\"__value_\"Q}\"__p3_\"{__compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, float>, std::equal_to<std::string>, std::hash<std::string>>>=\"__value_\"f}}}"
- "{vector<voiceactions::FstSpotterResults, std::allocator<voiceactions::FstSpotterResults>>=\"__begin_\"^{FstSpotterResults}\"__end_\"^{FstSpotterResults}\"__end_cap_\"{__compressed_pair<voiceactions::FstSpotterResults *, std::allocator<voiceactions::FstSpotterResults>>=\"__value_\"^{FstSpotterResults}}}"

```
