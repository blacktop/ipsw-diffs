## libBNNS.dylib

> `/System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libBNNS.dylib`

```diff

-1497.120.5.0.0
-  __TEXT.__text: 0xa27fc4
-  __TEXT.__auth_stubs: 0x1270
-  __TEXT.__gcc_except_tab: 0x2b4fc
-  __TEXT.__const: 0x1526f
-  __TEXT.__cstring: 0x3028c
-  __TEXT.__oslogstring: 0x36b
-  __TEXT.__unwind_info: 0xb910
-  __TEXT.__eh_frame: 0xbcd8
-  __DATA_CONST.__got: 0x110
-  __DATA_CONST.__const: 0x3a90
-  __AUTH_CONST.__auth_got: 0x940
-  __AUTH_CONST.__const: 0xf820
+1835.0.0.0.0
+  __TEXT.__text: 0xe99534
+  __TEXT.__auth_stubs: 0x1650
+  __TEXT.__gcc_except_tab: 0x2d8ac
+  __TEXT.__const: 0x29730
+  __TEXT.__cstring: 0x4a450
+  __TEXT.__oslogstring: 0x303
+  __TEXT.__unwind_info: 0x179c0
+  __TEXT.__eh_frame: 0xbe94
+  __DATA_CONST.__got: 0x168
+  __DATA_CONST.__const: 0x4758
+  __AUTH_CONST.__auth_got: 0xb30
+  __AUTH_CONST.__const: 0x28ca8
   __AUTH_CONST.__cfstring: 0x200
-  __DATA.__data: 0x1c
-  __DATA.__bss: 0xc0
+  __AUTH.__data: 0x1aa8
+  __DATA.__data: 0x4508
+  __DATA.__bss: 0xd10
+  __DATA.__common: 0xbe8
   __DATA_DIRTY.__data: 0x4e8
   __DATA_DIRTY.__bss: 0x108
   - /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libBLAS.dylib

   - /System/Library/PrivateFrameworks/MIL.framework/MIL
   - /usr/lib/libSystem.B.dylib
   - /usr/lib/libc++.1.dylib
-  UUID: B000637D-C085-367D-B90B-CA453A56A106
-  Functions: 11599
-  Symbols:   617
-  CStrings:  4648
+  UUID: CE0CDF48-DDBA-3F20-B09E-DE0176ACDA93
+  Functions: 32843
+  Symbols:   830
+  CStrings:  7084
 
Symbols:
+ _BNNSComputeTwoVariablePolynomial_D1_d16
+ _BNNSComputeTwoVariablePolynomial_D2_d15
+ _BNNSComputeTwoVariablePolynomial_D3_d14
+ _BNNSComputeTwoVariablePolynomial_S1_d16
+ _BNNSComputeTwoVariablePolynomial_S2_d15
+ _BNNSComputeTwoVariablePolynomial_S3_d14
+ _BNNSGraphCompileMLIR
+ _BNNSGraphCompileOptionsSetInputFormat
+ _BNNSGraphCompileOptionsSetTargetByChipsetID
+ _BNNSGraphContextMakeFromFile
+ _BNNSReplaceByDelegateOpsMLIR
+ _BNNSSegmentCoreMLIR
+ __DefaultRuneLocale
+ __NSGetExecutablePath
+ __ZNK3MIL7IRValue12TryGetScalarIjEEPKT_v
+ __ZNK3MIL8Location14GetDescriptionEv
+ __ZNKSt3__110error_code7messageEv
+ __ZNKSt3__114error_category10equivalentERKNS_10error_codeEi
+ __ZNKSt3__114error_category10equivalentEiRKNS_15error_conditionE
+ __ZNKSt3__114error_category23default_error_conditionEi
+ __ZNSt13exception_ptrD1Ev
+ __ZNSt19bad_optional_accessD1Ev
+ __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6appendEPKc
+ __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6assignEPKc
+ __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6insertEmPKc
+ __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6resizeEmc
+ __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE7reserveEm
+ __ZNSt3__113shared_futureIvED1Ev
+ __ZNSt3__114__shared_countD2Ev
+ __ZNSt3__114error_categoryD2Ev
+ __ZNSt3__115__thread_structC1Ev
+ __ZNSt3__115__thread_structD1Ev
+ __ZNSt3__115recursive_mutexC1Ev
+ __ZNSt3__115recursive_mutexD1Ev
+ __ZNSt3__115system_categoryEv
+ __ZNSt3__116generic_categoryEv
+ __ZNSt3__117__assoc_sub_state16__on_zero_sharedEv
+ __ZNSt3__117__assoc_sub_state4waitEv
+ __ZNSt3__117__assoc_sub_state9set_valueEv
+ __ZNSt3__118condition_variableD1Ev
+ __ZNSt3__119__shared_weak_count4lockEv
+ __ZNSt3__119__thread_local_dataEv
+ __ZNSt3__120__throw_system_errorEiPKc
+ __ZNSt3__122__libcpp_verbose_abortEPKcz
+ __ZNSt3__15mutex4lockEv
+ __ZNSt3__15mutex6unlockEv
+ __ZNSt3__15mutexD1Ev
+ __ZNSt3__16futureIvEC1EPNS_17__assoc_sub_stateE
+ __ZNSt3__16futureIvED1Ev
+ __ZNSt3__16localeC1Ev
+ __ZNSt3__16thread6detachEv
+ __ZNSt3__16threadD1Ev
+ __ZSt7nothrow
+ __ZTIN3MIL15UnknownLocationE
+ __ZTIN3MIL16TextFileLocationE
+ __ZTIN3MIL8LocationE
+ __ZTINSt3__114error_categoryE
+ __ZTINSt3__117__assoc_sub_stateE
+ __ZTISt19bad_optional_access
+ __ZTVN10__cxxabiv121__vmi_class_type_infoE
+ __ZTVNSt3__115basic_streambufIcNS_11char_traitsIcEEEE
+ __ZTVNSt3__117__assoc_sub_stateE
+ __ZTVSt19bad_optional_access
+ __ZdlPvSt11align_val_t
+ __ZnwmRKSt9nothrow_t
+ __ZnwmSt11align_val_tRKSt9nothrow_t
+ ___cxa_atexit
+ ___fmaxf16
+ ___maskrune
+ __bnns_graph_builder_finalize
+ __bnns_graph_builder_make
+ __bnns_graph_builder_register_abs
+ __bnns_graph_builder_register_acos
+ __bnns_graph_builder_register_acosh
+ __bnns_graph_builder_register_add
+ __bnns_graph_builder_register_and
+ __bnns_graph_builder_register_argmax
+ __bnns_graph_builder_register_argmin
+ __bnns_graph_builder_register_argsort
+ __bnns_graph_builder_register_asin
+ __bnns_graph_builder_register_asinh
+ __bnns_graph_builder_register_atan
+ __bnns_graph_builder_register_atanh
+ __bnns_graph_builder_register_avg_pool
+ __bnns_graph_builder_register_batch_norm
+ __bnns_graph_builder_register_bidirectional_lstm
+ __bnns_graph_builder_register_cast
+ __bnns_graph_builder_register_ceil
+ __bnns_graph_builder_register_channel_norm
+ __bnns_graph_builder_register_clamped_relu
+ __bnns_graph_builder_register_clip
+ __bnns_graph_builder_register_concat
+ __bnns_graph_builder_register_constant
+ __bnns_graph_builder_register_constant_copy_data
+ __bnns_graph_builder_register_constant_pad
+ __bnns_graph_builder_register_conv
+ __bnns_graph_builder_register_conv_transpose
+ __bnns_graph_builder_register_copy
+ __bnns_graph_builder_register_cos
+ __bnns_graph_builder_register_cosh
+ __bnns_graph_builder_register_cumsum
+ __bnns_graph_builder_register_div
+ __bnns_graph_builder_register_dynamic_reshape
+ __bnns_graph_builder_register_elu
+ __bnns_graph_builder_register_equal
+ __bnns_graph_builder_register_erf
+ __bnns_graph_builder_register_exp
+ __bnns_graph_builder_register_exp2
+ __bnns_graph_builder_register_floor
+ __bnns_graph_builder_register_fma
+ __bnns_graph_builder_register_gather
+ __bnns_graph_builder_register_gather_along_axis
+ __bnns_graph_builder_register_gather_nd
+ __bnns_graph_builder_register_gelu
+ __bnns_graph_builder_register_gelu_approx_sigmoid
+ __bnns_graph_builder_register_gelu_approx_tanh
+ __bnns_graph_builder_register_greater
+ __bnns_graph_builder_register_greater_equal
+ __bnns_graph_builder_register_gru
+ __bnns_graph_builder_register_hard_sigmoid
+ __bnns_graph_builder_register_hard_swish
+ __bnns_graph_builder_register_input
+ __bnns_graph_builder_register_instance_norm
+ __bnns_graph_builder_register_l1_norm
+ __bnns_graph_builder_register_l2_norm
+ __bnns_graph_builder_register_l2_pool
+ __bnns_graph_builder_register_l2_spatial_norm
+ __bnns_graph_builder_register_layer_norm
+ __bnns_graph_builder_register_leaky_relu
+ __bnns_graph_builder_register_less
+ __bnns_graph_builder_register_less_equal
+ __bnns_graph_builder_register_linear
+ __bnns_graph_builder_register_log
+ __bnns_graph_builder_register_log_softmax
+ __bnns_graph_builder_register_log_sum
+ __bnns_graph_builder_register_log_sum_exp
+ __bnns_graph_builder_register_lstm
+ __bnns_graph_builder_register_matmul
+ __bnns_graph_builder_register_max
+ __bnns_graph_builder_register_max_pool
+ __bnns_graph_builder_register_mean
+ __bnns_graph_builder_register_min
+ __bnns_graph_builder_register_mod
+ __bnns_graph_builder_register_mul
+ __bnns_graph_builder_register_not
+ __bnns_graph_builder_register_not_equal
+ __bnns_graph_builder_register_or
+ __bnns_graph_builder_register_output
+ __bnns_graph_builder_register_pow
+ __bnns_graph_builder_register_prelu
+ __bnns_graph_builder_register_prod
+ __bnns_graph_builder_register_recip
+ __bnns_graph_builder_register_reduce_max
+ __bnns_graph_builder_register_reduce_min
+ __bnns_graph_builder_register_reflection_pad
+ __bnns_graph_builder_register_relu
+ __bnns_graph_builder_register_relu6
+ __bnns_graph_builder_register_replication_pad
+ __bnns_graph_builder_register_reshape
+ __bnns_graph_builder_register_rms_spatial_norm
+ __bnns_graph_builder_register_rnn
+ __bnns_graph_builder_register_round
+ __bnns_graph_builder_register_rsqrt
+ __bnns_graph_builder_register_scaled_tanh
+ __bnns_graph_builder_register_scatter
+ __bnns_graph_builder_register_scatter_along_axis
+ __bnns_graph_builder_register_scatter_nd
+ __bnns_graph_builder_register_select
+ __bnns_graph_builder_register_shape
+ __bnns_graph_builder_register_sigmoid
+ __bnns_graph_builder_register_silu
+ __bnns_graph_builder_register_sin
+ __bnns_graph_builder_register_sinh
+ __bnns_graph_builder_register_slice
+ __bnns_graph_builder_register_slice_update
+ __bnns_graph_builder_register_softmax
+ __bnns_graph_builder_register_softplus
+ __bnns_graph_builder_register_softsign
+ __bnns_graph_builder_register_sqrt
+ __bnns_graph_builder_register_squeeze
+ __bnns_graph_builder_register_sub
+ __bnns_graph_builder_register_sum
+ __bnns_graph_builder_register_sum_square
+ __bnns_graph_builder_register_tan
+ __bnns_graph_builder_register_tanh
+ __bnns_graph_builder_register_threshold
+ __bnns_graph_builder_register_thresholded_relu
+ __bnns_graph_builder_register_topk
+ __bnns_graph_builder_register_transpose
+ __bnns_graph_builder_register_unsqueeze
+ __bnns_graph_builder_register_xor
+ __bnns_graph_builder_tensor_from_tensor_ref
+ _access
+ _exit
+ _fclose
+ _fopen
+ _fread
+ _getpid
+ _getpriority
+ _isatty
+ _longjmp
+ _lseek
+ _malloc_type_calloc
+ _pthread_create
+ _pthread_setspecific
+ _qsort
+ _raise
+ _realpath$DARWIN_EXTSN
+ _setjmp
+ _setpriority
+ _sigaction
+ _sigprocmask
+ _stat
+ _strncmp
+ _unlink
+ _vsnprintf
+ _write
- __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEEC2Ev
- __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEED2Ev
- _atoi
- _strlcat
CStrings:
+ "\t\n\v\f\r "
+ "\n\r"
+ " \t"
+ " \t\n\v\f\r"
+ "    "
+ "      "
+ "        -----     "
+ "      op result types: "
+ "    ="
+ "    }"
+ "   ---User Time---"
+ "   ---Wall Time---"
+ "   --System Time--"
+ "   --User+System--"
+ "  %7.4f (%5.1f%%)"
+ "  --- Name ---\n"
+ "  ---Instr---"
+ "  ---Mem---"
+ "  // "
+ "  // block is not in a region!"
+ "  // no predecessors"
+ "  // pred: "
+ "  Total Execution Time: %5.4f seconds (%5.4f wall clock)\n"
+ "  }"
+ " != "
+ " #"
+ " ("
+ " ('"
+ " (block without parent)"
+ " (default: "
+ " (op in a child region)"
+ " (op in a parent region)"
+ " (op in the same block)"
+ " (op in the same region)"
+ " (op is neither in a parent nor in a child region)"
+ " (tried '"
+ " * "
+ " + "
+ " - "
+ " -> "
+ " -> ("
+ " -> ()"
+ " -> <inferred>"
+ " // "
+ " // id: "
+ " // unused"
+ " : "
+ " : ("
+ " ; for more info on dialect registration see https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-dialects-management"
+ " <"
+ " == 0"
+ " > input rank "
+ " > output rank "
+ " >= 0"
+ " Shrink dims = "
+ " after loop variable"
+ " along control flow edge"
+ " along control flow edge "
+ " and "
+ " and result element type "
+ " are incompatible with return type(s) of operation "
+ " arguments to match function signature"
+ " as "
+ " as both an input and output. Inputs and outputs must be distinct,"
+ " assembly format: "
+ " at "
+ " attribute created with unregistered dialect. If this is intended, please call allowUnregisteredDialects() on the MLIRContext, or use -allow-unregistered-dialect with the MLIR opt tool used"
+ " attributes"
+ " bits"
+ " but expected "
+ " but got "
+ " but had "
+ " but only "
+ " but start/end/strides are provided with "
+ " bytes when only "
+ " ceildiv "
+ " count ("
+ " dimension "
+ " does not dominate this use"
+ " does not match the indices uint dtype with bitwidth "
+ " elements"
+ " elements, expect "
+ " entry"
+ " entry instead"
+ " expect it to be "
+ " expect result rank to be "
+ " expected output shape mismatch: "
+ " expected rank is "
+ " externalize"
+ " floordiv "
+ " for appending!\n"
+ " for decl "
+ " for indices with rank: "
+ " for input with rank: "
+ " for key `value`"
+ " for mode "
+ " for op "
+ " for operand number "
+ " from "
+ " given shape is "
+ " has non-unit dimension length "
+ " in "
+ " in a child region)"
+ " in a parent region)"
+ " in affine map"
+ " in affine map range"
+ " in argument list"
+ " in attribute dictionary"
+ " in dimensional identifier list"
+ " in function @"
+ " in fused location"
+ " in input tensor."
+ " in integer set constraint list"
+ " in operand list"
+ " in symbol list"
+ " in the same region)"
+ " index: "
+ " is already registered."
+ " is beyond the legal range ["
+ " is larger than input rank "
+ " is newer than the current version "
+ " is not contained within the value shape, with index=["
+ " is not registered"
+ " is specified more than once in dimensions operand"
+ " is unused"
+ " is used by "
+ " mod "
+ " must be , but got "
+ " must be 0D tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or complex type with 16-bit float elements or complex type with 32-bit float elements or Boolean type. values, but got "
+ " must be 0D tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be 0D tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type values, but got "
+ " must be 0D tensor of Boolean type. values, but got "
+ " must be 0D tensor of Index type. values or 1D tensor of Index type. values, but got "
+ " must be 0D tensor of Index type. values, but got "
+ " must be 0D tensor of bfloat16 type or 16-bit float or 32-bit float or 1-bit signless integer or 4-bit signed integer or 8-bit signed integer or 16-bit signed integer or 32-bit signed integer or 64-bit signed integer or 1-bit unsigned integer or 2-bit unsigned integer or 3-bit unsigned integer or 4-bit unsigned integer or 6-bit unsigned integer or 8-bit unsigned integer or 16-bit unsigned integer or 32-bit unsigned integer or 64-bit unsigned integer values, but got "
+ " must be 1D tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be 1D tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be 1D tensor of 4-bit unsigned integer or 4-bit signed integer or 8-bit unsigned integer or 8-bit signed integer or f8E5M2 type or f8E4M3FN type or bfloat16 type or 16-bit float or 32-bit float values, but got "
+ " must be 1D tensor of Index type. values, but got "
+ " must be 2D tensor of Index type. values, but got "
+ " must be 4D tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be 4D tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be <= input rank "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or Boolean type. values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or complex type with 16-bit float elements or complex type with 32-bit float elements or Boolean type. values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer values, but got "
+ " must be CoreML Tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be CoreML Tensor of Boolean type. values, but got "
+ " must be CoreML Tensor of Index type. values, but got "
+ " must be CoreML Tensor of complex type with 16-bit float elements or complex type with 32-bit float elements values, but got "
+ " must be PDL handle for an `mlir::Value`, but got "
+ " must be PDL handle to an `mlir::Attribute`, but got "
+ " must be PDL handle to an `mlir::Operation *`, but got "
+ " must be PDL handle to an `mlir::Type`, but got "
+ " must be Tensor state wrapper, but got "
+ " must be Tensor type with additional layout information, but got "
+ " must be a multiple of dimension interleave factor "
+ " must be function type, but got "
+ " must be pdl type, but got "
+ " must be range of PDL handle for an `mlir::Value` values, but got "
+ " must be range of PDL handle to an `mlir::Operation *` values, but got "
+ " must be range of PDL handle to an `mlir::Type` or PDL handle for an `mlir::Value` values, but got "
+ " must be range of PDL handle to an `mlir::Type` values, but got "
+ " must be range of pdl type values, but got "
+ " must be ranked tensor of 16-bit float or 32-bit float or 4-bit signed integer or 8-bit signed integer or 32-bit signed integer values, but got "
+ " must be ranked tensor of 16-bit float or 32-bit float or 8-bit signed integer or 32-bit signed integer values, but got "
+ " must be shaped of any type values, but got "
+ " must be single element or range of PDL handle for an `mlir::Value`, but got "
+ " must be single element or range of PDL handle to an `mlir::Type`, but got "
+ " must be tensor of 1-bit signless integer values, but got "
+ " must be tensor of 1-bit unsigned integer or 2-bit unsigned integer or 3-bit unsigned integer or 4-bit unsigned integer or 6-bit unsigned integer or 8-bit unsigned integer values, but got "
+ " must be tensor of 2-bit unsigned integer or 3-bit unsigned integer or 4-bit unsigned integer or 6-bit unsigned integer or 8-bit unsigned integer values, but got "
+ " must be tensor of 32-bit signed integer values, but got "
+ " must be tensor of 4-bit signed integer or 8-bit signed integer or 8-bit unsigned integer values, but got "
+ " must be tensor of 4-bit signed integer or 8-bit unsigned integer or 8-bit signed integer or f8E5M2 type or f8E4M3FN type values, but got "
+ " must be tensor of 4-bit unsigned integer or 4-bit signed integer or 8-bit unsigned integer or 8-bit signed integer or f8E5M2 type or f8E4M3FN type or bfloat16 type or 16-bit float or 32-bit float values, but got "
+ " must be tensor of 8-bit signed integer or 16-bit signed integer or 32-bit signed integer or 64-bit signed integer or 8-bit unsigned integer or 16-bit unsigned integer or 32-bit unsigned integer or 64-bit unsigned integer values, but got "
+ " must be tensor of 8-bit unsigned integer or 8-bit signed integer or f8E5M2 type or f8E4M3FN type or bfloat16 type or 16-bit float or 32-bit float values, but got "
+ " must be tensor of 8-bit unsigned integer or 8-bit signed integer or f8E5M2 type or f8E4M3FN type values, but got "
+ " must be tensor of bfloat16 type or 16-bit float or 32-bit float or 1-bit signless integer or 4-bit signed integer or 8-bit signed integer or 16-bit signed integer or 32-bit signed integer or 64-bit signed integer or 1-bit unsigned integer or 2-bit unsigned integer or 3-bit unsigned integer or 4-bit unsigned integer or 6-bit unsigned integer or 8-bit unsigned integer or 16-bit unsigned integer or 32-bit unsigned integer or 64-bit unsigned integer values, but got "
+ " must be tensor of bfloat16 type or 16-bit float or 32-bit float or 1-bit signless integer values, but got "
+ " must be tensor of bfloat16 type or 16-bit float or 32-bit float or 32-bit signed integer values, but got "
+ " must be tensor of bfloat16 type or 16-bit float or 32-bit float values, but got "
+ " must be variadic of , but got "
+ " must be variadic of CoreML Tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or complex type with 16-bit float elements or complex type with 32-bit float elements or Boolean type. values, but got "
+ " must be variadic of PDL handle to an `mlir::Attribute`, but got "
+ " must be variadic of PDL handle to an `mlir::Operation *`, but got "
+ " must be variadic of pdl type, but got "
+ " must be variadic of single element or range of PDL handle for an `mlir::Value`, but got "
+ " must be variadic of single element or range of PDL handle to an `mlir::Type`, but got "
+ " must be variadic of tensor of 16-bit float or 32-bit float or f8E5M2 type or f8E4M3FN type or 4/8/16/32/64-bit signed integer or 4/8/16/32/64-bit unsigned integer or complex type with 16-bit float elements or complex type with 32-bit float elements or Boolean type. values, but got "
+ " must be variadic of tensor of bfloat16 type or 16-bit float or 32-bit float or 1-bit signless integer or 4-bit signed integer or 8-bit signed integer or 16-bit signed integer or 32-bit signed integer or 64-bit signed integer or 1-bit unsigned integer or 2-bit unsigned integer or 3-bit unsigned integer or 4-bit unsigned integer or 6-bit unsigned integer or 8-bit unsigned integer or 16-bit unsigned integer or 32-bit unsigned integer or 64-bit unsigned integer values, but got "
+ " must not be greater than dimension shape "
+ " names and "
+ " neither in a parent nor in a child region)"
+ " noinline"
+ " non-constant padding mode must have padding value as constant."
+ " not broadcast compatible with broadcasted operands's shapes "
+ " number of axes to shrink "
+ " number of dimensions "
+ " of type "
+ " operand type"
+ " operands"
+ " operands and "
+ " operands mismatch between return-like terminators"
+ " operands, but enclosing function (@"
+ " operands, but found "
+ " operands, but target successor needs "
+ " option: "
+ " or more operands, but found "
+ " or more results"
+ " output type "
+ " padding lengths for dim "
+ " padding lengths has "
+ " pattern: "
+ " please add an explicit identity op."
+ " preds: "
+ " private"
+ " produced by: "
+ " region control flow edge "
+ " regions"
+ " remain"
+ " requires 0 or 1 element, but found "
+ " results"
+ " results but was provided "
+ " results, got "
+ " should have no arguments"
+ " should match input type #"
+ " shrink axes contains "
+ " shrink dimension "
+ " storage available."
+ " successors but found "
+ " threads, but LLVM_ENABLE_THREADS has been turned off\n"
+ " to :"
+ " to a `coreml.graph` or a `coreml.import`"
+ " to be one of: "
+ " to bind"
+ " to have 0 or 1 blocks"
+ " to have intent "
+ " to match"
+ " types"
+ " types to match operand list"
+ " values"
+ " vs "
+ " was not constrained"
+ " which is higher than input rank "
+ " which is higher than max value "
+ " which is not equal to input rank "
+ " with properties."
+ " {"
+ "!"
+ "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~"
+ "\""
+ "\"\n\v\f"
+ "\" \t\n\v\f\r"
+ "\"  \t\n\v\f\r"
+ "\"0x"
+ "\">"
+ "\"> : "
+ "\"can't happen\" -- you found a bug"
+ "#"
+ "#-}"
+ "$._-"
+ "$_-"
+ "%"
+ "%."
+ "%9lld  "
+ "%d"
+ "' "
+ "' as well)"
+ "' at index: "
+ "' attribute cannot have negative elements"
+ "' character in pretty dialect name"
+ "' does not expect resource handles"
+ "' does not implement InferTypeOpInterface"
+ "' does not implement the bytecode interface"
+ "' does not implement the bytecode interface, but found a version entry"
+ "' does not reference a valid function"
+ "' does not support 1:N conversion"
+ "' does not support result type inference (or is not registered)"
+ "' expects different type than prior uses: "
+ "' failed to satisfy constraint: "
+ "' failed to satisfy constraint: 16-bit signless integer attribute whose value is non-negative"
+ "' failed to satisfy constraint: 32-bit float attribute"
+ "' failed to satisfy constraint: 32-bit signed integer attribute"
+ "' failed to satisfy constraint: 32-bit signless integer attribute"
+ "' failed to satisfy constraint: 32-bit signless integer attribute whose value is non-negative"
+ "' failed to satisfy constraint: 32-bit signless integer attribute whose value is positive"
+ "' failed to satisfy constraint: 32-bit signless integer elements attribute"
+ "' failed to satisfy constraint: An Attribute containing a dense multi-dimensional array backed by a resource"
+ "' failed to satisfy constraint: Array of `param.decl`"
+ "' failed to satisfy constraint: Array of dictionary attributes"
+ "' failed to satisfy constraint: CoreML Pad Op's padding mode to use: 'circular' | 'constant' | 'reflect' | 'replicate' | 'symmetric'"
+ "' failed to satisfy constraint: Padding type enum"
+ "' failed to satisfy constraint: PoisonAttrInterface instance"
+ "' failed to satisfy constraint: The gelu approximation algorithm to use: 'none' | 'tanh' | 'sigmoid'"
+ "' failed to satisfy constraint: TypedAttr instance"
+ "' failed to satisfy constraint: any type attribute"
+ "' failed to satisfy constraint: array attribute"
+ "' failed to satisfy constraint: bool attribute"
+ "' failed to satisfy constraint: comparison kind enum"
+ "' failed to satisfy constraint: convolution padding type enum"
+ "' failed to satisfy constraint: dictionary of named attribute values"
+ "' failed to satisfy constraint: flat symbol reference attribute"
+ "' failed to satisfy constraint: gelu approximation function enum"
+ "' failed to satisfy constraint: i1 dense array attribute"
+ "' failed to satisfy constraint: i32 dense array attribute"
+ "' failed to satisfy constraint: i8 dense array attribute"
+ "' failed to satisfy constraint: logical kind enum"
+ "' failed to satisfy constraint: pooling padding type enum"
+ "' failed to satisfy constraint: scatter mode enum"
+ "' failed to satisfy constraint: string array attribute"
+ "' failed to satisfy constraint: string attribute"
+ "' failed to satisfy constraint: symbol reference attribute"
+ "' failed to satisfy constraint: type array attribute"
+ "' failed to satisfy constraint: type attribute of function type"
+ "' failed to satisfy constraint: type-array array attribute"
+ "' failed to satisfy constraint: unit attribute"
+ "' for dialect '"
+ "' found in dialect ('"
+ "' has already been registered"
+ "' has type "
+ "' in dictionary attribute"
+ "' in file metadata dictionary"
+ "' is a data layout attribute"
+ "' is already in use"
+ "' is an inferred attribute and should not be specified in the explicit attribute dictionary"
+ "' is invalid value for boolean argument! Try 0 or 1"
+ "' is unknown"
+ "' is unknown. If this is intended, please call allowUnregisteredDialects() on the MLIRContext, or use -allow-unregistered-dialect with the MLIR tool used."
+ "' not found for custom op '"
+ "' occurs more than once in the attribute list"
+ "' on a PassManager intended to run on '"
+ "' op"
+ "' op "
+ "' op inferred type(s) "
+ "' operation"
+ "' pass manager on '"
+ "' provides no attribute parsing hook"
+ "' provides no type parsing hook"
+ "' registered more than once!\n"
+ "' restricted to '"
+ "' specified."
+ "' that was explicitly marked illegal"
+ "' to be a string attribute, but got "
+ "' to encode alignment in first 4 bytes"
+ "' to encode alignment in first 4 bytes, but got non-power-of-2 value: "
+ "' to represent state for '"
+ "' value invalid for llong argument!"
+ "' value invalid for uint argument!"
+ "'!"
+ "') "
+ "') that does not allow unknown operations"
+ "', did you intend to nest?"
+ "', found '"
+ "', found that it represents '"
+ "'callee' must be function type, but got "
+ "'result' must be pdl type, but got "
+ "'result' must be single element or range of PDL handle to an `mlir::Type`, but got "
+ "(of:{"
+ ")\n"
+ ") "
+ ") -> "
+ ") does not match with the total size ("
+ ") doesn't match function result type ("
+ ") expected at least 1"
+ ") is larger than maximum value for size type ("
+ ") must match the type of the corresponding argument in "
+ ") returns "
+ ") specified in attribute '"
+ ") that remained live after conversion"
+ ") to ("
+ ") to match number of inputs ("
+ ") to match number of operands ("
+ ") to match number of outputs ("
+ ") to match number of results ("
+ "), but the maximum index was "
+ "*** unknown regexp error code ***"
+ "*no default*"
+ "+"
+ "+Inf"
+ ", ..."
+ ", ["
+ ", but dimension of input at axis is "
+ ", but got "
+ ", but got: "
+ ", but provided "
+ ", got "
+ ", must be in range ["
+ ", nullptr"
+ ", offset: "
+ ", offset_rank = "
+ ", scale_rank = "
+ ", type was "
+ ", which is not size 1"
+ "--"
+ "->"
+ "-INF"
+ "..."
+ "... Pass statistics report ..."
+ "/"
+ "//"
+ "// "
+ "0123456789"
+ "0123456789ABCDEFabcdef"
+ "0123456789abcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+ "0b"
+ "0x"
+ ": "
+ ": @"
+ ": CommandLine Error: Option '"
+ ": for the "
+ ": source has "
+ ": source type #"
+ ": {"
+ "::"
+ "; marking pass as failed"
+ "<"
+ "<\""
+ "<<NULL AFFINE MAP>>"
+ "<<NULL ATTRIBUTE>>"
+ "<<NULL TYPE>>"
+ "<<NULL VALUE>>"
+ "<<UNKNOWN OPERATION>>"
+ "<<UNKNOWN SSA VALUE>>"
+ "<Pass-Options-Parser>: no such option "
+ "<block argument> of type '"
+ "<block>"
+ "<empty>"
+ "<user-defined tensor>"
+ "= "
+ "= *unknown option value*\n"
+ "=<"
+ "=<value>"
+ "==="
+ "===\n"
+ "={"
+ ">"
+ ">..."
+ ">]"
+ "?"
+ "@"
+ "@ identifier expected to start with letter or '_'"
+ "@<<INVALID EMPTY SYMBOL>>"
+ "A file error occurred."
+ "A signal was caught while processing the MLIR module:"
+ "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
+ "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
+ "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789"
+ "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~"
+ "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ "
+ "ACK"
+ "All scale values must be positive"
+ "Allocation failed"
+ "AttrType (2)"
+ "AttrTypeOffset (3)"
+ "Attribute"
+ "Attribute or Type entry offset points past the end of section"
+ "AvgPool2dOp: BNNS AvgPoolOp does not support divisor override"
+ "AvgPool2dOp: failed to get constant divisor override"
+ "BEL"
+ "BNNS"
+ "BNNS Copy: invalid copy op to execute, params %p, output_ptr %p, input_ptr %p"
+ "BNNS Graph Builder MatMul does not support scalar inputs; use the mul op instead"
+ "BNNS Graph Builder Register Binary Arithmetic"
+ "BNNS Graph Builder Register Elementwise Activation"
+ "BNNS Graph Builder Register Reduction"
+ "BNNS Graph Builder Register Relational"
+ "BNNS Graph Builder Register Unary Arithmetic"
+ "BNNS Graph Builder tensors must be contiguous"
+ "BNNS Graph Builder: cannot inspect a NULL tensor"
+ "BNNS Graph Builder: passed graph builder of unexpected size"
+ "BNNS Graph Builder: passed null graph builder"
+ "BNNS Graph Compile: Failed to parse '"
+ "BNNS Graph Compile: Failed to parse type of function input '"
+ "BNNS Graph Compile: failed to parse bytecode."
+ "BNNS Graph Context Set Dynamic Shapes : received invalid graph context."
+ "BNNS Graph tensors must have unique names"
+ "BNNS Graph: ffn op values changed, execution failed"
+ "BNNS Graph: ffn_norm encountered NaN, execution failed"
+ "BNNS Tensor Contraction: output descriptor is illegal \"%s\""
+ "BNNS could not replace BNNS graphs by delegate ops"
+ "BNNS could not segment CoreML IR graph"
+ "BNNS transpose2d_amx1, unsupported data types"
+ "BNNS transpose2d_amx2, unsupported data types"
+ "BNNS transpose2d_amx3, unsupported data types"
+ "BNNS-MLIR bytecode does not contain exactly one module"
+ "BNNS-MLIR functions block contains non-function operation"
+ "BNNS-MLIR input does not support specifying a single function to compile"
+ "BNNS-MLIR module does not have exactly one region"
+ "BNNS-MLIR module region does not have exactly one block"
+ "BNNS: unsupported input type"
+ "BNNS: wrong variant chosen"
+ "BNNSGraphCompileOptionsSetInputFormat"
+ "BNNSGraphCompileOptionsSetTargetByChipsetID"
+ "BS"
+ "Base64 encoded strings must be a multiple of 4 bytes in length"
+ "BasicNeuralNetworkSubroutines-1835~189"
+ "BatchNormOp: failed to get constant epsilon"
+ "BroadcastInDimsOp: failed to get constant axes"
+ "BroadcastInDimsOp: failed to get constant dim_sizes"
+ "Broken properties section: didn't exhaust the offsets table"
+ "Buffer allocation failed"
+ "Building op `"
+ "CAN"
+ "CR"
+ "Can't add pass '"
+ "Cannot find option named '"
+ "Cannot specify more than one option with cl::ConsumeAfter!"
+ "Canonicalize operations"
+ "Canonicalizer"
+ "ConcatOp: failed to get constant dim"
+ "ConstantOp value must be either DenseElementsAttr or DenseResourceElementsAttr"
+ "ConstantOp value type must match output type"
+ "Conv2dOp: failed to get constant axes"
+ "Conv2dOp: failed to get constant dilation"
+ "Conv2dOp: failed to get constant padding"
+ "Convert Odie to BNNS MLIR"
+ "Convert PDL ops to PDL interpreter ops"
+ "ConvertCoreMLToBNNS"
+ "ConvertPDLToPDLInterp"
+ "DC1"
+ "DC2"
+ "DC3"
+ "DC4"
+ "DEL"
+ "DLE"
+ "Dead op was not eliminated!"
+ "DenseI32ArrayAttr"
+ "DesiredTypeName = "
+ "Dialect (1)"
+ "Dialect Attribute already registered."
+ "Dialect Attribute with name "
+ "Dialect Type already registered."
+ "Dialect Type with name "
+ "Dialect `"
+ "Dialect does not support versioning"
+ "DialectVersions (7)"
+ "Disable multi-threading within MLIR, overrides any further call to MLIRContext::enableMultiThreading()"
+ "Don't run any control-flow simplification."
+ "EM"
+ "ENABLE_ODIE_COREMLAX_COPY_FOLDING"
+ "ENQ"
+ "EOT"
+ "ESC"
+ "ETB"
+ "ETX"
+ "Elide ElementsAttrs with \"...\" that have more elements than the given upper limit"
+ "Elide printing value of resources if string is too long in chars."
+ "Enable -time-passes memory tracking (this may be slow)"
+ "Epsilon must be in {fp32, fp16, bf16}"
+ "Error"
+ "Error in BNNS Conv3D."
+ "Error in Conv3D."
+ "Error in ConvTranspose3D."
+ "Error opening info-output-file '"
+ "Expand or Squeeze: failed to get constant axes"
+ "Expected '<' after 'sparse'"
+ "Expected operand "
+ "Exponent has no digits"
+ "FF"
+ "FS"
+ "Failed to lower CoreML IR to BNNS-MLIR"
+ "Failed to mmap memory"
+ "Failed to replace GraphOps by DelegateOps"
+ "Failed to segment CoreML graph"
+ "Failed to write segmented CoreML graph"
+ "Failures have been detected while processing an MLIR pass pipeline"
+ "File to append -stats and -timer output to"
+ "FusedLocation"
+ "FusedLocation<"
+ "GS"
+ "GatherLut op failed"
+ "GatherLut op failed with out of bound index"
+ "General options"
+ "GraphOp has no concept of 'nested' visibility"
+ "GreedyPatternRewriteIteration"
+ "GreedyPatternRewriteIteration("
+ "HT"
+ "Heap"
+ "Hex strings require an exponent"
+ "INF"
+ "INFINITY"
+ "INVALIDBLOCK"
+ "IO failure on output stream: "
+ "IOSurface"
+ "IS1"
+ "IS2"
+ "IS3"
+ "IS4"
+ "In the report, sort the timers in each group in wall clock time order"
+ "In-Flight Diagnostics:\n"
+ "Inconvertible error value. An error has occurred that could not be converted to a known std::error_code. Please file a bug."
+ "Inf"
+ "Input lut should have rank=K+2 where K is the rank of indices"
+ "Internal error in dominance verification"
+ "Invalid Base64 character %#2.2x at index %llu"
+ "Invalid attribute `alpha` in property conversion: "
+ "Invalid attribute `approx` in property conversion: "
+ "Invalid attribute `approximate` in property conversion: "
+ "Invalid attribute `arg_attrs` in property conversion: "
+ "Invalid attribute `attributeValueNames` in property conversion: "
+ "Invalid attribute `axes` in property conversion: "
+ "Invalid attribute `axis` in property conversion: "
+ "Invalid attribute `batch_dims` in property conversion: "
+ "Invalid attribute `benefit` in property conversion: "
+ "Invalid attribute `beta` in property conversion: "
+ "Invalid attribute `block_sizes` in property conversion: "
+ "Invalid attribute `callee` in property conversion: "
+ "Invalid attribute `caseValues` in property conversion: "
+ "Invalid attribute `ceil_mode` in property conversion: "
+ "Invalid attribute `compareAtLeast` in property conversion: "
+ "Invalid attribute `constantType` in property conversion: "
+ "Invalid attribute `constantTypes` in property conversion: "
+ "Invalid attribute `count` in property conversion: "
+ "Invalid attribute `delegate_id` in property conversion: "
+ "Invalid attribute `dilation` in property conversion: "
+ "Invalid attribute `eliminate_axis` in property conversion: "
+ "Invalid attribute `epsilon` in property conversion: "
+ "Invalid attribute `exclude_padding_from_average` in property conversion: "
+ "Invalid attribute `externAttr` in property conversion: "
+ "Invalid attribute `externalize` in property conversion: "
+ "Invalid attribute `function_type` in property conversion: "
+ "Invalid attribute `generatedOps` in property conversion: "
+ "Invalid attribute `groups` in property conversion: "
+ "Invalid attribute `ignore_axis` in property conversion: "
+ "Invalid attribute `ignore_end` in property conversion: "
+ "Invalid attribute `ignore_extent` in property conversion: "
+ "Invalid attribute `index` in property conversion: "
+ "Invalid attribute `inferredResultTypes` in property conversion: "
+ "Invalid attribute `inputAttributeNames` in property conversion: "
+ "Invalid attribute `interleave` in property conversion: "
+ "Invalid attribute `isNegated` in property conversion: "
+ "Invalid attribute `kernel_sizes` in property conversion: "
+ "Invalid attribute `kind` in property conversion: "
+ "Invalid attribute `message` in property conversion: "
+ "Invalid attribute `mode` in property conversion: "
+ "Invalid attribute `name` in property conversion: "
+ "Invalid attribute `no_inline` in property conversion: "
+ "Invalid attribute `num_splits` in property conversion: "
+ "Invalid attribute `oor_fatal` in property conversion: "
+ "Invalid attribute `opName` in property conversion: "
+ "Invalid attribute `opname` in property conversion: "
+ "Invalid attribute `pad_type` in property conversion: "
+ "Invalid attribute `pad` in property conversion: "
+ "Invalid attribute `padding_mode` in property conversion: "
+ "Invalid attribute `param_decls` in property conversion: "
+ "Invalid attribute `path` in property conversion: "
+ "Invalid attribute `perm` in property conversion: "
+ "Invalid attribute `priv` in property conversion: "
+ "Invalid attribute `res_attrs` in property conversion: "
+ "Invalid attribute `resource` in property conversion: "
+ "Invalid attribute `rewriter` in property conversion: "
+ "Invalid attribute `rootKind` in property conversion: "
+ "Invalid attribute `safeTransforms` in property conversion: "
+ "Invalid attribute `split_sizes` in property conversion: "
+ "Invalid attribute `step` in property conversion: "
+ "Invalid attribute `stride` in property conversion: "
+ "Invalid attribute `strides` in property conversion: "
+ "Invalid attribute `sym_name` in property conversion: "
+ "Invalid attribute `sym_visibility` in property conversion: "
+ "Invalid attribute `target_spec` in property conversion: "
+ "Invalid attribute `toImport` in property conversion: "
+ "Invalid attribute `transpose_a` in property conversion: "
+ "Invalid attribute `transpose_b` in property conversion: "
+ "Invalid attribute `type` in property conversion: "
+ "Invalid attribute `types` in property conversion: "
+ "Invalid attribute `value` in property conversion: "
+ "Invalid character in exponent"
+ "Invalid character in significand"
+ "Invalid string"
+ "Invalid string length"
+ "Invalid trailing hexadecimal fraction!"
+ "KERNEL_COPY_CONCAT_DYNAMIC_SME_OR_NEON"
+ "KERNEL_COPY_SLICE_BY_SIZE_DYNAMIC_MLA_OR_NEON"
+ "KERNEL_COPY_SLICE_BY_SIZE_DYNAMIC_SME_OR_NEON"
+ "KERNEL_DODGE_V2"
+ "KERNEL_EINSUM_STRIDED_GEMM_INTEL64_DYNAMIC"
+ "KERNEL_EINSUM_STRIDED_GEMM_MLA1_DYNAMIC"
+ "KERNEL_EINSUM_STRIDED_GEMM_MLA2_DYNAMIC"
+ "KERNEL_EINSUM_STRIDED_GEMM_MLA3_DYNAMIC"
+ "KERNEL_EINSUM_STRIDED_GEMM_NEON_DYNAMIC"
+ "KERNEL_EINSUM_STRIDED_GEMM_SME2_DYNAMIC"
+ "KERNEL_GATHER_LUT"
+ "KERNEL_GEMM_INTEL64"
+ "KERNEL_GEMM_INTEL64_DYNAMIC"
+ "KERNEL_GEMM_MLA1"
+ "KERNEL_GEMM_MLA1_DYNAMIC"
+ "KERNEL_GEMM_MLA2"
+ "KERNEL_GEMM_MLA2_DYNAMIC"
+ "KERNEL_GEMM_MLA3"
+ "KERNEL_GEMM_MLA3_DYNAMIC"
+ "KERNEL_GEMM_NEON"
+ "KERNEL_GEMM_NEON_DYNAMIC"
+ "KERNEL_GEMM_SME2"
+ "KERNEL_GEMM_SME2_DYNAMIC"
+ "KERNEL_GRU_MLA1"
+ "KERNEL_GRU_MLA2"
+ "KERNEL_GRU_MLA3"
+ "KERNEL_GRU_NEON"
+ "KERNEL_HID_SSP_ATTENTION_MLA1"
+ "KERNEL_HID_SSP_ATTENTION_MLA2"
+ "KERNEL_LSTM_MERGED_WEIGHTS_MLA1"
+ "KERNEL_LSTM_MERGED_WEIGHTS_MLA2"
+ "KERNEL_LSTM_MERGED_WEIGHTS_MLA3"
+ "KERNEL_LSTM_MERGED_WEIGHTS_NEON"
+ "KERNEL_LSTM_MLA1"
+ "KERNEL_LSTM_MLA2"
+ "KERNEL_LSTM_MLA3"
+ "KERNEL_LSTM_NEON"
+ "KERNEL_MATMUL_ELEMENTWISE_ACTIVATION_MATMUL_MLA2"
+ "KERNEL_REDUCE_FP_SUM_AMX2"
+ "KERNEL_REDUCE_FP_SUM_AMX3"
+ "KERNEL_REDUCE_MIN_MAX_AXM2"
+ "KERNEL_REDUCE_MIN_MAX_AXM3"
+ "KERNEL_RNN_MERGED_WEIGHTS_MLA1"
+ "KERNEL_RNN_MERGED_WEIGHTS_MLA2"
+ "KERNEL_RNN_MERGED_WEIGHTS_MLA3"
+ "KERNEL_RNN_MERGED_WEIGHTS_NEON"
+ "KERNEL_RNN_MLA1"
+ "KERNEL_RNN_MLA2"
+ "KERNEL_RNN_MLA3"
+ "KERNEL_RNN_NEON"
+ "KERNEL_SPATIAL_NORM_MLA3"
+ "KERNEL_SPATIAL_NORM_SME2"
+ "KERNEL_TTS_NLP_KV_CACHE_DRAFT_MHA"
+ "KERNEL_TTS_SOUNDSTORM_CONV_FC_SWIGLU_MODULE"
+ "KERNEL_TTS_SOUNDSTORM_FFN_MF_NORM_X3"
+ "KERNEL_TTS_SOUNDSTORM_FFN_NORM_X3"
+ "KERNEL_TTS_SOUNDSTORM_FIXED_CONV_FC_SWIGLU_MODULE"
+ "KERNEL_UPDATE_STREAMING_STATE"
+ "LF"
+ "LLVM ERROR: "
+ "LLVM ERROR: out of memory\n"
+ "Labels of patterns that should be filtered out during application"
+ "Labels of patterns that should be used during application, all other patterns are filtered out"
+ "Length of 'scale' and the dimension of `input` at axis must be the same. "
+ "MLIR Parser: custom op parser '%s'"
+ "MLIR tensor already registered for a different BNNS tensor"
+ "MLIR21.0.0git"
+ "ML\xefR"
+ "MTLBuffer"
+ "Max. iterations between applying patterns / simplifying regions"
+ "Max. number of pattern rewrites within an iteration"
+ "MaxPoolOp: BNNS does not support non-unit dilation"
+ "MaxPoolOp: failed to get constant dilation"
+ "Miscellaneous Ungrouped Timers"
+ "Multiple errors"
+ "Multiple errors:\n"
+ "NAK"
+ "NUL"
+ "Native PDL Rewrite failed, but the pattern rewriter doesn't support recovery. Failable pattern rewrites should not be used with pattern rewriters that do not support them."
+ "None"
+ "OpaqueLocation"
+ "OpaqueLocation<"
+ "OpaqueLocation<%p>"
+ "Operations with a 'SymbolTable' must have exactly one block"
+ "Operations with a 'SymbolTable' must have exactly one region"
+ "PATH"
+ "Perform aggressive control-flow simplification (e.g. block merging)."
+ "Perform control flow optimizations to the region tree"
+ "Perform simple control-flow simplifications (e.g. dead args elimination)."
+ "Pipeline failed while executing "
+ "Pipeline failed while executing ["
+ "PoolOp: failed to get constant ceil_mode"
+ "PoolOp: failed to get constant kernel_size"
+ "PoolOp: failed to get constant padding"
+ "PoolOp: failed to get constant stride"
+ "Print DenseElementsAttrs with a hex string that have more elements than the given upper limit (use -1 to disable)"
+ "Print SSA IDs using NameLocs as prefixes"
+ "Print debug info in MLIR output"
+ "Print pretty debug info in MLIR output"
+ "Print the generic op form"
+ "Print unique SSA ID numbers for values, block arguments and naming conflicts across all regions"
+ "Print users of operation results and block arguments as a comment"
+ "Print with local scope and inline information (eliding aliases for attributes, types, and locations)"
+ "Properties (8)"
+ "Properties idx out-of-bound for "
+ "Properties offset out-of-bound for "
+ "Property conversion failed."
+ "Provided NUM_PALETTES "
+ "Provided length of scale is "
+ "REG_0x%x"
+ "REG_ASSERT"
+ "REG_BADBR"
+ "REG_BADPAT"
+ "REG_BADRPT"
+ "REG_EBRACE"
+ "REG_EBRACK"
+ "REG_ECOLLATE"
+ "REG_ECTYPE"
+ "REG_EESCAPE"
+ "REG_EMPTY"
+ "REG_EPAREN"
+ "REG_ERANGE"
+ "REG_ESPACE"
+ "REG_ESUBREG"
+ "REG_INVARG"
+ "REG_NOMATCH"
+ "RS"
+ "ReduceOp: failed to get constant axes"
+ "Region #"
+ "Registered dialects: "
+ "Replace the graph body by a call to the BNNS delegate"
+ "ReplaceGraphBodyWithDelegateOp"
+ "Resource (5)"
+ "ResourceOffset (6)"
+ "SI"
+ "SO"
+ "SOC must not be empty"
+ "SOH"
+ "STX"
+ "SUB"
+ "SYN"
+ "Seed the worklist in general top-down order"
+ "Segment operations intended for the BNNS delegate"
+ "Segmenter"
+ "SelBroadcastInDimsOpectOp: failed to get construct reps"
+ "SelectOp: failed to get constant dim"
+ "SelectOp: failed to get constant index"
+ "SelectOp: failed to get construct start index"
+ "Significand has no digits"
+ "Skip op verification when using custom printers"
+ "Skip regions when printing ops."
+ "SliceOp: failed to get constant strides"
+ "SmallVector capacity unable to grow. Already at maximum size "
+ "SmallVector unable to grow. Requested capacity ("
+ "SoftmaxOp: failed to get constant axis"
+ "SoftmaxOp: failed to get constant groups"
+ "SplitOp: failed to get constant section sizes"
+ "StackOp: failed to get constant axis"
+ "StackOp: failed to get constant split size"
+ "String (0)"
+ "String contains multiple dots"
+ "String has no digits"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertAddOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertAndOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertBatchMatmul]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertBatchNormOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertBroadcastInDimsOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertCastOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertConcatOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertConstOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertConv2dOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertCosOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertDivOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertEqOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertExpOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertFillOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertFloorDivOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertGatherNDOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertGeluOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertGraphToFunc]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertGtOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertLogOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertMaxOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertMinOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertModOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertMulOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertNeOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertNotOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertOrOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertOutputOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertPoolOp<mlir::ODIE::Compiler::CoreML::AvgPool2dOp, mlir::bnns::AveragePoolingOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertPoolOp<mlir::ODIE::Compiler::CoreML::MaxPool2dOp, mlir::bnns::MaxPoolingOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertPowOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertRange1dOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertReduce<mlir::ODIE::Compiler::CoreML::AllOp, mlir::bnns::ReduceLogicalAndOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertReduce<mlir::ODIE::Compiler::CoreML::AnyOp, mlir::bnns::ReduceLogicalOrOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertReduce<mlir::ODIE::Compiler::CoreML::ReduceMaxOp, mlir::bnns::ReduceMaxOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertReduce<mlir::ODIE::Compiler::CoreML::ReduceMeanOp, mlir::bnns::ReduceMeanOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertReduce<mlir::ODIE::Compiler::CoreML::ReduceSumOp, mlir::bnns::ReduceSumOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertReluOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertReshapeOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertRsqrtOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertScatterNdOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSelectOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertShapeOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSigmoidOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSiluOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSinOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSliceOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSliceUpdateOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSoftmaxOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSplitOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSqrtOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSqueezeExpand<mlir::ODIE::Compiler::CoreML::ExpandDimsOp, mlir::bnns::ExpandDimsOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSqueezeExpand<mlir::ODIE::Compiler::CoreML::ShrinkDimsOp, mlir::bnns::SqueezeOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertStackOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertSubOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertTanhOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertTileOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertTransposeOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::ConvertWhereOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = (anonymous namespace)::DeleteLLOModuleOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = bool]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = double]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = float]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = int]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = llvm::APFloat]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = llvm::APInt]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = llvm::StringRef]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = long long]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = long]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ApplyPatternAction]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ArrayAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::AttributeTrait::IsLocation<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::Attribute]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::BlobAttr::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::BlobAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::BoolAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::BranchOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::BytecodeDialectInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::BytecodeOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::BytecodeOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::CallOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::CallOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::CallableOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::CallableOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ConditionallySpeculatable::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ConditionallySpeculatable]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ConvertToLLVMPatternInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DataLayoutSpecInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DenseElementsAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DenseIntElementsAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DenseResourceElementsAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DialectFoldInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DialectInlinerInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DialectResourceBlobHandle<mlir::BuiltinDialect>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DictionaryAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::DistinctAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ElementsAttr::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ElementsAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::FlatSymbolRefAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::FloatAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::FloatType::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::FloatType]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::FunctionOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::FunctionOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::InferShapedTypeOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::InferShapedTypeOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::InferTypeOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::InferTypeOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::IntegerAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::LocationAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::MemRefElementTypeInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::MemRefLayoutAttrInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::MemRefLayoutAttrInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::MemoryEffectOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::MemoryEffectOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::MemoryEffects::Allocate]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::MemoryEffects::Read]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ApproximateAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ComplexDecompositionOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ComplexDecompositionOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ConditionallyFoldable::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ConditionallyFoldable]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ExternAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ImportableOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ImportableOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::IntentProviderOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::IntentProviderOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::KernelTypeInference::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::KernelTypeInference]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::PaddingModeAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ParamDeclArrayAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ParamScopeOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ParamScopeOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ReplaceBroadcastToWithBroadcastInDims]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ReplaceWithOneBlock]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ReplaceWithReshape<mlir::ODIE::Compiler::CoreML::ExpandDimsOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::ReplaceWithReshape<mlir::ODIE::Compiler::CoreML::ShrinkDimsOp>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::TargetSpecAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::CallOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ClassOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ConstantOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::DelegateOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ErrorOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::FuncOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::GELUOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::GraphOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ImportOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::InvokeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::IsolatedGroupOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::MemberOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::ModuleOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::PadOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::PlaceholderOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreML::detail::TargetSpecOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreMLAX::FoldCastOpIntoCopyWithConstraintsOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreMLAX::PromoteCastOpToViewOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreMLAX::PromoteToFromPairToCastOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreMLAX::RemoveRedundantCopyDiscardingConstraintsOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::CoreMLAX::RemoveRedundantCopyWithConstraintsOp]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::KeywordPrintableAttr::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::KeywordPrintableAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::ParamAttrInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ODIE::Compiler::ParamAttrInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpAsmDialectInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpAsmOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpAsmOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AffineScope<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AlwaysSpeculatableImplTrait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AtLeastNOperands<1>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AtLeastNOperands<2>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AtLeastNOperands<3>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AtLeastNSuccessors<1>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AttrSizedOperandSegments<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AttrSizedResultSegments<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::AutomaticAllocationScope<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ConstantLike<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::Elementwise<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasOnlyGraphRegion<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::ODIE::Compiler::CoreML::ClassOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::ODIE::Compiler::CoreML::FuncOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::ODIE::Compiler::CoreML::GraphOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::ODIE::Compiler::CoreML::WhileOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::pdl::PatternOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::pdl::RewriteOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasParent<mlir::pdl_interp::ForEachOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::HasRecursiveMemoryEffects<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::IsCommutative<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::IsIdempotent<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::IsIsolatedFromAbove<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::IsTerminator<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::MemRefsNormalizable<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NOperands<2>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NOperands<3>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NOperands<4>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NOperands<5>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NOperands<6>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NOperands<7>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NRegions<2>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NResults<2>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NSuccessors<2>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NoRegionArguments<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::NoTerminator<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ODIE::Compiler::CoreML::Decomposable<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ODIE::Compiler::CoreML::KernelNotImplemented<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneOperand<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneRegion<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneResult<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneSuccessor<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::ODIE::Compiler::CoreML::TokenType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::ShapedType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::TensorType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::bnns::TensorWithLayoutType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::pdl::AttributeType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::pdl::OperationType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::pdl::PDLType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::pdl::RangeType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::pdl::TypeType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OneTypedResult<mlir::pdl::ValueType>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::OpInvariants<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ResultsBroadcastableShape<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ReturnLike<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::SameOperandsAndResultElementType<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::SameOperandsAndResultShape<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::SameOperandsAndResultType<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::SameOperandsElementType<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::SameTypeOperands<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::SingleBlock<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::SingleBlockImplicitTerminator<mlir::ODIE::Compiler::CoreML::YieldOp>::Impl<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::SymbolTable<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::VariadicOperands<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::VariadicResults<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ZeroOperands<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ZeroRegions<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ZeroResults<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::OpTrait::ZeroSuccessors<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::RegionBranchOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::RegionBranchOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::RegionBranchTerminatorOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::RegionBranchTerminatorOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::RegionKindInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::RegionKindInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ResourceBlobManagerDialectInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ShapedType::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ShapedType]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::StringAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::SymbolOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::SymbolOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::SymbolRefAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::SymbolUserOpInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::SymbolUserOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::TypeAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::TypedAttr::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::TypedAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::UnitAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ValueSemantics<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::VerifiableTensorEncoding::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::VerifiableTensorEncoding]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::(anonymous namespace)::CopyInputsToOutputs]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::CompareKindEnumAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::ConvPaddingEnumAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::GeluApproxEnumAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::LogicalKindEnumAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::PadEnumAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::PoolingPaddingEnumAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::ScatterModeAttr]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::AffineDequantizeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ApplyLUTOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::AveragePoolingOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::BatchNormOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ClampedReluOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ClipOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::CompareOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ConcatOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ConstOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ConvOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::EluOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ExpandDimsOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::GatherNDOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::GatherOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::GeluOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::HardSigmoidOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::IndexPermuteOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::InverseOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::L2PoolingOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::LeakyReluOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::LinearActivationOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::LogOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::LogSoftmaxOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::LogicalOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::MatmulOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::MaxPoolingOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::PadOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceL1NormOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceL2NormOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceLogSumExpOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceLogSumOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceLogicalAndOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceLogicalOrOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceMaxOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceMeanOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceMinOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceProductOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceSumOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ReduceSumSquareOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::RsqrtOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ScaledTanhOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ScatterNdOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::SliceExtentOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::SliceRangeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::SliceUpdateOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::SoftmaxOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::SoftplusOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::SplitOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::SqueezeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::StackOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ThresholdOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bnns::detail::ThresholdReluOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::bufferization::BufferizableOpInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::AffineBinaryOpExprStorage]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::AffineConstantExprStorage]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::AffineDimExprStorage]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::AffineMapStorage]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::DenseArrayAttrImpl<bool>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::DenseArrayAttrImpl<int32_t>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::DenseArrayAttrImpl<int8_t>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::IntegerSetStorage]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::ModuleOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::OpToOpPassAdaptor]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::PreservedAnalyses::AllAnalysesType]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::detail::StorageUserTrait::IsMutable<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::func::detail::CallIndirectOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::func::detail::CallOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::func::detail::ConstantOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::func::detail::FuncOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::ApplyNativeConstraintOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::ApplyNativeRewriteOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::AttributeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::OperationOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::PatternOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::ReplaceOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::ResultOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::ResultsOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::RewriteOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::TypeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl::detail::TypesOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::ApplyConstraintOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::ApplyRewriteOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CheckAttributeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CheckOperandCountOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CheckOperationNameOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CheckResultCountOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CheckTypeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CheckTypesOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CreateAttributeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CreateOperationOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CreateTypeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::CreateTypesOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::ExtractOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::FuncOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::GetAttributeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::GetOperandOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::GetOperandsOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::GetResultOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::GetResultsOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::RecordMatchOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::SwitchAttributeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::SwitchOperandCountOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::SwitchOperationNameOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::SwitchResultCountOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::SwitchTypeOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_interp::detail::SwitchTypesOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::AttributeAnswer]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::AttributeLiteralPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::AttributePosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::AttributeQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::BoolNode]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::ConstraintPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::ConstraintQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::EqualToQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::ExitNode]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::FalseAnswer]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::ForEachPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::IsNotNullQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::OperandCountAtLeastQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::OperandCountQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::OperandGroupPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::OperandPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::OperationNameAnswer]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::OperationNameQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::OperationPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::ResultCountAtLeastQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::ResultCountQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::ResultGroupPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::ResultPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::SuccessNode]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::SwitchNode]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::TrueAnswer]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::TypeAnswer]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::TypeLiteralPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::TypePosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::TypeQuestion]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::UnsignedAnswer]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::pdl_to_pdl_interp::UsersPosition]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ub::PoisonAttrInterface::Trait<Empty>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ub::PoisonAttrInterface]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = mlir::ub::detail::PoisonOpGenericAdaptorBase::Properties]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = short]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = signed char]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<double>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<float>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<int>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<llvm::APFloat>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<llvm::APInt>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<long long>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<short>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<signed char>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<unsigned char>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<unsigned int>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<unsigned long long>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = std::complex<unsigned short>]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = unsigned char]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = unsigned int]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = unsigned long long]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = unsigned long]"
+ "StringRef llvm::detail::getTypeNameImpl() [DesiredTypeName = unsigned short]"
+ "TERM"
+ "Test only: Fail pass on non-convergence to detect cyclic pattern"
+ "The first K dimensions of lut must be factors of indices dimensions where K is the rank of indices"
+ "The number of elements in nonzero_data should not exceed the number of elements in mask"
+ "The output dimension does not match the indices' dimension with vector size over vector_axis"
+ "Total\n\n"
+ "TransposeOp: failed to get constant permutation"
+ "Trying to create a Type that was not registered in this MLIRContext."
+ "Trying to create an Attribute that was not registered in this MLIRContext."
+ "Trying to register different dialects for the same namespace: "
+ "Trying to schedule a dynamic pipeline on an operation that isn't nested under the current operation the pass is processing"
+ "Type"
+ "US"
+ "Unexpected missing `wasRegistered` opname flag at bytecode version "
+ "Unknown ("
+ "Unknown builtin attribute"
+ "Unknown pooling padding type"
+ "UnknownLocation"
+ "Unrecognized input format"
+ "Unsupported data type for "
+ "Unsupported pad mode: constant "
+ "Unsupported type "
+ "Unterminated brace sequence. Escape with {{ for a literal brace."
+ "VT"
+ "Warning: request a ThreadPool with "
+ "When a diagnostic is emitted on an operation, also print the operation as an attached note"
+ "When a diagnostic is emitted, also print the stack trace as an attached note"
+ "Zeroes are not permitted in new_shape"
+ "[:<:]]"
+ "[:>:]]"
+ "[=<"
+ "[unknown]"
+ "\\/"
+ "] do not match dest strides ["
+ "] exceeds input rank"
+ "] is "
+ "] is 0"
+ "] is expected to be "
+ "]) does not match type (["
+ "]); inferred shape of indices literal (["
+ "]); inferred shape of values literal (["
+ "], and type="
+ "]: "
+ "]<"
+ "]>"
+ "^[a-zA-Z_][a-zA-Z_0-9\\$]*$"
+ "^bb"
+ "_"
+ "__anon_reshape_shape"
+ "__var"
+ "_anon_default_beta_"
+ "_anon_default_beta_for:"
+ "_anon_default_gamma_"
+ "_anon_default_gamma_for:"
+ "_bnns_graph_builder_"
+ "_bnns_graph_builder_register+"
+ "_bnns_graph_builder_register_"
+ "_bnns_graph_builder_register_argmax"
+ "_bnns_graph_builder_register_argmin"
+ "_bnns_graph_builder_register_argsort"
+ "_bnns_graph_builder_register_batch_norm"
+ "_bnns_graph_builder_register_cast"
+ "_bnns_graph_builder_register_channel_norm"
+ "_bnns_graph_builder_register_concat"
+ "_bnns_graph_builder_register_conv"
+ "_bnns_graph_builder_register_conv_transpose"
+ "_bnns_graph_builder_register_copy"
+ "_bnns_graph_builder_register_cumsum"
+ "_bnns_graph_builder_register_dynamic_reshape"
+ "_bnns_graph_builder_register_fma"
+ "_bnns_graph_builder_register_gather"
+ "_bnns_graph_builder_register_gather_nd"
+ "_bnns_graph_builder_register_input"
+ "_bnns_graph_builder_register_layer_norm"
+ "_bnns_graph_builder_register_linear"
+ "_bnns_graph_builder_register_matmul"
+ "_bnns_graph_builder_register_output"
+ "_bnns_graph_builder_register_pad"
+ "_bnns_graph_builder_register_prelu"
+ "_bnns_graph_builder_register_reshape"
+ "_bnns_graph_builder_register_scatter"
+ "_bnns_graph_builder_register_select"
+ "_bnns_graph_builder_register_shape"
+ "_bnns_graph_builder_register_slice"
+ "_bnns_graph_builder_register_slice_update"
+ "_bnns_graph_builder_register_softmax"
+ "_bnns_graph_builder_register_squeeze"
+ "_bnns_graph_builder_register_topk"
+ "_bnns_graph_builder_register_transpose"
+ "_bnns_graph_builder_register_unsqueeze"
+ "_bnns_graph_builder_regsiter_"
+ "_input_"
+ "_inversed_input_3_y_0_to_fp16"
+ "_lut("
+ "_mul"
+ "_resources: {"
+ "`"
+ "` but it isn't known in this MLIRContext: the dialect may not be loaded or this operation hasn't been added by the dialect. See also https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-dialects-management"
+ "` in dialect `"
+ "` on "
+ "` type created with unregistered dialect. If this is intended, please call allowUnregisteredDialects() on the MLIRContext, or use -allow-unregistered-dialect with the MLIR opt tool used"
+ "`!"
+ "`dense_resource` expected a shaped type"
+ "`{0}` running `{1}` on Operation `{2}`"
+ "a dialect with namespace '"
+ "abcdefghijklmnopqrstuvwxyz"
+ "add a trailing dot to make the literal a float"
+ "affine_map"
+ "affine_map<"
+ "affine_set"
+ "affine_set<"
+ "after"
+ "aggressive"
+ "alert"
+ "alignments"
+ "all input tensors must have the same data type"
+ "all input tensors' shapes must match except for the axis"
+ "all input types must match"
+ "all non-scalar operands/results must have the same shape and base type"
+ "alnum"
+ "ampersand"
+ "any"
+ "apostrophe"
+ "apply-pattern"
+ "approx"
+ "approximate"
+ "are"
+ "arg"
+ "arg #"
+ "arg_attrs"
+ "argument and block argument type mismatch"
+ "arguments may only have dialect attributes"
+ "array"
+ "array<"
+ "as"
+ "asterisk"
+ "async.value"
+ "at"
+ "at unspecified input location."
+ "at_least"
+ "attempting to parse "
+ "attempting to parse a byte at the end of the bytecode"
+ "attempting to skip "
+ "attention_scale"
+ "attribute"
+ "attribute '"
+ "attribute dilation must have size matching spatial rank of input"
+ "attribute names with a '.' are reserved for dialect-defined names"
+ "attribute pad is only permitted if pad_type == provided"
+ "attribute pad must have size 2 * spatial rank of input"
+ "attribute stride must have size matching spatial rank of input"
+ "attribute type different than expected: expected "
+ "attributeValueNames"
+ "attributes"
+ "axis can only be a scalar"
+ "axis must be within range (-data_rank - 1, data_rank) (exclusive). Provided axis: "
+ "axis must not exceed rank of tensors"
+ "backslash"
+ "backspace"
+ "bad_function_call was thrown in -fno-exceptions mode"
+ "bad_optional_access was thrown in -fno-exceptions mode"
+ "baseEncoding"
+ "before"
+ "benefit"
+ "bidirectional_lstm"
+ "blank"
+ "blob"
+ "block argument not owned by block"
+ "block with no terminator, has "
+ "block_sizes"
+ "bnns.abs"
+ "bnns.abstract_to_layout"
+ "bnns.acos"
+ "bnns.acosh"
+ "bnns.add"
+ "bnns.affine_dequantize"
+ "bnns.apply_lut"
+ "bnns.asin"
+ "bnns.asinh"
+ "bnns.atan"
+ "bnns.atanh"
+ "bnns.avg_pool"
+ "bnns.batch_norm"
+ "bnns.broadcast"
+ "bnns.cast"
+ "bnns.ceil"
+ "bnns.clamped_relu"
+ "bnns.clip"
+ "bnns.compare"
+ "bnns.concat"
+ "bnns.const"
+ "bnns.conv"
+ "bnns.copy"
+ "bnns.cos"
+ "bnns.cosh"
+ "bnns.dead"
+ "bnns.div"
+ "bnns.elu"
+ "bnns.erf"
+ "bnns.exp"
+ "bnns.exp2"
+ "bnns.expand_dims"
+ "bnns.fill"
+ "bnns.floor"
+ "bnns.floor_div"
+ "bnns.gather"
+ "bnns.gather_nd"
+ "bnns.gelu"
+ "bnns.hard_sigmoid"
+ "bnns.index_permute"
+ "bnns.inverse"
+ "bnns.l2_pool"
+ "bnns.layout_to_abstract"
+ "bnns.leaky_relu"
+ "bnns.linear_activation"
+ "bnns.log"
+ "bnns.log_softmax"
+ "bnns.logical"
+ "bnns.logical_not"
+ "bnns.lut"
+ "bnns.matmul"
+ "bnns.max"
+ "bnns.max_pool"
+ "bnns.min"
+ "bnns.mod"
+ "bnns.mul"
+ "bnns.pad"
+ "bnns.pow"
+ "bnns.range_1d"
+ "bnns.read_state"
+ "bnns.reduce_l1_norm"
+ "bnns.reduce_l2_norm"
+ "bnns.reduce_log_sum"
+ "bnns.reduce_log_sum_exp"
+ "bnns.reduce_logical_and"
+ "bnns.reduce_logical_or"
+ "bnns.reduce_max"
+ "bnns.reduce_mean"
+ "bnns.reduce_min"
+ "bnns.reduce_product"
+ "bnns.reduce_sum"
+ "bnns.reduce_sum_square"
+ "bnns.relu"
+ "bnns.relu6"
+ "bnns.reshape"
+ "bnns.round"
+ "bnns.rsqrt"
+ "bnns.scaled_tanh"
+ "bnns.scatter_nd"
+ "bnns.sdpa"
+ "bnns.select"
+ "bnns.shape"
+ "bnns.sigmoid"
+ "bnns.silu"
+ "bnns.sin"
+ "bnns.sinh"
+ "bnns.slice_extent"
+ "bnns.slice_range"
+ "bnns.slice_update"
+ "bnns.softmax"
+ "bnns.softplus"
+ "bnns.softsign"
+ "bnns.split"
+ "bnns.sqrt"
+ "bnns.square"
+ "bnns.squeeze"
+ "bnns.stack"
+ "bnns.state"
+ "bnns.sub"
+ "bnns.tan"
+ "bnns.tanh"
+ "bnns.tensor_with_layout"
+ "bnns.threshold"
+ "bnns.threshold_relu"
+ "bnns.tile"
+ "bnns.write_state"
+ "bnns_graph_builder_register_"
+ "body"
+ "bodyRegion"
+ "braces not balanced"
+ "brackets ([ ]) not balanced"
+ "branching to block of a different region"
+ "broadcast_in_dims op is decreasing number of elements. Input type "
+ "builtin"
+ "builtin.affine_map"
+ "builtin.array"
+ "builtin.bf16"
+ "builtin.call_site_loc"
+ "builtin.complex"
+ "builtin.dense_array"
+ "builtin.dense_int_or_fp_elements"
+ "builtin.dense_resource_elements"
+ "builtin.dense_string_elements"
+ "builtin.dictionary"
+ "builtin.distinct"
+ "builtin.f128"
+ "builtin.f16"
+ "builtin.f32"
+ "builtin.f4E2M1FN"
+ "builtin.f64"
+ "builtin.f6E2M3FN"
+ "builtin.f6E3M2FN"
+ "builtin.f80"
+ "builtin.f8E3M4"
+ "builtin.f8E4M3"
+ "builtin.f8E4M3B11FNUZ"
+ "builtin.f8E4M3FN"
+ "builtin.f8E4M3FNUZ"
+ "builtin.f8E5M2"
+ "builtin.f8E5M2FNUZ"
+ "builtin.f8E8M0FNU"
+ "builtin.file_line_range"
+ "builtin.float"
+ "builtin.function"
+ "builtin.fused_loc"
+ "builtin.index"
+ "builtin.integer"
+ "builtin.integer_set"
+ "builtin.memref"
+ "builtin.module"
+ "builtin.name_loc"
+ "builtin.none"
+ "builtin.opaque"
+ "builtin.opaque_loc"
+ "builtin.sparse_elements"
+ "builtin.strided_layout"
+ "builtin.string"
+ "builtin.symbol_ref"
+ "builtin.tensor"
+ "builtin.tf32"
+ "builtin.tuple"
+ "builtin.type"
+ "builtin.unit"
+ "builtin.unknown_loc"
+ "builtin.unranked_memref"
+ "builtin.unranked_tensor"
+ "builtin.unrealized_conversion_cast"
+ "builtin.vector"
+ "bytecode version "
+ "callee"
+ "callsite("
+ "can only contain attributes with dialect-prefixed names, found: '"
+ "can't run '"
+ "cannot apply encoding to unranked tensor"
+ "cannot broadcast vector with tensor"
+ "cannot have affine map for unranked memref type"
+ "cannot name an operation with no results"
+ "cannot reshape a tensor to have more than 8 dimensions"
+ "cannot squeeze dimension "
+ "cannot unsqueeze out-of-range dimension "
+ "canonicalize"
+ "carriage-return"
+ "caseValues"
+ "ceildiv"
+ "circular"
+ "circumflex"
+ "circumflex-accent"
+ "cl::location(x) specified more than once!"
+ "clip must be in {fp32, bf16, fp16}"
+ "cntrl"
+ "codeSnippet"
+ "colon"
+ "combo_dodge_v2"
+ "combo_hid_ssp_attention"
+ "combo_tts_nlp_kv_cache_draft_mha"
+ "combo_tts_soundstorm_CONV_FC_SWIGLU_MODULE"
+ "combo_tts_soundstorm_FFN_NORM_MF_X3"
+ "combo_tts_soundstorm_FFN_NORM_X3"
+ "combo_tts_soundstorm_FIXED_CONV_FC_SWIGLU_MODULE"
+ "combo_tts_soundstorm_ffn_mf_norm_x3"
+ "combo_tts_soundstorm_ffn_norm_x3"
+ "comma"
+ "commercial-at"
+ "compareAtLeast"
+ "complex"
+ "complex<"
+ "concat.interleave=true not supported"
+ "constant too large for index"
+ "constantType"
+ "constantTypes"
+ "constantValue"
+ "convert-coreml-to-bnns"
+ "convert-pdl-to-pdl-interp"
+ "copy"
+ "core"
+ "coreml"
+ "coreml.acos"
+ "coreml.acosh"
+ "coreml.add"
+ "coreml.all"
+ "coreml.and"
+ "coreml.any"
+ "coreml.approximate"
+ "coreml.argsort"
+ "coreml.array"
+ "coreml.asin"
+ "coreml.asinh"
+ "coreml.async.await"
+ "coreml.async.value"
+ "coreml.atan"
+ "coreml.atanh"
+ "coreml.avg_pool_2d"
+ "coreml.batch_matmul"
+ "coreml.batchnorm"
+ "coreml.broadcast_in_dims"
+ "coreml.broadcast_shapes"
+ "coreml.broadcast_to"
+ "coreml.cast"
+ "coreml.concat"
+ "coreml.condition"
+ "coreml.constant"
+ "coreml.conv2d"
+ "coreml.cos"
+ "coreml.cosh"
+ "coreml.create_complex"
+ "coreml.create_token"
+ "coreml.decomposable.l2_norm"
+ "coreml.delegate"
+ "coreml.divide"
+ "coreml.equal"
+ "coreml.erf"
+ "coreml.error"
+ "coreml.exp"
+ "coreml.expand_dims"
+ "coreml.extern"
+ "coreml.file_resource"
+ "coreml.fill"
+ "coreml.floor_divide"
+ "coreml.gather_nd"
+ "coreml.gelu"
+ "coreml.get_shape"
+ "coreml.graph"
+ "coreml.greater"
+ "coreml.handle"
+ "coreml.if"
+ "coreml.imaginary_part"
+ "coreml.import"
+ "coreml.intent"
+ "coreml.invoke"
+ "coreml.isolated_group"
+ "coreml.join_token"
+ "coreml.llo.call"
+ "coreml.llo.class"
+ "coreml.llo.func"
+ "coreml.llo.member"
+ "coreml.llo.placeholder"
+ "coreml.llo.return"
+ "coreml.log"
+ "coreml.max_pool_2d"
+ "coreml.maximum"
+ "coreml.minimum"
+ "coreml.module"
+ "coreml.modulo"
+ "coreml.mul"
+ "coreml.non_zero"
+ "coreml.non_zero output.shape[1] is "
+ "coreml.not"
+ "coreml.not_equal"
+ "coreml.odie_location_frame_attr"
+ "coreml.opaque"
+ "coreml.or"
+ "coreml.output"
+ "coreml.pad"
+ "coreml.padding_mode"
+ "coreml.param.bind"
+ "coreml.param.constant"
+ "coreml.param.decl"
+ "coreml.param.decl.array"
+ "coreml.param.ref"
+ "coreml.param_ref"
+ "coreml.pow"
+ "coreml.range"
+ "coreml.read_handle"
+ "coreml.real_part"
+ "coreml.reduce_max"
+ "coreml.reduce_mean"
+ "coreml.reduce_min"
+ "coreml.reduce_sum"
+ "coreml.relu"
+ "coreml.reshape"
+ "coreml.reverse"
+ "coreml.rsqrt"
+ "coreml.scatter_nd"
+ "coreml.select"
+ "coreml.shrink_dims"
+ "coreml.sigmoid"
+ "coreml.silu"
+ "coreml.sin"
+ "coreml.sinh"
+ "coreml.slice"
+ "coreml.slice_update"
+ "coreml.softmax"
+ "coreml.sort"
+ "coreml.split"
+ "coreml.sqrt"
+ "coreml.stack"
+ "coreml.sub"
+ "coreml.symbol"
+ "coreml.symbol_ref"
+ "coreml.tan"
+ "coreml.tanh"
+ "coreml.target_spec"
+ "coreml.tensor_encoding"
+ "coreml.tile"
+ "coreml.token"
+ "coreml.torch_location_extras"
+ "coreml.transform.cast"
+ "coreml.transpose"
+ "coreml.type"
+ "coreml.where"
+ "coreml.while"
+ "coreml.write_handle"
+ "coreml.xor"
+ "coreml.yield"
+ "coremlax"
+ "coremlax.cast"
+ "coremlax.constexpr_blockwise_shift_scale"
+ "coremlax.constexpr_lut_to_dense"
+ "coremlax.constexpr_sparse_to_dense"
+ "coremlax.copy_discarding_constraints"
+ "coremlax.copy_with_constraints"
+ "coremlax.dequantize"
+ "coremlax.hw_constraints"
+ "coremlax.quantize"
+ "coremlax.view"
+ "could not resolve the callee "
+ "could not resolve the callee to a `coreml.llo.func` or a `coreml.import`"
+ "count"
+ "created with unregistered dialect. If this is intended, please call allowUnregisteredDialects() on the MLIRContext, or use -allow-unregistered-dialect with the MLIR opt tool used"
+ "custom op '"
+ "custom parser failed to parse parameter 'alignments'"
+ "custom parser failed to parse parameter 'interleave'"
+ "data shape is required to be static"
+ "data type expected to be "
+ "dataLayout = "
+ "data_rank = "
+ "decomposition"
+ "default value type and member type must match"
+ "definition of SSA value '"
+ "delegateOptions = "
+ "delegate_id"
+ "dense"
+ "dense<"
+ "dense_resource"
+ "dense_resource<"
+ "dense_resource<__elided__>"
+ "diagnostic emitted with trace:\n"
+ "dialect"
+ "dialect "
+ "dialect '"
+ "digit"
+ "dilation"
+ "dilation must be > 0"
+ "dimension interleave factor "
+ "dimension shape "
+ "dimension shape and dimension interleave factor must both be static or both be dynamic"
+ "direction must be forward or reverse"
+ "disable-patterns"
+ "disable_threading"
+ "disabled"
+ "distinct"
+ "distinct["
+ "dodge_v2_scratch"
+ "dodge_v2_weights"
+ "does not allow a value! '"
+ "dollar-sign"
+ "duplicate key '"
+ "duplicate or unknown struct parameter name: "
+ "duplicate top-level section: "
+ "dynamic_prep_and_execute_copy received conflicting accelerator support. This results in dispatching of AMX copies."
+ "eight"
+ "either both weight and bias must be specified, or neither"
+ "element of pdl.range cannot be another range, but got"
+ "element type bitwidth must be a multiple of 8"
+ "elements hex data size is invalid for provided type: "
+ "elements literal must be a shaped type"
+ "elements literal type must have static shape"
+ "eliminate_axis"
+ "elseRegion"
+ "embed_0_bias_to_fp16"
+ "embed_0_weight_to_fp16"
+ "embed_2_bias"
+ "embed_2_running_mean"
+ "embed_2_running_var"
+ "embed_2_weight"
+ "embed_3_bias_to_fp16"
+ "embed_3_weight_to_fp16"
+ "embed_5_bias_to_fp16"
+ "embed_5_running_mean_to_fp16"
+ "embed_5_running_var_to_fp16"
+ "embed_5_weight_to_fp16"
+ "embed_6_bias_to_fp16"
+ "embed_6_weight_to_fp16"
+ "embed_8_bias_to_fp16"
+ "embed_8_running_mean_to_fp16"
+ "embed_8_running_var_to_fp16"
+ "embed_8_weight_to_fp16"
+ "empty (sub)expression"
+ "empty block: expect at least a terminator"
+ "empty operation name is invalid"
+ "enable-patterns"
+ "encoding dimension order should be permutation of the shape."
+ "encoding rank is different than tensor shape."
+ "entry block arguments were already defined"
+ "entry block must have "
+ "entry block of region may not have predecessors"
+ "equals-sign"
+ "error: "
+ "exclamation-mark"
+ "expect 4 operands"
+ "expect exactly two elements for "
+ "expect output of rank 2 for coreml.non_zero"
+ "expect shaped type for input"
+ "expect shaped type for scale"
+ "expect shaped type for zero_scale"
+ "expect two elements in dilation"
+ "expect two elements in padding"
+ "expect two elements in strides"
+ "expected "
+ "expected '"
+ "expected '\"' in string literal"
+ "expected '('"
+ "expected '(' at start of SSA symbol"
+ "expected '(' in callsite location"
+ "expected '(' in inline location"
+ "expected '(' in location"
+ "expected '(' to start operand list"
+ "expected ')'"
+ "expected ')' after child location of NameLoc"
+ "expected ')' after complex elements"
+ "expected ')' at end of SSA symbol"
+ "expected ')' in callsite location"
+ "expected ')' in inline location"
+ "expected ')' in location"
+ "expected ')' to end operand list"
+ "expected ')' to end region list"
+ "expected '*'"
+ "expected '+'"
+ "expected ','"
+ "expected ',' between complex elements"
+ "expected ',' or '"
+ "expected ',' or '>' in memref type"
+ "expected '-'"
+ "expected '->'"
+ "expected '->' in function type"
+ "expected '->' or ':'"
+ "expected '...'"
+ "expected ':'"
+ "expected ':' after 'offset'"
+ "expected ':' after block name"
+ "expected ':' after dense array type"
+ "expected ':' and type for SSA operand"
+ "expected ':' followed by operation type"
+ "expected ':' in operand list"
+ "expected '<'"
+ "expected '<' after 'array'"
+ "expected '<' after 'dense'"
+ "expected '<' after 'dense_resource'"
+ "expected '<' after 'strided'"
+ "expected '<' after distinct ID"
+ "expected '<' in affine map"
+ "expected '<' in complex type"
+ "expected '<' in integer set"
+ "expected '<' in memref type"
+ "expected '<' in tensor type"
+ "expected '<' in tuple type"
+ "expected '<' in vector type"
+ "expected '='"
+ "expected '=' after SSA name"
+ "expected '=' in attribute alias definition"
+ "expected '=' in type alias definition"
+ "expected '== affine-expr' or '>= affine-expr' at end of affine constraint"
+ "expected '>'"
+ "expected '>' after fused location metadata"
+ "expected '>' in affine map"
+ "expected '>' in complex type"
+ "expected '>' in integer set"
+ "expected '>' in tensor type"
+ "expected '>' in tuple type"
+ "expected '>' in vector type"
+ "expected '>' to close an array attribute"
+ "expected '>' to close distinct attribute"
+ "expected '>' to close properties"
+ "expected '?'"
+ "expected '['"
+ "expected '[' after 'distinct'"
+ "expected ']'"
+ "expected ']' to close distinct ID"
+ "expected 'at' in callsite location"
+ "expected 'offset' after comma"
+ "expected 'true' or 'false' value for key '"
+ "expected 'x' in dimension list"
+ "expected '{'"
+ "expected '{' to begin a region"
+ "expected '|'"
+ "expected '}'"
+ "expected 1-d tensor for sparse element values"
+ "expected AffineMap, but got IntegerSet"
+ "expected DictionaryAttr to set properties"
+ "expected IR section for region"
+ "expected IntegerSet, but got AffineMap"
+ "expected SSA identifier"
+ "expected SSA operand"
+ "expected YieldOp to terminate the decomposition block."
+ "expected `pdl.range<value>` result type when no index is specified, but got: "
+ "expected a 64-bit signed integer or '?'"
+ "expected a ShapedType for all inputs to concat"
+ "expected a bindable user when defined in the matcher body of a `pdl.pattern`"
+ "expected a blob resource entry, but found a "
+ "expected a bool resource entry, but found a "
+ "expected a callee expression of type `symbol`"
+ "expected a parameter attribute if the callee is not resolved"
+ "expected a parameter expression of type `symbol`"
+ "expected a parameter expression of type `type`"
+ "expected a parameter name in struct"
+ "expected a result of type "
+ "expected a single dimension along which to concat"
+ "expected a single operand of type `!coreml.async.value`"
+ "expected a size expression of any integer type, got "
+ "expected a string resource entry, but found a "
+ "expected a trailing type"
+ "expected affine expression"
+ "expected alignment byte (0xCB), but got: '0x"
+ "expected alignment to be a power-of-two"
+ "expected alignments to be statically defined"
+ "expected alignments to have (rank + 1) elements"
+ "expected all input shapes to match along all dimensions other than the concat dimension"
+ "expected all input tensors to have the same rank"
+ "expected an argument of type "
+ "expected an element type expression of type `type`, got "
+ "expected an integer or floating point type"
+ "expected an unsigned 64-bit integer"
+ "expected at least one argument"
+ "expected at least one argument or result"
+ "expected at least one result for cast operation"
+ "expected attribute"
+ "expected attribute name"
+ "expected attribute of type: "
+ "expected attribute value"
+ "expected bare identifier"
+ "expected block name"
+ "expected body to terminate with `pdl.rewrite`"
+ "expected constant integer or floating point value"
+ "expected constant value when specified within a `pdl.rewrite`"
+ "expected dialect version section"
+ "expected distinct ID"
+ "expected either integer or `:` post `to` in FileLineColRange"
+ "expected element literal of primitive type"
+ "expected exactly 1 operand"
+ "expected exactly 1 operands"
+ "expected exactly 2 operands"
+ "expected exactly 3 operands"
+ "expected floating point literal"
+ "expected floating-point, integer, or complex element type, got "
+ "expected function type"
+ "expected hex string blob for key '"
+ "expected i1 type for 'true' or 'false' values"
+ "expected identifier key for 'external_resources' entry"
+ "expected identifier key for 'resource' entry"
+ "expected identifier key in file metadata dictionary"
+ "expected input token '"
+ "expected integer column number in FileLineColRange"
+ "expected integer elements, but parsed floating-point"
+ "expected integer line number in FileLineColRange"
+ "expected integer literal"
+ "expected integer number of results"
+ "expected integer or float type, got: "
+ "expected integer or floating point literal"
+ "expected integer or index type for IntegerAttr, but got: "
+ "expected integer value"
+ "expected interleave to have (rank) elements"
+ "expected keyword for An enum corresponding to the backing type to be used for allocations."
+ "expected list element"
+ "expected location attribute, but got"
+ "expected location instance"
+ "expected location, but found '"
+ "expected memory space to be last in memref type"
+ "expected named operation to have at least 1 result"
+ "expected nested symbol reference identifier"
+ "expected no external arguments when the rewrite is specified inline"
+ "expected no operands"
+ "expected no replacement values to be provided when the replacement operation is present"
+ "expected non-empty function body"
+ "expected non-function type"
+ "expected number of argument attrs ("
+ "expected number of cases to match the number of case values, got "
+ "expected number of result attrs ("
+ "expected only `pdl` operations within the pattern body"
+ "expected only one of [`type`, `value`] to be set"
+ "expected operand"
+ "expected operand to be ranked tensor"
+ "expected operand to have element type "
+ "expected operation name in quotes"
+ "expected resource offset section when resource section is present"
+ "expected rewrite region to be empty when rewrite is external"
+ "expected rewrite region to be non-empty if external name is not specified"
+ "expected shape (["
+ "expected source "
+ "expected ssa identifier"
+ "expected static shape"
+ "expected string"
+ "expected string containing hex digits starting with `0x`"
+ "expected string value for key '"
+ "expected symbol keyword"
+ "expected the 'coreml.output' terminator"
+ "expected the decomposition block to contain ops."
+ "expected the number of strides to match the rank"
+ "expected the same element type for all inputs to concat"
+ "expected the same number of attribute values and attribute names, got "
+ "expected three consecutive dots for an ellipsis"
+ "expected type "
+ "expected type instead of SSA identifier"
+ "expected unsigned integer elements, but parsed negative value"
+ "expected valid '@'-identifier for symbol name"
+ "expected valid attribute name"
+ "expected valid keyword"
+ "expected valid keyword or string"
+ "expected valid ssa identifier"
+ "expected valid symbol name."
+ "expects a non-empty block"
+ "expects argument attribute array to have the same number of elements as the number of function arguments, got "
+ "expects argument attribute dictionary to be a DictionaryAttr, but got `"
+ "expects at most one data layout attribute"
+ "expects graph region #"
+ "expects one region"
+ "expects parent op "
+ "expects region #"
+ "expects regions to end with '"
+ "expects result attribute array to have the same number of elements as the number of function results, got "
+ "expects result attribute dictionary to be a DictionaryAttr, but got `"
+ "extern"
+ "externAttr"
+ "external"
+ "externalize"
+ "extra = "
+ "f"
+ "f128"
+ "f16"
+ "f32"
+ "f4E2M1FN"
+ "f64"
+ "f6E2M3FN"
+ "f6E3M2FN"
+ "f80"
+ "f8E3M4"
+ "f8E4M3"
+ "f8E4M3B11FNUZ"
+ "f8E4M3FN"
+ "f8E4M3FNUZ"
+ "f8E5M2"
+ "f8E5M2FNUZ"
+ "f8E8M0FNU"
+ "failed to broadcast batch dimensions"
+ "failed to construct function type"
+ "failed to convert CoreML::GraphOp region"
+ "failed to create output stream: "
+ "failed to infer returned types"
+ "failed to legalize operation '"
+ "failed to legalize unresolved materialization from ("
+ "failed to lower PDL pattern module to the PDL Interpreter"
+ "failed to map memory for ring buffer "
+ "failed to parse ApproximateAttr parameter 'value' which is to be a `mlir::ODIE::Compiler::CoreML::Approximate`"
+ "failed to parse BNNS_State_Type parameter 'wrappedType' which is to be a `Type`"
+ "failed to parse BNNS_TensorWithLayout_Type parameter 'elementType' which is to be a `Type`"
+ "failed to parse BNNS_TensorWithLayout_Type parameter 'interleave' which is to be a `::llvm::ArrayRef<int64_t>`"
+ "failed to parse BNNS_TensorWithLayout_Type parameter 'min_row_align' which is to be a `int64_t`"
+ "failed to parse BNNS_TensorWithLayout_Type parameter 'shape' which is to be a `::llvm::ArrayRef<int64_t>`"
+ "failed to parse BNNS_TensorWithLayout_Type parameter 'strides' which is to be a `::llvm::ArrayRef<int64_t>`"
+ "failed to parse CMLAX_HardwareConstraints parameter 'backing' which is to be a `AllocationTypeEnum`"
+ "failed to parse CMLAX_HardwareConstraints parameter 'baseEncoding' which is to be a `::mlir::ODIE::Compiler::CoreML::TensorEncodingAttr`"
+ "failed to parse COREML_AsyncValueType parameter 'innerType' which is to be a `::mlir::Type`"
+ "failed to parse COREML_ExternAttr parameter 'library' which is to be a `::llvm::StringRef`"
+ "failed to parse COREML_HandleType parameter 'innerType' which is to be a `::mlir::Type`"
+ "failed to parse COREML_IntentAttr parameter 'value' which is to be a `mlir::ODIE::Compiler::CoreML::Intent`"
+ "failed to parse COREML_ODIELocationFrameAttr parameter 'codeSnippet' which is to be a `StringAttr`"
+ "failed to parse COREML_ODIELocationFrameAttr parameter 'frontendAttribute' which is to be a `std::optional<Attribute>`"
+ "failed to parse COREML_ODIELocationFrameAttr parameter 'method' which is to be a `StringAttr`"
+ "failed to parse COREML_ParamRefType parameter 'param' which is to be a `TypedAttr`"
+ "failed to parse COREML_TargetSpecAttr parameter 'dataLayout' which is to be a `DictionaryAttr`"
+ "failed to parse COREML_TargetSpecAttr parameter 'delegateOptions' which is to be a `DictionaryAttr`"
+ "failed to parse COREML_TargetSpecAttr parameter 'extra' which is to be a `::llvm::StringRef`"
+ "failed to parse COREML_TargetSpecAttr parameter 'soc' which is to be a `::llvm::StringRef`"
+ "failed to parse COREML_TargetSpecAttr parameter 'triple' which is to be a `::llvm::StringRef`"
+ "failed to parse COREML_TorchLocationExtrasAttr parameter 'stackTrace' which is to be a `::llvm::ArrayRef<StringAttr>`"
+ "failed to parse CoreMLTensorEncodingAttr parameter 'dimsOrdering' which is to be a `::llvm::ArrayRef<int32_t>`"
+ "failed to parse FileResourceAttr parameter 'file_name' which is to be a `StringAttr`"
+ "failed to parse FileResourceAttr parameter 'offset' which is to be a `IntegerAttr`"
+ "failed to parse PaddingModeAttr parameter 'value' which is to be a `mlir::ODIE::Compiler::CoreML::PaddingMode`"
+ "failed to parse ParamDeclArrayAttr parameter 'value' which is to be a `::llvm::ArrayRef<ParamDeclAttr>`"
+ "failed to parse the attribute dictionary"
+ "failed to parse the body region"
+ "failed to parse the function signature"
+ "failed to read version int"
+ "failed to verify 'elementType': integer or index or floating-point"
+ "failed to verify constraint: region with 1 blocks"
+ "failed to verify constraint: region with at least 1 blocks"
+ "failed to verify constraint: region with at most 1 blocks"
+ "failed to verify that Operand 5 and operand 0 must have the same inner element type."
+ "failed to verify that Operands should have same element type."
+ "failed to verify that Operands should have same shape."
+ "failed to verify that Operation must have at least two operands."
+ "failed to verify that Result 0 and operand 0 must have the same inner element type."
+ "failed to verify that Result 0 and operand 0 must have the same rank."
+ "failed to verify that Result 0 and operand 0 must have the same shape."
+ "failed to verify that Result 0 and operand 1 must have the same shape."
+ "failed to verify that Result 0 and operand 4 must have the same rank."
+ "failed to verify that Result 0 element type must match element type of operand 0."
+ "failed to verify that Result 0 element type must match element type of operand 1."
+ "failed to verify that Result 0 element type must match element type of operand 2."
+ "failed to verify that Result 0 element type must match element type of operand 4."
+ "failed to verify that `range` is a PDL range whose element type matches type of `result`"
+ "failed to verify that `value` type matches arity of `result`"
+ "failed to verify that callee input types match argument types"
+ "failed to verify that callee result types match result types"
+ "failed to verify that input token must come from an operation on the same handle"
+ "failed to verify that number of dims >=2 and last dim of operand 0 equals second last dim of operand 1"
+ "failed to verify that number of handle inputs must match number of token outputs"
+ "fc_scratch"
+ "fc_scratch(for:"
+ "ffn_0_proj_bias"
+ "ffn_1_proj_bias"
+ "ffn_2_proj_bias"
+ "file_resource"
+ "filename"
+ "five"
+ "floating point value not valid for specified type"
+ "floating point value too large"
+ "floating point value too large for attribute"
+ "floordiv"
+ "for"
+ "for LSTM, initial_c must be provided"
+ "for LSTM, initial_c must have the same shape as initial_h"
+ "for LSTM, initial_c must have the same type as initial_h"
+ "for bidirectional LSTM, both weight_ih_back and weight_hh_back must be provided"
+ "for bidirectional LSTM, if either forward or reverse bias is provided, both must be provided"
+ "for bidirectional LSTM, when reverse bias is provided, its shape must match that of the forward bias"
+ "for bidirectional LSTM, when reverse bias is provided, its type must match that of the forward bias"
+ "for parametric op here"
+ "form-feed"
+ "found trailing characters: '"
+ "four"
+ "from"
+ "from "
+ "frontendAttribute"
+ "full-stop"
+ "func"
+ "func.call"
+ "func.call_indirect"
+ "func.constant"
+ "func.func"
+ "func.return"
+ "function result types: "
+ "function signature("
+ "function_type"
+ "fused"
+ "gather_indices"
+ "gather_lut"
+ "gemm_intermediate for sdpa "
+ "generatedOps"
+ "getParseAssemblyFn hook called on unregistered op"
+ "got binding of type "
+ "graph"
+ "graphs do not allow the default symbol visibility attr"
+ "graphs marked 'externalize' must not be private"
+ "grave-accent"
+ "greater-than-sign"
+ "group"
+ "gru: encountered invalid pointer."
+ "h16c"
+ "h16s"
+ "handle"
+ "has "
+ "has inferred results, but the created operation '"
+ "has no custom assembly form"
+ "has properties but missing BytecodeOpInterface for "
+ "hexadecimal float constant out of range for type"
+ "hexadecimal float literal should not have a leading minus"
+ "hw_constraints"
+ "hyphen"
+ "hyphen-minus"
+ "if a result is non-scalar, then at least one operand must be non-scalar"
+ "if an operand is non-scalar, then all results must be non-scalar"
+ "if an operand is non-scalar, then there must be at least one non-scalar result"
+ "if provided, the last dimension of the bias, the hidden size, must match the last dimension of initial_h"
+ "ignore_axis"
+ "ignore_end"
+ "ignore_extent"
+ "ignoring unknown external resources for '"
+ "in"
+ "in bytecode version "
+ "in custom textual format, the absence of terminator implies '"
+ "inconsistency in registered CommandLine options"
+ "incorrect number of operands for callee"
+ "incorrect number of results for callee"
+ "indices shape is required to be static"
+ "inf"
+ "inferred"
+ "inferred return types did not match actual return types"
+ "inferred shape of elements literal (["
+ "inferredResultTypes"
+ "info-output-file"
+ "innermost dimension of indices "
+ "input and output batch sizes do not match"
+ "input and output ranks must match"
+ "input buffer is not an MLIR bytecode file"
+ "input must have at least two dimensions"
+ "input must have rank 3"
+ "input rank is "
+ "input rank must be >= 1"
+ "input tensors must match in rank"
+ "input type must be bf16, fp16, or fp32"
+ "input/output rank must be >= 1"
+ "input0 and input1 must have the same data type"
+ "inputAttributeNames"
+ "inputNames"
+ "inputs"
+ "integer bitwidth is limited to "
+ "integer constant out of range"
+ "integer constant out of range for attribute"
+ "integer constant out of range for type"
+ "integer literal not valid for specified type"
+ "integer value too large"
+ "intent"
+ "intents cannot be supplied on IsolatedGroupOp; intents are derived from the contained ops"
+ "interleave is only supported for a single dimension"
+ "internal.combo_tts_nlp_kv_cache_draft_mha"
+ "internal.combo_tts_soundstorm_CONV_FC_SWIGLU_MODULE"
+ "internal.combo_tts_soundstorm_FIXED_CONV_FC_SWIGLU_MODULE"
+ "internal.combo_tts_soundstorm_ffn_mf_norm_x3"
+ "internal.combo_tts_soundstorm_ffn_norm_x3"
+ "internal.dodge_v2"
+ "internal.gather_lut"
+ "internal.sub"
+ "invalid "
+ "invalid 'pdl' type: `"
+ "invalid An enum corresponding to the backing type to be used for allocations. specification: "
+ "invalid SSA name"
+ "invalid SSA value result number"
+ "invalid `dense_resource` handle type"
+ "invalid argument to regex routine"
+ "invalid attribute name"
+ "invalid backreference number"
+ "invalid block name"
+ "invalid block name in region with named arguments"
+ "invalid character class"
+ "invalid character range"
+ "invalid collating element"
+ "invalid dialect namespace '"
+ "invalid dimension"
+ "invalid element type for complex"
+ "invalid integer width"
+ "invalid kind of Type specified"
+ "invalid kind of attribute specified"
+ "invalid kind of type specified"
+ "invalid memref element type"
+ "invalid memref size"
+ "invalid properties "
+ "invalid regular expression"
+ "invalid repetition count(s)"
+ "invalid section ID: "
+ "invalid tensor element type"
+ "invalid tensor ref"
+ "invalid type identifier"
+ "is"
+ "isNegated"
+ "k must be at least 1"
+ "kind"
+ "l2_spatial_norm"
+ "left-brace"
+ "left-curly-bracket"
+ "left-parenthesis"
+ "left-square-bracket"
+ "less-than-sign"
+ "llvm-symbolizer"
+ "llvm_regexec() failed to match"
+ "loc"
+ "loc("
+ "logits"
+ "long"
+ "low-line"
+ "lstm: encountered invalid pointer."
+ "lut shape is required to be static"
+ "lut_indices"
+ "malformed null-terminated string, no null character found"
+ "map"
+ "mask shape is required to be static"
+ "matcher"
+ "matmul("
+ "matmul: model compiled for hardware not available on this device"
+ "matvec op requires input types to be FP16, BF16, or FP32"
+ "matvec op requires output type to be FP16, BF16, or FP32"
+ "max-iterations"
+ "max-num-rewrites"
+ "memref"
+ "memref layout mismatch between rank and affine map: "
+ "memref<"
+ "memref<*x"
+ "message"
+ "method"
+ "min_row_align"
+ "mismatch in result shape and permutation. resultShape["
+ "mismatch in slice shape. Expected shape: "
+ "mismatched matrix dimensions"
+ "missing ']' closing scalable dimension"
+ "missing data for top-level section: "
+ "missing left operand of binary operator"
+ "missing operand of negation"
+ "missing right operand of binary operator"
+ "mlir-disable-threading"
+ "mlir-elide-elementsattrs-if-larger"
+ "mlir-elide-resource-strings-if-larger"
+ "mlir-pretty-debuginfo"
+ "mlir-print-assume-verified"
+ "mlir-print-debuginfo"
+ "mlir-print-elementsattrs-with-hex-if-larger"
+ "mlir-print-local-scope"
+ "mlir-print-op-generic"
+ "mlir-print-op-on-diagnostic"
+ "mlir-print-skip-regions"
+ "mlir-print-stacktrace-on-diagnostic"
+ "mlir-print-unique-ssa-ids"
+ "mlir-print-value-users"
+ "mlir-use-nameloc-as-prefix"
+ "mlir::ODIE::Compiler::CoreML::Approximate"
+ "mlir::ODIE::Compiler::CoreML::Intent"
+ "mlir::ODIE::Compiler::CoreML::PaddingMode"
+ "mlir_reproducer"
+ "multi-valued option specified with ValueDisallowed modifier!"
+ "multiple memory spaces specified in memref type"
+ "must be the last operation in the parent block"
+ "must concatenate at least one tensor"
+ "must have an operation name when nested within a `pdl.rewrite`"
+ "must have inferable or constrained result types when nested within `pdl.rewrite`"
+ "n_params must be either 1 or x.size[1]"
+ "n_spatial_dims exceeds rank of input"
+ "name"
+ "nan"
+ "negative integer literal not valid for unsigned integer type"
+ "nested"
+ "newline"
+ "nine"
+ "no bindings provided"
+ "no coremlax.copy_with_constraints users"
+ "no expression inside parentheses"
+ "no value attribute provided"
+ "no_inline"
+ "noinline"
+ "non-affine expression: at least one of the multiply operands has to be either a constant or symbolic"
+ "non-affine expression: right operand of ceildiv has to be either a constant or symbolic"
+ "non-affine expression: right operand of floordiv has to be either a constant or symbolic"
+ "non-affine expression: right operand of mod has to be either a constant or symbolic"
+ "non-private graphs must have a body"
+ "none"
+ "nonzero_data shape is required to be static"
+ "normal"
+ "normalization op only supports {BF16, FP16, FP32} parameters"
+ "normalize_mean_to_fp16"
+ "not all forward unresolved forward operand references"
+ "not enough parameters provided by "
+ "not enough values!"
+ "note: "
+ "null character not allowed in operation name"
+ "null operand found"
+ "number of dims must match, got "
+ "number of elements in dims must be equal to input rank"
+ "number of handle inputs must match number of token outputs"
+ "number of operands and types do not match: got "
+ "number-sign"
+ "odie_location_frame_attr"
+ "of"
+ "only contiguous layout is supported"
+ "only num_layers = 1 is supported"
+ "only one -1 is allowed in new_shape"
+ "only rank 1 bias is supported"
+ "only rank 2 initial_h, weight_ih, weight_hh are supported"
+ "oor_fatal"
+ "opName"
+ "opaque"
+ "operand"
+ "operand #"
+ "operand defined as a block argument (block #"
+ "operand defined here"
+ "operand group starting at #"
+ "operand must be a range of loop variable type"
+ "operand type mismatch: expected operand type "
+ "operandSegmentSizes"
+ "operand_segment_sizes"
+ "operands don't have broadcast-compatible shapes"
+ "operation"
+ "operation being parsed with an unregistered dialect. If this is intended, please use -allow-unregistered-dialect with the MLIR tool used"
+ "operation defines "
+ "operation is created in a non-inferrable context, but '"
+ "operation location alias was never defined"
+ "operation name"
+ "operation with block successors must terminate its parent block"
+ "operation's operand is unlinked"
+ "opname"
+ "order of token outputs does not match order of handle inputs"
+ "out"
+ "out of memory"
+ "out_token"
+ "output must have the same rank as the input indices"
+ "output rank is "
+ "output shape is invalid for parameters"
+ "output shape["
+ "output type expected to be "
+ "outputNames"
+ "output_layer_weight_to_fp16"
+ "outputs"
+ "pad type same_lower is not allowed for conv_transpose"
+ "padding must be <= kernel_size / 2"
+ "padding must be >= 0"
+ "param.bind"
+ "param.constant"
+ "param.decl"
+ "param.decl.array"
+ "param.ref"
+ "param_decls"
+ "param_ref"
+ "parent operands"
+ "parent results"
+ "parentheses not balanced"
+ "parsed use-list orders were invalid and could not be applied"
+ "parsed zero elements, but type ("
+ "pass-execution"
+ "passed null tensor"
+ "pattern '"
+ "pdl"
+ "pdl.apply_native_constraint"
+ "pdl.apply_native_rewrite"
+ "pdl.attribute"
+ "pdl.erase"
+ "pdl.operand"
+ "pdl.operands"
+ "pdl.operation"
+ "pdl.pattern"
+ "pdl.range"
+ "pdl.replace"
+ "pdl.result"
+ "pdl.results"
+ "pdl.rewrite"
+ "pdl.type"
+ "pdl.types"
+ "pdl.value"
+ "pdl_generated_rewriter"
+ "pdl_interp"
+ "pdl_interp.apply_constraint"
+ "pdl_interp.apply_rewrite"
+ "pdl_interp.are_equal"
+ "pdl_interp.branch"
+ "pdl_interp.check_attribute"
+ "pdl_interp.check_operand_count"
+ "pdl_interp.check_operation_name"
+ "pdl_interp.check_result_count"
+ "pdl_interp.check_type"
+ "pdl_interp.check_types"
+ "pdl_interp.continue"
+ "pdl_interp.create_attribute"
+ "pdl_interp.create_operation"
+ "pdl_interp.create_range"
+ "pdl_interp.create_type"
+ "pdl_interp.create_types"
+ "pdl_interp.erase"
+ "pdl_interp.extract"
+ "pdl_interp.finalize"
+ "pdl_interp.foreach"
+ "pdl_interp.func"
+ "pdl_interp.get_attribute"
+ "pdl_interp.get_attribute_type"
+ "pdl_interp.get_defining_op"
+ "pdl_interp.get_operand"
+ "pdl_interp.get_operands"
+ "pdl_interp.get_result"
+ "pdl_interp.get_results"
+ "pdl_interp.get_users"
+ "pdl_interp.get_value_type"
+ "pdl_interp.is_not_null"
+ "pdl_interp.record_match"
+ "pdl_interp.replace"
+ "pdl_interp.switch_attribute"
+ "pdl_interp.switch_operand_count"
+ "pdl_interp.switch_operation_name"
+ "pdl_interp.switch_result_count"
+ "pdl_interp.switch_type"
+ "pdl_interp.switch_types"
+ "percent-sign"
+ "period"
+ "perm["
+ "permutation must only hold values between 0 and "
+ "pipeline"
+ "plus-sign"
+ "poison"
+ "prelu_constant_alpha"
+ "previously defined here"
+ "previously referenced here"
+ "previously used here with type "
+ "print"
+ "prior use here"
+ "priv"
+ "private"
+ "probs"
+ "provided resource handle differs from the expected resource type"
+ "public"
+ "punct"
+ "question-mark"
+ "quotation-mark"
+ "r"
+ "range"
+ "rank of data, scale, and offset should match. "
+ "rank of scale must not exceed rank of x"
+ "rank should be the same as the rank of x"
+ "reading a sparse array found index "
+ "reading sparse array with indexing above 8 bits: "
+ "redefinition of SSA value '"
+ "redefinition of attribute alias id '"
+ "redefinition of block '"
+ "redefinition of identifier '"
+ "redefinition of symbol named '"
+ "redefinition of type alias id '"
+ "reduce_logical_and"
+ "reduce_logical_or"
+ "reference to an undefined block"
+ "reference to block defined in another region"
+ "reference to function with mismatched type"
+ "reference to invalid result number"
+ "reference to undefined function '"
+ "referenced attribute does not match previous definition: "
+ "referring to parametric op here"
+ "referring to parametric op here with specialized signature "
+ "region #"
+ "region entry argument '"
+ "region should have no arguments"
+ "region-simplify"
+ "remark: "
+ "repetition-operator operand invalid"
+ "replace-with-delegate-ops"
+ "reproducer generated at `"
+ "required by region isolation constraints"
+ "requires "
+ "requires 0 successors but found "
+ "requires 1 successor but found "
+ "requires a 'callee' symbol reference attribute"
+ "requires a single operand"
+ "requires a value!"
+ "requires all operands to have the same type"
+ "requires at least "
+ "requires attribute 'alpha'"
+ "requires attribute 'approx'"
+ "requires attribute 'attributeValueNames'"
+ "requires attribute 'axes'"
+ "requires attribute 'axis'"
+ "requires attribute 'benefit'"
+ "requires attribute 'beta'"
+ "requires attribute 'callee'"
+ "requires attribute 'caseValues'"
+ "requires attribute 'constantValue'"
+ "requires attribute 'count'"
+ "requires attribute 'delegate_id'"
+ "requires attribute 'epsilon'"
+ "requires attribute 'function_type'"
+ "requires attribute 'index'"
+ "requires attribute 'inputAttributeNames'"
+ "requires attribute 'kernel_sizes'"
+ "requires attribute 'kind'"
+ "requires attribute 'message'"
+ "requires attribute 'mode'"
+ "requires attribute 'name'"
+ "requires attribute 'opname'"
+ "requires attribute 'pad'"
+ "requires attribute 'padding_mode'"
+ "requires attribute 'param_decls'"
+ "requires attribute 'perm'"
+ "requires attribute 'resource'"
+ "requires attribute 'rewriter'"
+ "requires attribute 'strides'"
+ "requires attribute 'sym_name'"
+ "requires attribute 'target_spec'"
+ "requires attribute 'toImport'"
+ "requires attribute 'type'"
+ "requires attribute 'types'"
+ "requires attribute 'value'"
+ "requires dense i32 array attribute '"
+ "requires exactly one argument"
+ "requires one region"
+ "requires one result"
+ "requires string attribute '"
+ "requires the same element type for all operands"
+ "requires the same element type for all operands and results"
+ "requires the same encoding for all operands and results"
+ "requires the same shape for all operands and results"
+ "requires the same type for all operands and results"
+ "requires visibility attribute '"
+ "requires zero operands"
+ "requires zero regions"
+ "requires zero results"
+ "res_attrs"
+ "resource"
+ "resource handle"
+ "result"
+ "result number not allowed in argument list"
+ "result type "
+ "result type #"
+ "result type mismatch at index "
+ "resultSegmentSizes"
+ "results may only have dialect attributes"
+ "return"
+ "returning an operation from a constraint is not supported"
+ "reverse-solidus"
+ "rewriter"
+ "rewriters"
+ "right-brace"
+ "right-curly-bracket"
+ "right-parenthesis"
+ "right-square-bracket"
+ "rms_spatial_norm"
+ "rnn: encountered invalid pointer."
+ "root"
+ "rootKind"
+ "s"
+ "safeTransforms"
+ "scale can only be a scalar or rank-1 tensor"
+ "scale shape is required to be static"
+ "scale size across each dimension should be a factor of corresponding size of dimension in data argument"
+ "scratch for attention "
+ "scratch for elementwise activation matmul "
+ "scratch for matmul softmax matmul "
+ "scratch for sdpa "
+ "see a disconnected value / operation here"
+ "see current operation: "
+ "see existing live user here: "
+ "see existing symbol definition here"
+ "see non-`pdl` operation defined here"
+ "see terminator defined here"
+ "segmenter"
+ "semicolon"
+ "set"
+ "seven"
+ "shape of scale, and offset are not matching"
+ "shape op encountered no output tensors"
+ "shape tensor should be rank-1 and have static shape"
+ "six"
+ "size mismatch for operand/result_segment_size"
+ "size mismatch in attribute conversion: "
+ "slash"
+ "slice"
+ "soc = "
+ "softmax axis cannot exceed rank of input tensor"
+ "solidus"
+ "sort-timers"
+ "source dtype and result dtype are different"
+ "source or result have dynamic shape"
+ "source strides ["
+ "source strides don't match dest strides"
+ "space"
+ "sparse"
+ "sparse index #"
+ "sparse<"
+ "stack trace must not be empty"
+ "stride["
+ "strided"
+ "strided<["
+ "string size exceeds the available data size"
+ "successor"
+ "successors in non-terminator"
+ "sym_name"
+ "sym_visibility"
+ "symbol"
+ "symbol declaration cannot have public visibility"
+ "symbol's parent must have the SymbolTable trait"
+ "symbol("
+ "symbol_ref"
+ "tab"
+ "target_spec"
+ "tensor"
+ "tensor literal is invalid; ranks are not consistent between elements"
+ "tensor<"
+ "tensor<*x"
+ "tensor_encoding"
+ "tensor_with_layout"
+ "test-convergence"
+ "tf32"
+ "the batch size, dimension 1 of x and the second to last dimension of initial_h must match"
+ "the hidden size, the last dimension of initial_h and weight_hh, must match the second to last dimension of weight_ih and weight_hh"
+ "the input size, dimension 2 of x and the last dimension of weight_ih must match"
+ "the last dimension of indices must be of static size"
+ "the operations must form a connected component"
+ "the pattern must contain at least one `pdl.operation`"
+ "thenRegion"
+ "this operation does not support properties"
+ "thread constructor failed"
+ "three"
+ "tilde"
+ "tmp_"
+ "to"
+ "toImport"
+ "token"
+ "too many arguments specified in argument list"
+ "too many signal callbacks already registered"
+ "top-down"
+ "topk_indices"
+ "topk_values"
+ "torch_location_extras"
+ "track-memory"
+ "trailing backslash (\\)"
+ "trailing characters found after "
+ "transpose_a"
+ "transpose_b"
+ "triple = "
+ "trying to read an array of "
+ "trying to schedule a pass on an operation not marked as 'IsolatedFromAbove'"
+ "trying to schedule a pass on an unregistered operation"
+ "trying to schedule a pass on an unsupported operation"
+ "tts soundstorm ffn_norm_x3 scratch(for:"
+ "tuple"
+ "tuple<"
+ "two"
+ "type"
+ "type names with a '.' are reserved for dialect-defined names"
+ "type of entry block argument #"
+ "type of return operand "
+ "types"
+ "ub"
+ "ub.poison"
+ "uint"
+ "unable to convert type for "
+ "unable to infer result type for operation"
+ "unable to schedule pass '"
+ "unbalanced '"
+ "undefined symbol alias id '"
+ "underscore"
+ "unexpected 'resource' section for dialect '"
+ "unexpected character"
+ "unexpected decimal integer literal for a floating point value"
+ "unexpected delimiter"
+ "unexpected keyword: "
+ "unexpected nul or EOF in pretty dialect name"
+ "unexpected properties emitted incompatible with bytecode <5"
+ "unexpected resource offset section when resource section is not present"
+ "unexpected resources for dialect '"
+ "unexpected ssa identifier"
+ "unexpected trailing bytes after "
+ "unexpected trailing bytes in resource entry '"
+ "unexpected trailing data between the offsets for strings and their data"
+ "unexpected trailing data in the Attribute/Type offset section"
+ "unit"
+ "unknown  type `"
+ "unknown 'resource' key '"
+ "unknown attribute `"
+ "unknown attribute code: "
+ "unknown escape in string literal"
+ "unknown key '"
+ "unknown<"
+ "unrecognized activation"
+ "unregistered operation '"
+ "unsqueeze"
+ "unsupported constant tensor data type for shape"
+ "unsupported input type"
+ "unsupported memory space Attribute"
+ "unsupported scatter mode"
+ "unsupported version requested "
+ "unused"
+ "updates rank is "
+ "updates shape["
+ "use of undeclared SSA value name"
+ "use of undeclared identifier"
+ "use of value '"
+ "user"
+ "users"
+ "using value defined outside the region"
+ "value index range was outside of the expected range for the parent region, got ["
+ "variadic arguments must be in the end of the argument list"
+ "vector elements must be int/index/float type but got "
+ "vector types must have positive constant sizes but got "
+ "vector<"
+ "vector_axis must be within range (-indices_rank - 1, indices_rank) (exclusive). Provided axis: "
+ "verify_each"
+ "vertical-line"
+ "vertical-tab"
+ "visibility expected to be one of [\"public\", \"private\", \"nested\"], but got "
+ "warning: "
+ "weight_hh_back must match shape of weight_hh"
+ "weight_ih_back must match shape of weight_ih"
+ "weights shape is inconsistent with input shape with respect to input channel count and group count"
+ "weights shape is inconsistent with output shape with respect to output channel count"
+ "with"
+ "with inferred results cannot also have explicit result types"
+ "x must be rank 3"
+ "x, initial_h, weight_ih, and weight_hh must be provided"
+ "xdigit"
+ "zero"
+ "zero-point can only be a scalar or rank-1 tensor"
+ "zero_bias"
+ "zero_point and scale should be of same length"
+ "{-#"
+ "{...}"
+ "{}"
+ "|"
- " -A %u"
- " -B %zu"
- " -B %zu -IS %zu -OS %zu"
- " -BD "
- " -Bdelta"
- " -CDS 2"
- " -DS %zu %zu"
- " -Idelta"
- " -LPA %u"
- " -P %zu %zu"
- " -PA %zu %zu %zu %zu"
- " -S %zu %zu"
- " -SD "
- " -WO %zu"
- " -Wdelta"
- " -axis "
- " -axis 255 "
- " -bi"
- " -bias"
- " -bias "
- " -bias -BD %s"
- " -clientptr=off"
- " -clientptr=on"
- " -dequantize "
- " -groups %zu "
- " -inplace"
- " -low-mem"
- " -no-cell"
- " -no-hidden"
- " -nt %zu"
- " -peephole"
- " -pw %u"
- " -quantize "
- " -scale"
- " -sum_input_delta"
- " -train-ptr"
- " -training"
- " -trans"
- " -wl IOHW"
- " -wl IOHrWr"
- " -wl OIHrWr"
- " = MGLM_append_slice("
- " = slice_expression(x="
- " GEMM: %s %c%c %zu x %zu x %zu "
- " as both an input and output. Inputs and outputs must be distict,"
- " not in [0,"
- " please an explicit identity op."
- " } "
- " } { "
- " }, .data_type = %d } "
- " }, .stride = {"
- "%s -IO %zu"
- "%s -OO %zu"
- "%s%s%s%s"
- "%sIS %zu "
- "%sRS %zu "
- "%zu "
- "%{name=layer}s %{name=direction}s BS:%{name=batch_size}zu %{name=summary}s"
- "(unsupported fn %d) "
- "+="
- ", .input = "
- ", .output = "
- ", begin = ["
- ", op="
- ", updates = "
- "-A %d "
- "-A %u "
- "-AC "
- "-B %zu %s"
- "-B %zu %s%s"
- "-B %zu -IABS %zu -IBBS %zu -OS %zu "
- "-Bdelta "
- "-C %zu -I %zu %zu %s%s-O %zu %zu %s%s-K %zu %zu -P %zu %zu -S %zu %zu %s%s -D %s %s "
- "-I"
- "-I %zu %zu %zu %s%s-O %zu %zu %zu %s%s-K %zu %zu -P %zu %zu -S %zu %zu %s-ID %s -OD %s -WD %s%s "
- "-I %zu %zu %zu %s%s-O %zu %zu %zu %s%s-K %zu %zu%s%s%s%s%s%s -ID %s -OD %s -WD %s%s "
- "-I %zu -O %zu %s-ID %s -OD %s -WD %s%s%s%s"
- "-I %zu -O %zu -B %zu -seq %zu -stack %zu%s%s%s%s%s%s%s"
- "-I %zu -O %zu -B %zu -seq %zu -stack %zu%s%s%s%s%s%s%s -grad"
- "-I %zu -O %zu -K %u %u -LPA %u -A %u -ID %s -OD %s -WD %s%s "
- "-I1"
- "-I1_type %d "
- "-I2"
- "-I2_type %d "
- "-IAdelta "
- "-IBdelta "
- "-M %d "
- "-O"
- "-O_type %d "
- "-R %d "
- "-T"
- "-W"
- "-Wdelta "
- "-add_zero_attn"
- "-avgE "
- "-avgI "
- "-beta %f "
- "-eps %e "
- "-epsilon %f "
- "-gamma %f "
- "-in_place1 "
- "-in_place2 "
- "-max "
- "-momentum %f "
- "-num_groups %zu "
- "-op %d "
- "-op %s Indexing: %s Contracting:%s%s A:%s B:%s C:%s"
- "-unmax "
- "1"
- "2"
- "3"
- "4"
- "5"
- "6"
- "7"
- "8"
- "9"
- "<No summary info id %u>"
- "A"
- "AB"
- "ACCELERATE_416DE66E47C9"
- "ACCELERATE_7B09D8C42EF4"
- "ACCELERATE_83A752B02172"
- "ACCELERATE_965A44538097E"
- "ACCELERATE_B4EB444453EC"
- "ACCELERATE_DB267B4233C11"
- "ACCELERATE_DF5AD80B280E"
- "AffineGridSample"
- "B"
- "BA"
- "BNNS %s CONVOLUTION PARAMETERS: -one_line %s%s%s"
- "BNNS 3bit matvec get indices size failed"
- "BNNS 3bit matvec get packed lut size failed"
- "BNNS 3bit matvec index packing failed"
- "BNNS 3bit matvec index packing scratch allocation failed"
- "BNNS 3bit matvec pack indices failed"
- "BNNS 3bit matvec pack lut failed"
- "BNNS 3bit matvec unsupported data types"
- "BNNS => NORM %s"
- "BNNS ACTIVATION PARAMETERS: -I %zu %zu %zu %s%s-O %zu %zu %zu %s%s-ID %s -OD %s%s%s%s%s%s"
- "BNNS AFFINE GRID SAMPLE %s %s %s %s"
- "BNNS ARITHMETIC (%s) BWD %s%s%s"
- "BNNS ARITHMETIC (%s) FWD %s%s%s"
- "BNNS Activation Apply Backward: unable to allocate memory to compute activation, using slower compute path"
- "BNNS Arithmetic Filter Warning: Batch size is 0, nothing to do"
- "BNNS Arithmetic Filter: Error wrong filter, this function should only be used for a filter created with BNNSFilterCreateLayerArithmetic"
- "BNNS Arithmetic Filter: input type is BNNSConstant, no gradient to compute"
- "BNNS Batchnorm Apply Backward: activation allocation failed"
- "BNNS Batchnorm Apply Backward: failed to apply activation backward"
- "BNNS BroadcastMatMul FWD %s -A %s -B %s -C %s%s"
- "BNNS CONTRACTION %s%s%s"
- "BNNS CONVOLUTION A1: problem doesn't fit in memory limit\n"
- "BNNS CONVOLUTION ACCELERATE1: weights aren't contiguous, using pack weights general\n"
- "BNNS CONVOLUTION CUSTOMIZED: -one_line %s%s%s"
- "BNNS CONVOLUTION PARAMETERS: -one_line %s%s%s"
- "BNNS CONVOLUTION VERS2: -one_line %s%s%s"
- "BNNS CONVOLUTIONS CUSTOMIZED: layer param is NULL\n"
- "BNNS CONVOLUTIONS VERSION2: 2D conv doesn't fit in memory limit"
- "BNNS CONVOLUTIONS VERSION2: BFloat16 weights are only allowed for OIHW layout"
- "BNNS CONVOLUTIONS VERSION2: cannot compute nonzero output channels for zero input channels"
- "BNNS CONVOLUTIONS VERSION2: empty input spatial dimensions without padding is not allowed"
- "BNNS CONVOLUTIONS VERSION2: empty kernel or output spatial dimensions not allowed"
- "BNNS CONVOLUTIONS VERSION2: int/out/weight/bias descriptor element stride (stride[0]) must be 1"
- "BNNS CONVOLUTIONS VERSION2: layer param is NULL\n"
- "BNNS CONVOLUTIONS VERSION2: output bias or scale is not supported\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported activation\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported bias data type\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported input data type\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported output data type\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported weight data type\n"
- "BNNS COPYSUM %s%s%s"
- "BNNS Convolution Create: convolution doesn't support indexed weights"
- "BNNS Convolution Create: input data type is not supported"
- "BNNS Convolution Create: int16/uint16 output is not supported"
- "BNNS Convolution Create: int8/uint8 output supported only with int8/uint8 inputs and weights"
- "BNNS Convolution Create: not allowed to delay allocation to apply if weights ptr isn't maintained by Client\n"
- "BNNS Convolution Create: output data type is not supported"
- "BNNS Convolution Create: uint32 output is not supported"
- "BNNS Convolution Create: weight data type is not supported"
- "BNNS Convolution: Repacking to CONV_WEIGHT_REPACK_MLA_GENERAL_* on this hardware is not yet supported\n"
- "BNNS Convolution: Winograd weights memory doesn't fit in memory\n"
- "BNNS Convolution: unable to create Winograd that fit in memory\n"
- "BNNS Convolutions A1   FP Engine: kernel with greater than 16 isn't supported (-K %zu %zu)"
- "BNNS Convolutions A1  FP Engine: kernel with greater than 16 isn't supported (-K %zu %zu), kernel width after dilation: %zu"
- "BNNS Convolutions A1: 2D conv doesn't fit in memory limit"
- "BNNS Convolutions A1: asymmetric strides aren't supported (-S %zu %zu)"
- "BNNS Convolutions A1: dilation is only supported for 1x1 stride (-DS %zu %zu) (-S %zu %zu)"
- "BNNS Convolutions A1: input is 0, no computation (-I %zu %zu %zu)"
- "BNNS Convolutions A1: strides larger than 2, aren't supported (-S %zu %zu)"
- "BNNS Copy DEST %s SRC %s %s"
- "BNNS DEPTHWISE CONVOLUTION %s"
- "BNNS DROPOUT %s%s%s"
- "BNNS EMBEDDING %s"
- "BNNS Embedding Apply: Input value %lld is out of range [0, %zu)\n"
- "BNNS FIRST FILTER => QUANT %s"
- "BNNS FIRST FILTER:"
- "BNNS FULLY CONNECTED PARAMETERS: %s%s%s"
- "BNNS FUSED %s%s"
- "BNNS FUSED PADDING/CONVOLUTION %s"
- "BNNS Fully Connected Backward: no bias, bias delta ignored"
- "BNNS Fully Connected Choose: inputs, weights, outputs and bias must be contigeous in memory (stride[0] <= 1)"
- "BNNS Fully Connected Sparse COO: probably wrong stride size %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch multi %zu * %zu * %zu, num nonzero %zu, number of mla vecfp %zu, number of mla matfp+lut %zu, number of mla matfp %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single %zu * %zu * %zu, num nonzero %zu, number of mla vecfp %zu, number of nop vecfp %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single %zu * %zu, num non-zero %zu, number of neon fma %zu, sparsify size in bytes %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single %zu * %zu, num nonzero %zu, number of neon fma %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single 4x4 %zu * %zu, num nonzero %zu, number of neon fma %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 12_16 mla2 %zu * %zu, num non-zero %zu, number of mla2 fma %zu, sparsify size in bytes %zu\n"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 12_16 mla3 %zu * %zu, num non-zero %zu, number of mla3 fma %zu, sparsify size in bytes %zu\n"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 14_16 mla2 %zu * %zu, num non-zero %zu, number of mla2 fma %zu, sparsify size in bytes %zu\n"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 14_16 mla3 %zu * %zu, num non-zero %zu, number of mla3 fma %zu, sparsify size in bytes %zu\n"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 5_8 %zu * %zu, num non-zero %zu, number of neon fma %zu, sparsify size in bytes %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 6_8 %zu * %zu, num non-zero %zu, number of neon fma %zu, sparsify size in bytes %zu"
- "BNNS Fully Connected Sparse Info: fp32 batch multi %zu * %zu * %zu, num nonzero %zu, number of mla vecfp %zu, number of mla matfp+lut %zu, number of mla matfp %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp32 batch single %zu * %zu, num nonzero %zu, number of neon fma %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse: using batch single compute for batch_size %zu, will be probably better to use batch_multi code path"
- "BNNS Fully Connected Sparsify: not enough memory in scratch memory to encode sparsity"
- "BNNS Fully Connected Sparsify: tried structured 12:16 but number of non zeros is vey low %zu"
- "BNNS Fully Connected Sparsify: tried structured 13:16 but number of non zeros is vey low %zu"
- "BNNS Fully Connected Sparsify: tried structured 14:16 but number of non zeros is vey low %zu"
- "BNNS Fully Connected Sparsify: tried structured 5:8 but number of non zeros is vey low %zu"
- "BNNS Fully Connected Sparsify: tried structured 6:8 but number of non zeros is vey low %zu"
- "BNNS Fully Connected: attempting to convert %zu x %zu x %zu to Sparse"
- "BNNS Fully Connected: using generic code to convert data 1 element each time\n"
- "BNNS Fully Convolution Sparse COO: probably wrong stride size %zu"
- "BNNS Fused Filter Backward Multi-Input Warning: Batch size is 0, nothing to do"
- "BNNS Fused Filter Backward Multi-Input: Error - only fused arithmetic and normalization is supported."
- "BNNS Fused Filter Backward Multi-Input: Error normalization backward failed"
- "BNNS Fused Filter Backward Multi-Input: Error normalization beta delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward Multi-Input: Error normalization gamma delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward Warning: Batch size is 0, nothing to do"
- "BNNS Fused Filter Backward: Error - fused compute and quantization gradient is not support "
- "BNNS Fused Filter Backward: Error Weight delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward: Error bias delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward: Error normalization backward failed"
- "BNNS Fused Filter Backward: Error normalization beta delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward: Error normalization gamma delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward: Error wrong filter, this function should only be used for a filter created with BNNSFilterCreateFusedLayer"
- "BNNS Fused Filter Multi-Input Warning: Batch size is 0, nothing to do"
- "BNNS Fused Filter Multi-Input: Error - only fused arithmetic and normalization is supported."
- "BNNS Fused Filter Multi-Input: Error arithmetic filter apply failed"
- "BNNS Fused Filter Warning: Batch size is 0, nothing to do"
- "BNNS Fused Filter: Error first filter apply failed"
- "BNNS Fused Filter: Error malloc failed"
- "BNNS Fused Filter: Error wrong filter, this function should only be used for a filter created with BNNSFilterCreateFusedLayer"
- "BNNS Group Norm Apply Backward: activation allocation failed"
- "BNNS Group Norm Apply Backward: failed to apply activation backward"
- "BNNS Instance Norm Apply Backward: activation allocation failed"
- "BNNS Instance Norm Apply Backward: failed to apply activation backward"
- "BNNS LOSS %s"
- "BNNS LSTM %s"
- "BNNS LSTM APPLY BACKWARD: forward pass intermediate results weren't cached, recomputing forward pass"
- "BNNS Layer Norm Apply Backward: activation allocation failed"
- "BNNS Layer Norm Apply Backward: failed to apply activation backward"
- "BNNS Log Filter: invalid one input filter id %u"
- "BNNS Log Filter: invalid two input filter id %u"
- "BNNS Loss Backward Error: weight_size value must be 0,1 batch_size, or batch_size*input_width for softmax/sigmoid/categorical cross entropy, mse, mae, log, hinge, and huber"
- "BNNS Loss Error: weight_size value must be 0,1 batch_size, or batch_size*input_width for sigmoid/categorical cross entropy, mse, mae, log, hinge, and huber"
- "BNNS Loss Error: weight_size value must be 0,1 batch_size, or batch_size*input_width for softmax"
- "BNNS Loss Warning: reduction BNNSLossReductionWeightedMean sum of weights is zero"
- "BNNS Loss Warning: weight_size==0 but weight pointer is not NULL. Weight pointer is ignored."
- "BNNS Loss: Error yolo weight_size value must be 0, use yolo specific weight factors during filter create"
- "BNNS Loss: Warning weight_size==0 but weight pointer is not NULL. Weight pointer is ignored."
- "BNNS MULTIHEAD ATTENTION PARAMETERS: -multihead %zu -TSL %zu -SSL %zu -dm %zu -dk %zu -dv %zu%s"
- "BNNS NORM -batchnorm %s%s%s"
- "BNNS NORM -groupnorm %s%s%s"
- "BNNS NORM -instancenorm %s%s%s"
- "BNNS NORM -layernorm %s%s%s"
- "BNNS Normalization Backward Warning: Batch size is 0, nothing to do"
- "BNNS Normalization Backward: Error wrong filter, this function should only be used for a filter created with BNNSFilterCreateLayerNormalization"
- "BNNS Normalization Warning: epsilon is zero, it may cause division by zero"
- "BNNS Normalization Warning: momentum is zero"
- "BNNS PADDING %s"
- "BNNS PADDING: ndim %u lpad[%u,%u,%u,%u,%u,%u,%u,%u] OrigTensor[%llu,%llu,%llu,%llu,%llu,%llu,%llu,%llu] rpad[%u,%u,%u,%u,%u,%u,%u,%u] -> DstTensor[%llu,%llu,%llu,%llu,%llu,%llu,%llu,%llu]\n"
- "BNNS POOLING PARAMETERS: %s%s%s"
- "BNNS Permute Filter Warning: Batch size is 0, nothing to do"
- "BNNS Pooling Filter Warning: Batch size is 0, nothing to do"
- "BNNS Pooling: optimized code supports kernel width/height up to 16"
- "BNNS REDUCTION %s%s%s"
- "BNNS RESIZE %s%s%s"
- "BNNS SLICE_EXPR: Unexpected kind for slice_expr.%s[%zu] = 0x%hx\n"
- "BNNS SLICE_EXPR: bound tensor index is out of range for slice_expr.%s[%zu] = %lld\n"
- "BNNS SLICE_EXPR: bound tensor is not rank 1 for slice_expr.%s[%zu] = %lld\n"
- "BNNS SLICE_EXPR: bound tensor out of bounds for slice_expr.%s[%zu] = %lld\n"
- "BNNS SLICE_EXPR: bound tensor shape dimn out of bounds for slice_expr.%s[%zu] = %lld\n"
- "BNNS SLICE_EXPR: effective index begin[%zu]=%lld not in range [0, %llu)\n"
- "BNNS SLICE_EXPR: effective index end[%zu]=%lld not in range (0, %llu]\n"
- "BNNS SPARSE CONVOLUTION: -one_line %s%s%s"
- "BNNS SPARSE FULLY CONNECTED PARAMETERS: %s%s%s"
- "BNNS Sparse Fully Connected: dense mla codepath available, better to use dense mla than sparse neon"
- "BNNS Sparse Fully Connected: out of scratch memory to encode"
- "BNNS TRANSPOSED CONVOLUTION: -one_line -trans %s%s%s"
- "BNNS Tensor Contraction: ouput descriptor is illegal \"%s\""
- "BNNS VECTOR TRANSPOSED CONVOLUTION: -one_line -trans %s%s%s"
- "BNNS VIO Pose: Unexpected Tensor Sizes\n"
- "BNNS VIO Pose: missing %s"
- "BNNS VIO Pose: wrong size"
- "BNNS fuse_dequant_matvec: encountered unexpected dequantization scheme"
- "BNNS, Warning, Trying to generate IR for a zero-sized input"
- "BNNS: DEBUG INTERMEDIATE TYPE %u DOES NOT MATCH TENSOR TYPE %u\n"
- "BNNS: FAILED TO COMPARE TENSOR OF TYPE %u\n"
- "BNNS: Your BNNS-IR file contains a bug and must be recompiled with a newer compiler"
- "BNNS: wrong varaitn chosen"
- "BasicNeuralNetworkSubroutines-1497.120.5~198"
- "C %s %.2f * %sA%s %s%s%s"
- "COPY %zu %zu %zu %zu (%zu %zu %zu %zu) <-- %zu %zu %zu %zu (%zu %zu %zu %zu)"
- "Convolution weight delta compute warning - batch size is 0, nothing to do"
- "Copy"
- "D"
- "D "
- "DFT"
- "EnumeratedShapes"
- "Epsilon must be in {fp32, fp16}"
- "I:"
- "I: %zu %zu %zu O: %zu %zu %zu K: %zu %zu TYPE: %s %s %s"
- "I: %zu %zu %zu O: %zu %zu %zu K: %zu %zu TYPE: %s %s %s DILATION: %zu %zu"
- "I: %zu O: %zu TYPE: %s %s %s TRANS: %c"
- "KERNEL_COPY_APPEND_SLICE_MGLM_V0"
- "KERNEL_COPY_APPEND_SLICE_MGLM_V1"
- "KERNEL_COPY_CONCAT_DYNAMIC_SME2_0_OR_NEON"
- "KERNEL_COPY_SLICE_BY_SIZE_DYNAMIC"
- "KERNEL_COPY_SLICE_EXPR"
- "KERNEL_MATMUL_ELEMENTWISE_ACTIVATION_MATMUL"
- "KERNEL_MATMUL_LARGE_N_REPACK"
- "KERNEL_MATMUL_LARGE_N_REPACK_DYNAMIC"
- "KERNEL_MATMUL_MLA2_GRP_INT4"
- "KERNEL_MATMUL_MLA3_DKM_INT3"
- "KERNEL_MATMUL_MLA3_GRP_INT4_V2"
- "KERNEL_MGLM_MATMUL_2x2_INDEXED4_MLA3"
- "KERNEL_MGLM_MHA_V2_BF16_FP32_MLA3"
- "KERNEL_TTS_SOUNDSTORM_FFN_NORM_FFN_NORM_FFN_NORM"
- "K_cache_input"
- "K_values"
- "Key %s not found in user data."
- "LSTM BWD %s%s"
- "LSTM FWD %s%s"
- "M:%d I: %llu %llu %llu %llu P: [%u %u] [%u %u] [%u %u] [%u %u]"
- "MGLM"
- "MGLM_noint4"
- "MatMul"
- "Negative strides not supported for slice_expression"
- "Pooling layer filter running slow path: stride=%zu,%zu kernel=%zu,%zu"
- "PredefinedOptimization"
- "Q_values"
- "RangeDims"
- "S "
- "SME svadd_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME svmul_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME vadd_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME vmul_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME vsadd_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME vsmul_fp32 kernel was called on problem size that doesn't merit SME usage."
- "StateMode"
- "Unsupported data type"
- "V_cache_input"
- "V_values"
- "WINOGRAD"
- "], end = ["
- "^T"
- "_anon_default_beta_for:batchnorm(of:{"
- "_anon_default_beta_for:instance_norm(of:{"
- "_anon_default_beta_for:layernorm(of:{"
- "_anon_default_gamma_for:batchnorm(of:{"
- "_anon_default_gamma_for:instance_norm(of:{"
- "_anon_default_gamma_for:layernorm(of:{"
- "at undefined location"
- "at unspecified MIL location."
- "attn_wt"
- "autogenerated downconvert"
- "autogenerated upconvert"
- "bound"
- "clip must be in {fp32, fp16}"
- "combo_mglm_mha_part0_v1"
- "combo_mglm_mha_part1_v1"
- "combo_mglm_mha_v2"
- "combo_tts_soundstorm_FFN_NORM_FFN_NORM_FFN_NORM"
- "comobo_rotation"
- "custom"
- "div_no_nan"
- "encoder_0_weights"
- "epsilon2"
- "func "
- "group("
- "internal.combo_mglm_mha_v2"
- "internal.matvec"
- "internal.mglm_append_slice"
- "internal.slice_expression"
- "inverse_with_eps"
- "ios17.dequantize"
- "ios17.quantize"
- "log2"
- "log_with_eps"
- "mask_bias"
- "matvec op requires input types to be FP16 or FP32"
- "matvec op requires output type to be FP16 or FP32"
- "matvec("
- "mglm_append_slice"
- "mha_scratch(for:"
- "mul_no_nan"
- "mul_scalar"
- "negate"
- "normalization op only supports {FP16, FP32} parameters"
- "op:%s I:"
- "out of bounds slice_expression: begin["
- "out of bounds slice_expression: end["
- "recip"
- "rsqrt_root"
- "rsqrt_with_eps"
- "scrtach for elementwise activation matmul "
- "scrtach for matmul softmax matmul "
- "slice_expression"
- "slice_expression only supports fp16, bf16, fp32 and int32 operands"
- "slice_expression requires input and output types to match"
- "slice_slide_pass"
- "sliced{"
- "soft_wt"
- "sqkt"
- "trunc_div"
- "trunc_remainder"
- "tts soundstorm ffn_norm scratch(for:"
- "w"
- "{ .control = %d, .size { %zu, %zu, %zu, %zu }, .rate = %f, .gain = %f } "
- "{ .ndim = %zu, .size = {"
- "{ .opstr = \"%s\", .zero_output = %c, .alpha = %f, .beta = %f, .apply_fn_type = %d, .sum = "
- "{repacked_for: "

```
