## localspeechrecognition

> `/System/Library/Frameworks/Speech.framework/XPCServices/localspeechrecognition.xpc/localspeechrecognition`

```diff

-3302.15.1.0.0
-  __TEXT.__text: 0x2b7c4
-  __TEXT.__auth_stubs: 0x13b0
-  __TEXT.__objc_stubs: 0x2a40
-  __TEXT.__objc_methlist: 0x914
-  __TEXT.__const: 0x898
-  __TEXT.__objc_methname: 0x43f0
-  __TEXT.__cstring: 0x2a09
-  __TEXT.__constg_swiftt: 0xa78
-  __TEXT.__swift5_typeref: 0x6f9
-  __TEXT.__swift5_reflstr: 0x582
-  __TEXT.__swift5_fieldmd: 0x3e4
+3304.65.2.11.1
+  __TEXT.__text: 0x2e928
+  __TEXT.__auth_stubs: 0x15a0
+  __TEXT.__objc_stubs: 0x2940
+  __TEXT.__objc_methlist: 0x954
+  __TEXT.__const: 0xb28
+  __TEXT.__cstring: 0x3014
+  __TEXT.__objc_methname: 0x43b0
+  __TEXT.__constg_swiftt: 0xe40
+  __TEXT.__swift5_typeref: 0x7d4
+  __TEXT.__swift5_reflstr: 0x68e
+  __TEXT.__swift5_fieldmd: 0x52c
   __TEXT.__swift5_builtin: 0x50
   __TEXT.__swift5_assocty: 0x90
-  __TEXT.__swift5_proto: 0x48
-  __TEXT.__swift5_types: 0x48
+  __TEXT.__swift5_proto: 0x54
+  __TEXT.__swift5_types: 0x64
   __TEXT.__objc_classname: 0x170
-  __TEXT.__objc_methtype: 0x11eb
+  __TEXT.__objc_methtype: 0x1227
   __TEXT.__swift5_capture: 0xf8
-  __TEXT.__gcc_except_tab: 0x39c
-  __TEXT.__oslogstring: 0x136a
-  __TEXT.__unwind_info: 0x94c
-  __TEXT.__eh_frame: 0x658
-  __DATA_CONST.__auth_got: 0x9e8
-  __DATA_CONST.__got: 0x2d8
-  __DATA_CONST.__auth_ptr: 0x38
-  __DATA_CONST.__const: 0xe68
+  __TEXT.__gcc_except_tab: 0x364
+  __TEXT.__oslogstring: 0x13b5
+  __TEXT.__unwind_info: 0x1104
+  __TEXT.__eh_frame: 0x6a0
+  __DATA_CONST.__auth_got: 0xae0
+  __DATA_CONST.__got: 0x308
+  __DATA_CONST.__auth_ptr: 0x40
+  __DATA_CONST.__const: 0x11a8
   __DATA_CONST.__cfstring: 0x760
-  __DATA_CONST.__objc_classlist: 0x98
+  __DATA_CONST.__objc_classlist: 0xa8
   __DATA_CONST.__objc_catlist: 0x10
   __DATA_CONST.__objc_protolist: 0x98
   __DATA_CONST.__objc_imageinfo: 0x8
+  __DATA_CONST.__objc_protorefs: 0x48
+  __DATA_CONST.__objc_classrefs: 0x3a0
+  __DATA_CONST.__objc_superrefs: 0x18
   __DATA_CONST.__objc_intobj: 0x18
-  __DATA.__objc_const: 0x2580
-  __DATA.__objc_selrefs: 0x1140
-  __DATA.__objc_protorefs: 0x48
-  __DATA.__objc_classrefs: 0x388
-  __DATA.__objc_superrefs: 0x18
+  __DATA.__objc_const: 0x2988
+  __DATA.__objc_selrefs: 0x1168
   __DATA.__objc_ivar: 0x84
-  __DATA.__objc_data: 0x8b0
-  __DATA.__data: 0x13a0
+  __DATA.__objc_data: 0x970
+  __DATA.__data: 0x1898
   __DATA.__common: 0xa0
-  __DATA.__bss: 0x978
+  __DATA.__bss: 0xb08
   - /System/Library/Frameworks/AudioToolbox.framework/AudioToolbox
   - /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation
   - /System/Library/Frameworks/Foundation.framework/Foundation
   - /System/Library/Frameworks/Speech.framework/Speech
+  - /System/Library/PrivateFrameworks/AIMLExperimentationAnalytics.framework/AIMLExperimentationAnalytics
   - /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices
   - /System/Library/PrivateFrameworks/BiomePubSub.framework/BiomePubSub
   - /System/Library/PrivateFrameworks/CoreAnalytics.framework/CoreAnalytics

   - /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation
   - /System/Library/PrivateFrameworks/SiriPowerInstrumentation.framework/SiriPowerInstrumentation
   - /System/Library/PrivateFrameworks/TCC.framework/TCC
+  - /System/Library/PrivateFrameworks/Trial.framework/Trial
   - /usr/lib/libSystem.B.dylib
   - /usr/lib/libobjc.A.dylib
   - /usr/lib/swift/libswiftAVFoundation.dylib

   - /usr/lib/swift/libswiftCoreMedia.dylib
   - /usr/lib/swift/libswiftDarwin.dylib
   - /usr/lib/swift/libswiftDispatch.dylib
+  - /usr/lib/swift/libswiftDistributed.dylib
   - /usr/lib/swift/libswiftMetal.dylib
   - /usr/lib/swift/libswiftObjectiveC.dylib
   - /usr/lib/swift/libswiftQuartzCore.dylib

   - /usr/lib/swift/libswift_Concurrency.dylib
   - /usr/lib/swift/libswiftos.dylib
   - /usr/lib/swift/libswiftsimd.dylib
-  UUID: 20547D2E-BADC-320C-BB14-7E0A9A654642
-  Functions: 816
-  Symbols:   394
-  CStrings:  1257
+  UUID: 2502CD41-B17A-3A63-B664-A136B7948228
+  Functions: 909
+  Symbols:   411
+  CStrings:  1304
 
Symbols:
+ _OBJC_CLASS_$_ASRSchemaASRAudioPacketContainingEndOfFirstWordReadyUpstream
+ _OBJC_CLASS_$_ASRSchemaASRFinalAudioPacketContainingSpeechReadyUpstream
+ _OBJC_CLASS_$_ASRSchemaASRFirstAudioPacketReadyUpstream
+ _OBJC_CLASS_$_ASRSchemaASRFirstAudioPacketRecorded
+ _OBJC_CLASS_$_TRIClient
+ _free
+ _malloc
+ _objc_retain_x4
+ _swift_allocateGenericClassMetadata
+ _swift_allocateGenericValueMetadata
+ _swift_checkMetadataState
+ _swift_defaultActor_deallocate
+ _swift_defaultActor_destroy
+ _swift_getFunctionTypeMetadata
+ _swift_getGenericMetadata
+ _swift_initClassMetadata2
+ _swift_initStructMetadata
+ _swift_release_n
+ _swift_setDeallocating
- _OBJC_CLASS_$_AFFeatureFlags
- _OBJC_CLASS_$_SFEntitledTrialAssetManager
CStrings:
+ "$defaultActor"
+ "%s Adding audio packet: %zu"
+ "%s Failed to read Hammer config file at path: %@"
+ "%s GeoLM: No region specific asset found for language: %@, regionId: %{private}@"
+ "%s GeoLM: Region specific asset for %{private}@ is incompatible with the main asset."
+ "%s Inline LME input size=%zu"
+ "%s No Hammer asset found for language: %@"
+ "%s Recognizer is running, cancel the request"
+ "%s Schedule cooldown timer only after active request finishes"
+ "Configuring recognizer with speech profile at path: %{private}s"
+ "GeoLM: region mapping json file is nil Or there is no regionMapping for given language=%s"
+ "GeoLM: region mapping json file=%s"
+ "Insufficient space allocated to copy string contents"
+ "Negative value is not representable"
+ "Not enough bits to represent the passed value"
+ "SIRI_SPEECH_SV_SPEECH_PROFILE"
+ "Setting disableContextualBiasing=%{bool}d based on factor level from Trial."
+ "Swift/ContiguousArrayBuffer.swift"
+ "Swift/Integers.swift"
+ "Swift/StringTesting.swift"
+ "Swift/StringUTF8View.swift"
+ "Swift/UnsafeBufferPointer.swift"
+ "Swift/UnsafePointer.swift"
+ "Swift/UnsafeRawPointer.swift"
+ "T@\"NSString\",?,R,C"
+ "Unexpectedly found nil while unwrapping an Optional value"
+ "UnsafeMutableBufferPointer with negative count"
+ "UnsafeMutablePointer.initialize overlapping range"
+ "UnsafeMutablePointer.initialize with negative count"
+ "UnsafeMutablePointer.moveInitialize with negative count"
+ "UnsafeMutableRawPointer.initializeMemory overlapping range"
+ "UnsafeMutableRawPointer.initializeMemory with negative count"
+ "Vv24@0:8@\"_SFAnalyzerClientInfo\"16"
+ "Vv24@0:8@?<v@?@\"NSNumber\"@\"NSError\">16"
+ "Vv48@0:8@\"_SFSpeechRecognizerSupportedFeatures\"16@\"_SFAnalyzerClientInfo\"24@\"_SFAnalysisContextCodingObject\"32@\"_SFAnalysisOptions\"40"
+ "_TtC22localspeechrecognition28ExperimentationTriggerLogger"
+ "_TtC22localspeechrecognition32TrialExperimentationAssetManager"
+ "aneUsed"
+ "aotLmeUsed"
+ "audioBufferListenerLock"
+ "booleanValue"
+ "clientWithIdentifier:"
+ "cpuInstructionsInMillionsPerSecond"
+ "data"
+ "dictationUIInteractionID"
+ "initWithLocale:config:"
+ "initWithSpeechRecognitionFeatures:acousticFeatures:snr:"
+ "invalid Collection: less than 'count' elements in collection"
+ "isLocked"
+ "languageStr"
+ "levelForFactor:withNamespaceName:"
+ "listenerLock"
+ "loadSpeechProfiles:language:"
+ "ncb_feature_enabled"
+ "numContextualEmbeddings"
+ "numberWithUnsignedLongLong:"
+ "prepareForReuseWithNewSupportedFeatures:clientInfo:analysisContext:analysisOptions:"
+ "priority"
+ "processStartTimeOnce"
+ "processStartTimeOnceWithReply:"
+ "queue"
+ "queueBuilder"
+ "setAudioPacketContainingEndOfFirstWordReadyUpstream:"
+ "setClientInfo(_:)"
+ "setClientInfo:"
+ "setDisableContextualBiasing:"
+ "setFinalAudioPacketContainingSpeechReadyUpstream:"
+ "setFirstAudioPacketReadyUpstream:"
+ "setFirstAudioPacketRecorded:"
+ "setLeftContextText(_:)"
+ "setLeftContextText:"
+ "setRightContext(_:)"
+ "setSelectedText(_:)"
+ "snr"
+ "totalITNDurationInNs"
+ "totalITNRuns"
+ "trialClient"
+ "userSpeechProfiles"
+ "userSpeechProfilesWithReply:"
+ "value"
+ "wrappedValue"
- "%s Adding audio packet: %ld"
- "%s Failed to query Trial with error=%@"
- "%s Failed to read Hammer json file"
- "%s GeoLM: geoLM region specific [%@] asset exists on device, but not compatible."
- "%s GeoLM: region specific [%@] geo-config json file=%@"
- "%s GeoLM: region specific asset is not found for given language=%@ regionId=%@"
- "%s Inline LME input size=%lu"
- "-[LSRSpeechAssets purgeAssetsForLanguage:clientID:completion:]"
- "Failed to load speech profile at %{private}s: %@"
- "Loaded speech profile: path=%{private}s"
- "Setting new profile: %ld"
- "Vv24@0:8@?<v@?Q@\"NSError\">16"
- "Vv48@0:8@\"NSUUID\"16@\"_SFSpeechRecognizerSupportedFeatures\"24@\"_SFAnalysisContextCodingObject\"32@\"_SFAnalysisOptions\"40"
- "cpuMillionInstructionsPerSecond"
- "dictationUIInteractionId"
- "downloadAssetOfType:language:urgent:forceUpgrade:progressHandler:completionHandler:"
- "downloadStatusWithConfig:progressHandler:completionHandler:"
- "highPriority"
- "initWithPath:error:"
- "initWithSpeechRecognitionFeatures:acousticFeatures:"
- "installationStatusForLanguagesForAssetType:includeDetailedStatus:error:"
- "installedAssetWithConfig:"
- "installedAssetWithConfig:regionId:"
- "installedAssetWithConfig:regionId:triggerDownload:"
- "isASRAdoptingUAFEnabled"
- "prepareForReuseWithNewAsrID:supportedFeatures:analysisContext:analysisOptions:"
- "processStartTime"
- "processStartTimeWithReply:"
- "purgeInstalledAssetForAssetType:language:regionId:error:"
- "setAssetsPurgeability:forLanguages:assetType:"
- "supportedLanguagesWithAssetType:"
- "v16@?0Q8"
- "v20@?0d8B16"

```
