## libBNNS.dylib

> `/System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/libBNNS.dylib`

```diff

 1860.0.16.0.0
-  __TEXT.__text: 0xf176c4
-  __TEXT.__auth_stubs: 0x1680
-  __TEXT.__gcc_except_tab: 0x2e478
+  __TEXT.__text: 0xf0076c
+  __TEXT.__auth_stubs: 0x1660
+  __TEXT.__gcc_except_tab: 0x2e418
   __TEXT.__const: 0x2ae10
-  __TEXT.__cstring: 0x4f92c
-  __TEXT.__oslogstring: 0x36b
-  __TEXT.__unwind_info: 0x18a78
-  __TEXT.__eh_frame: 0xbc44
+  __TEXT.__cstring: 0x4bddb
+  __TEXT.__oslogstring: 0x303
+  __TEXT.__unwind_info: 0x189f8
+  __TEXT.__eh_frame: 0xbbb4
   __DATA_CONST.__got: 0x168
-  __DATA_CONST.__const: 0x4ab0
-  __AUTH_CONST.__auth_got: 0xb48
+  __DATA_CONST.__const: 0x4a60
+  __AUTH_CONST.__auth_got: 0xb38
   __AUTH_CONST.__const: 0x2a748
   __AUTH_CONST.__cfstring: 0x200
   __AUTH.__data: 0x1c70

   - /System/Library/PrivateFrameworks/MIL.framework/MIL
   - /usr/lib/libSystem.B.dylib
   - /usr/lib/libc++.1.dylib
-  UUID: B0A34234-2C95-39B1-96F1-8CA2C79BB888
-  Functions: 34319
-  Symbols:   834
-  CStrings:  7541
+  UUID: DEF0037A-3E87-3209-9688-47B94A4D252A
+  Functions: 34270
+  Symbols:   832
+  CStrings:  7219
 
Symbols:
- _atoi
- _strlcat
CStrings:
+ "BasicNeuralNetworkSubroutines-1860.0.16~1147"
- " -A %u"
- " -B %zu"
- " -B %zu -IS %zu -OS %zu"
- " -BD "
- " -Bdelta"
- " -CDS 2"
- " -DS %zu %zu"
- " -Idelta"
- " -LPA %u"
- " -P %zu %zu"
- " -PA %zu %zu %zu %zu"
- " -S %zu %zu"
- " -SD "
- " -WO %zu"
- " -Wdelta"
- " -axis "
- " -axis 255 "
- " -bi"
- " -bias"
- " -bias "
- " -bias -BD %s"
- " -clientptr=off"
- " -clientptr=on"
- " -dequantize "
- " -groups %zu "
- " -inplace"
- " -low-mem"
- " -no-cell"
- " -no-hidden"
- " -nt %zu"
- " -peephole"
- " -pw %u"
- " -quantize "
- " -scale"
- " -sum_input_delta"
- " -train-ptr"
- " -training"
- " -trans"
- " -wl IOHW"
- " -wl IOHrWr"
- " -wl OIHrWr"
- " GEMM: %s %c%c %zu x %zu x %zu "
- " } "
- " } { "
- " }, .data_type = %d } "
- " }, .stride = {"
- "%s -IO %zu"
- "%s -OO %zu"
- "%s%s%s%s"
- "%sIS %zu "
- "%sRS %zu "
- "%zu "
- "%{name=layer}s %{name=direction}s BS:%{name=batch_size}zu %{name=summary}s"
- "(unsupported fn %d) "
- "+="
- ", .input = "
- ", .output = "
- "-A %d "
- "-A %u "
- "-AC "
- "-B %zu %s"
- "-B %zu %s%s"
- "-B %zu -IABS %zu -IBBS %zu -OS %zu "
- "-Bdelta "
- "-C %zu -I %zu %zu %s%s-O %zu %zu %s%s-K %zu %zu -P %zu %zu -S %zu %zu %s%s -D %s %s "
- "-I"
- "-I %zu %zu %zu %s%s-O %zu %zu %zu %s%s-K %zu %zu -P %zu %zu -S %zu %zu %s-ID %s -OD %s -WD %s%s "
- "-I %zu %zu %zu %s%s-O %zu %zu %zu %s%s-K %zu %zu%s%s%s%s%s%s -ID %s -OD %s -WD %s%s "
- "-I %zu -O %zu %s-ID %s -OD %s -WD %s%s%s%s"
- "-I %zu -O %zu -B %zu -seq %zu -stack %zu%s%s%s%s%s%s%s"
- "-I %zu -O %zu -B %zu -seq %zu -stack %zu%s%s%s%s%s%s%s -grad"
- "-I %zu -O %zu -K %u %u -LPA %u -A %u -ID %s -OD %s -WD %s%s "
- "-I1"
- "-I1_type %d "
- "-I2"
- "-I2_type %d "
- "-IAdelta "
- "-IBdelta "
- "-M %d "
- "-O"
- "-O_type %d "
- "-R %d "
- "-T"
- "-W"
- "-Wdelta "
- "-add_zero_attn"
- "-avgE "
- "-avgI "
- "-beta %f "
- "-eps %e "
- "-epsilon %f "
- "-gamma %f "
- "-in_place1 "
- "-in_place2 "
- "-max "
- "-momentum %f "
- "-num_groups %zu "
- "-op %d "
- "-op %s Indexing: %s Contracting:%s%s A:%s B:%s C:%s"
- "-unmax "
- "1"
- "2"
- "3"
- "4"
- "5"
- "6"
- "7"
- "8"
- "9"
- "<No summary info id %u>"
- "A"
- "AB"
- "ACCELERATE_416DE66E47C9"
- "ACCELERATE_7B09D8C42EF4"
- "ACCELERATE_83A752B02172"
- "ACCELERATE_965A44538097E"
- "ACCELERATE_B4EB444453EC"
- "ACCELERATE_DB267B4233C11"
- "ACCELERATE_DF5AD80B280E"
- "AffineGridSample"
- "B"
- "BA"
- "BNNS %s CONVOLUTION PARAMETERS: -one_line %s%s%s"
- "BNNS => NORM %s"
- "BNNS ACTIVATION PARAMETERS: -I %zu %zu %zu %s%s-O %zu %zu %zu %s%s-ID %s -OD %s%s%s%s%s%s"
- "BNNS AFFINE GRID SAMPLE %s %s %s %s"
- "BNNS ARITHMETIC (%s) BWD %s%s%s"
- "BNNS ARITHMETIC (%s) FWD %s%s%s"
- "BNNS Activation Apply Backward: unable to allocate memory to compute activation, using slower compute path"
- "BNNS Arithmetic Filter Warning: Batch size is 0, nothing to do"
- "BNNS Arithmetic Filter: Error wrong filter, this function should only be used for a filter created with BNNSFilterCreateLayerArithmetic"
- "BNNS Arithmetic Filter: input type is BNNSConstant, no gradient to compute"
- "BNNS Batchnorm Apply Backward: activation allocation failed"
- "BNNS Batchnorm Apply Backward: failed to apply activation backward"
- "BNNS BroadcastMatMul FWD %s -A %s -B %s -C %s%s"
- "BNNS CONTRACTION %s%s%s"
- "BNNS CONVOLUTION A1: problem doesn't fit in memory limit\n"
- "BNNS CONVOLUTION ACCELERATE1: weights aren't contiguous, using pack weights general\n"
- "BNNS CONVOLUTION CUSTOMIZED: -one_line %s%s%s"
- "BNNS CONVOLUTION PARAMETERS: -one_line %s%s%s"
- "BNNS CONVOLUTION VERS2: -one_line %s%s%s"
- "BNNS CONVOLUTIONS CUSTOMIZED: layer param is NULL\n"
- "BNNS CONVOLUTIONS VERSION2: 2D conv doesn't fit in memory limit"
- "BNNS CONVOLUTIONS VERSION2: BFloat16 weights are only allowed for OIHW layout"
- "BNNS CONVOLUTIONS VERSION2: cannot compute nonzero output channels for zero input channels"
- "BNNS CONVOLUTIONS VERSION2: empty input spatial dimensions without padding is not allowed"
- "BNNS CONVOLUTIONS VERSION2: empty kernel or output spatial dimensions not allowed"
- "BNNS CONVOLUTIONS VERSION2: int/out/weight/bias descriptor element stride (stride[0]) must be 1"
- "BNNS CONVOLUTIONS VERSION2: layer param is NULL\n"
- "BNNS CONVOLUTIONS VERSION2: output bias or scale is not supported\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported activation\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported bias data type\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported input data type\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported output data type\n"
- "BNNS CONVOLUTIONS VERSION2: unsupported weight data type\n"
- "BNNS COPYSUM %s%s%s"
- "BNNS Convolution Create: convolution doesn't support indexed weights"
- "BNNS Convolution Create: input data type is not supported"
- "BNNS Convolution Create: int16/uint16 output is not supported"
- "BNNS Convolution Create: int8/uint8 output supported only with int8/uint8 inputs and weights"
- "BNNS Convolution Create: not allowed to delay allocation to apply if weights ptr isn't maintained by Client\n"
- "BNNS Convolution Create: output data type is not supported"
- "BNNS Convolution Create: uint32 output is not supported"
- "BNNS Convolution Create: weight data type is not supported"
- "BNNS Convolution: Winograd weights memory doesn't fit in memory\n"
- "BNNS Convolution: unable to create Winograd that fit in memory\n"
- "BNNS Convolutions A1   FP Engine: kernel with greater than 16 isn't supported (-K %zu %zu)"
- "BNNS Convolutions A1  FP Engine: kernel with greater than 16 isn't supported (-K %zu %zu), kernel width after dilation: %zu"
- "BNNS Convolutions A1: 2D conv doesn't fit in memory limit"
- "BNNS Convolutions A1: asymmetric strides aren't supported (-S %zu %zu)"
- "BNNS Convolutions A1: dilation is only supported for 1x1 stride (-DS %zu %zu) (-S %zu %zu)"
- "BNNS Convolutions A1: input is 0, no computation (-I %zu %zu %zu)"
- "BNNS Convolutions A1: strides larger than 2, aren't supported (-S %zu %zu)"
- "BNNS Copy DEST %s SRC %s %s"
- "BNNS DEPTHWISE CONVOLUTION %s"
- "BNNS DROPOUT %s%s%s"
- "BNNS Dodge V2: Unexpected Tensor Sizes\n"
- "BNNS Dodge V2: unable to find constant tensor"
- "BNNS Dodge V2: wrong size"
- "BNNS EMBEDDING %s"
- "BNNS Embedding Apply: Input value %lld is out of range [0, %zu)\n"
- "BNNS FIRST FILTER => QUANT %s"
- "BNNS FIRST FILTER:"
- "BNNS FULLY CONNECTED PARAMETERS: %s%s%s"
- "BNNS FUSED %s%s"
- "BNNS FUSED PADDING/CONVOLUTION %s"
- "BNNS Fully Connected Backward: no bias, bias delta ignored"
- "BNNS Fully Connected Choose: inputs, weights, outputs and bias must be contiguous in memory (stride[0] <= 1)"
- "BNNS Fully Connected Sparse COO: probably wrong stride size %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch multi %zu * %zu * %zu, num nonzero %zu, number of mla vecfp %zu, number of mla matfp+lut %zu, number of mla matfp %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single %zu * %zu * %zu, num nonzero %zu, number of mla vecfp %zu, number of nop vecfp %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single %zu * %zu, num non-zero %zu, number of neon fma %zu, sparsify size in bytes %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single %zu * %zu, num nonzero %zu, number of neon fma %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single 4x4 %zu * %zu, num nonzero %zu, number of neon fma %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 12_16 mla2 %zu * %zu, num non-zero %zu, number of mla2 fma %zu, sparsify size in bytes %zu\n"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 12_16 mla3 %zu * %zu, num non-zero %zu, number of mla3 fma %zu, sparsify size in bytes %zu\n"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 14_16 mla2 %zu * %zu, num non-zero %zu, number of mla2 fma %zu, sparsify size in bytes %zu\n"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 14_16 mla3 %zu * %zu, num non-zero %zu, number of mla3 fma %zu, sparsify size in bytes %zu\n"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 5_8 %zu * %zu, num non-zero %zu, number of neon fma %zu, sparsify size in bytes %zu"
- "BNNS Fully Connected Sparse Info: fp16 batch single structured 6_8 %zu * %zu, num non-zero %zu, number of neon fma %zu, sparsify size in bytes %zu"
- "BNNS Fully Connected Sparse Info: fp32 batch multi %zu * %zu * %zu, num nonzero %zu, number of mla vecfp %zu, number of mla matfp+lut %zu, number of mla matfp %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse Info: fp32 batch single %zu * %zu, num nonzero %zu, number of neon fma %zu, sparsify size in bytes: %zu"
- "BNNS Fully Connected Sparse: using batch single compute for batch_size %zu, will be probably better to use batch_multi code path"
- "BNNS Fully Connected Sparsify: not enough memory in scratch memory to encode sparsity"
- "BNNS Fully Connected Sparsify: tried structured 12:16 but number of non zeros is vey low %zu"
- "BNNS Fully Connected Sparsify: tried structured 13:16 but number of non zeros is vey low %zu"
- "BNNS Fully Connected Sparsify: tried structured 14:16 but number of non zeros is vey low %zu"
- "BNNS Fully Connected Sparsify: tried structured 5:8 but number of non zeros is vey low %zu"
- "BNNS Fully Connected Sparsify: tried structured 6:8 but number of non zeros is vey low %zu"
- "BNNS Fully Connected: attempting to convert %zu x %zu x %zu to Sparse"
- "BNNS Fully Connected: using generic code to convert data 1 element each time\n"
- "BNNS Fully Convolution Sparse COO: probably wrong stride size %zu"
- "BNNS Fused Filter Backward Multi-Input Warning: Batch size is 0, nothing to do"
- "BNNS Fused Filter Backward Multi-Input: Error - only fused arithmetic and normalization is supported."
- "BNNS Fused Filter Backward Multi-Input: Error normalization backward failed"
- "BNNS Fused Filter Backward Multi-Input: Error normalization beta delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward Multi-Input: Error normalization gamma delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward Warning: Batch size is 0, nothing to do"
- "BNNS Fused Filter Backward: Error - fused compute and quantization gradient is not support "
- "BNNS Fused Filter Backward: Error Weight delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward: Error bias delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward: Error normalization backward failed"
- "BNNS Fused Filter Backward: Error normalization beta delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward: Error normalization gamma delta pointer is NULL. backward computation of all active parameters must be done in a single function call. "
- "BNNS Fused Filter Backward: Error wrong filter, this function should only be used for a filter created with BNNSFilterCreateFusedLayer"
- "BNNS Fused Filter Multi-Input Warning: Batch size is 0, nothing to do"
- "BNNS Fused Filter Multi-Input: Error - only fused arithmetic and normalization is supported."
- "BNNS Fused Filter Multi-Input: Error arithmetic filter apply failed"
- "BNNS Fused Filter Warning: Batch size is 0, nothing to do"
- "BNNS Fused Filter: Error first filter apply failed"
- "BNNS Fused Filter: Error malloc failed"
- "BNNS Fused Filter: Error wrong filter, this function should only be used for a filter created with BNNSFilterCreateFusedLayer"
- "BNNS Graph: failed to mmap BNNS IR file: %s"
- "BNNS Graph: failed to open BNNS IR file: %s"
- "BNNS Group Norm Apply Backward: activation allocation failed"
- "BNNS Group Norm Apply Backward: failed to apply activation backward"
- "BNNS Instance Norm Apply Backward: activation allocation failed"
- "BNNS Instance Norm Apply Backward: failed to apply activation backward"
- "BNNS LOSS %s"
- "BNNS LSTM %s"
- "BNNS LSTM APPLY BACKWARD: forward pass intermediate results weren't cached, recomputing forward pass"
- "BNNS Layer Norm Apply Backward: activation allocation failed"
- "BNNS Layer Norm Apply Backward: failed to apply activation backward"
- "BNNS Log Filter: invalid one input filter id %u"
- "BNNS Log Filter: invalid two input filter id %u"
- "BNNS Loss Backward Error: weight_size value must be 0,1 batch_size, or batch_size*input_width for softmax/sigmoid/categorical cross entropy, mse, mae, log, hinge, and huber"
- "BNNS Loss Error: weight_size value must be 0,1 batch_size, or batch_size*input_width for sigmoid/categorical cross entropy, mse, mae, log, hinge, and huber"
- "BNNS Loss Error: weight_size value must be 0,1 batch_size, or batch_size*input_width for softmax"
- "BNNS Loss Warning: reduction BNNSLossReductionWeightedMean sum of weights is zero"
- "BNNS Loss Warning: weight_size==0 but weight pointer is not NULL. Weight pointer is ignored."
- "BNNS Loss: Error yolo weight_size value must be 0, use yolo specific weight factors during filter create"
- "BNNS Loss: Warning weight_size==0 but weight pointer is not NULL. Weight pointer is ignored."
- "BNNS MULTIHEAD ATTENTION PARAMETERS: -multihead %zu -TSL %zu -SSL %zu -dm %zu -dk %zu -dv %zu%s"
- "BNNS NORM -batchnorm %s%s%s"
- "BNNS NORM -groupnorm %s%s%s"
- "BNNS NORM -instancenorm %s%s%s"
- "BNNS NORM -layernorm %s%s%s"
- "BNNS Normalization Backward Warning: Batch size is 0, nothing to do"
- "BNNS Normalization Backward: Error wrong filter, this function should only be used for a filter created with BNNSFilterCreateLayerNormalization"
- "BNNS Normalization Warning: epsilon is zero, it may cause division by zero"
- "BNNS Normalization Warning: momentum is zero"
- "BNNS PADDING %s"
- "BNNS PADDING: ndim %u lpad[%u,%u,%u,%u,%u,%u,%u,%u] OrigTensor[%llu,%llu,%llu,%llu,%llu,%llu,%llu,%llu] rpad[%u,%u,%u,%u,%u,%u,%u,%u] -> DstTensor[%llu,%llu,%llu,%llu,%llu,%llu,%llu,%llu]\n"
- "BNNS POOLING PARAMETERS: %s%s%s"
- "BNNS Permute Filter Warning: Batch size is 0, nothing to do"
- "BNNS Pooling Filter Warning: Batch size is 0, nothing to do"
- "BNNS Pooling: optimized code supports kernel width/height up to 16"
- "BNNS REDUCTION %s%s%s"
- "BNNS RESIZE %s%s%s"
- "BNNS SPARSE CONVOLUTION: -one_line %s%s%s"
- "BNNS SPARSE FULLY CONNECTED PARAMETERS: %s%s%s"
- "BNNS Sparse Fully Connected: dense mla codepath available, better to use dense mla than sparse neon"
- "BNNS Sparse Fully Connected: out of scratch memory to encode"
- "BNNS TRANSPOSED CONVOLUTION: -one_line -trans %s%s%s"
- "BNNS VECTOR TRANSPOSED CONVOLUTION: -one_line -trans %s%s%s"
- "BNNS VIO Pose: Unexpected Tensor Sizes\n"
- "BNNS VIO Pose: missing %s"
- "BNNS VIO Pose: wrong size"
- "BNNS, Warning, Trying to generate IR for a zero-sized input"
- "BNNS: DEBUG INTERMEDIATE TYPE %u DOES NOT MATCH TENSOR TYPE %u\n"
- "BNNS: FAILED TO COMPARE TENSOR OF TYPE %u\n"
- "BasicNeuralNetworkSubroutines-1860.0.16~363"
- "C %s %.2f * %sA%s %s%s%s"
- "COPY %zu %zu %zu %zu (%zu %zu %zu %zu) <-- %zu %zu %zu %zu (%zu %zu %zu %zu)"
- "Convolution weight delta compute warning - batch size is 0, nothing to do"
- "Copy"
- "D"
- "D "
- "DFT"
- "I:"
- "I: %zu %zu %zu O: %zu %zu %zu K: %zu %zu TYPE: %s %s %s"
- "I: %zu %zu %zu O: %zu %zu %zu K: %zu %zu TYPE: %s %s %s DILATION: %zu %zu"
- "I: %zu O: %zu TYPE: %s %s %s TRANS: %c"
- "Key %s not found in user data."
- "LSTM BWD %s%s"
- "LSTM FWD %s%s"
- "M:%d I: %llu %llu %llu %llu P: [%u %u] [%u %u] [%u %u] [%u %u]"
- "MatMul"
- "Pooling layer filter running slow path: stride=%zu,%zu kernel=%zu,%zu"
- "S "
- "SME svadd_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME svmul_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME vadd_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME vmul_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME vsadd_fp32 kernel was called on problem size that doesn't merit SME usage."
- "SME vsmul_fp32 kernel was called on problem size that doesn't merit SME usage."
- "WINOGRAD"
- "^T"
- "div_no_nan"
- "inverse_with_eps"
- "log2"
- "log_with_eps"
- "mul_no_nan"
- "negate"
- "op:%s I:"
- "recip"
- "rsqrt_with_eps"
- "trunc_div"
- "trunc_remainder"
- "w"
- "{ .control = %d, .size { %zu, %zu, %zu, %zu }, .rate = %f, .gain = %f } "
- "{ .ndim = %zu, .size = {"
- "{ .opstr = \"%s\", .zero_output = %c, .alpha = %f, .beta = %f, .apply_fn_type = %d, .sum = "

```
